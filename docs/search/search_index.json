{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to AirSim AirSim is a simulator for drones, cars and more, built on Unreal Engine . It is open-source, cross platform and supports hardware-in-loop with popular flight controllers such as PX4 for physically and visually realistic simulations. It is developed as an Unreal plugin that can simply be dropped into any Unreal environment you want. Our goal is to develop AirSim as a platform for AI research to experiment with deep learning, computer vision and reinforcement learning algorithms for autonomous vehicles. For this purpose, AirSim also exposes APIs to retrieve data and control vehicles in a platform independent way. Check out the quick 1.5 minute demo Drones in AirSim Cars in AirSim What's New New environments : Forest, Plains (windmill farm), TalkingHeads (human head simulation), TrapCam (animal detection via camera) Highly efficient NoDisplay view mode to turn off main screen rendering so you can capture images at high rate Lidar Sensor Case Study: Formula Student Technion Driverless Multi-Vehicle Capability ROS publisher Arducopter Solo Support AirSim 1.2 is released! This version has breaking changes in APIs and settings.json. Please see the API Upgrade and Settings Upgrade docs. We have upgraded to Unreal Engine 4.18 and Visual Studio 2017 (see upgrade instructions ) For complete list of changes, view our Changelog How to Get It Windows Download binaries Build it Linux Build it How to Use It Choosing the Mode: Car, Multirotor or ComputerVision By default AirSim will prompt you to choose Car or Multirotor mode. You can use SimMode setting to specify the default vehicle or the new ComputerVision mode . Manual drive If you have remote control (RC) as shown below, you can manually control the drone in the simulator. For cars, you can use arrow keys to drive manually. More details Programmatic control AirSim exposes APIs so you can interact with the vehicle in the simulation programmatically. You can use these APIs to retrieve images, get state, control the vehicle and so on. The APIs are exposed through the RPC, and are accessible via a variety of languages, including C++, Python, C# and Java. These APIs are also available as part of a separate, independent cross-platform library, so you can deploy them on a companion computer on your vehicle. This way you can write and test your code in the simulator, and later execute it on the real vehicles. Transfer learning and related research is one of our focus areas. More details Gathering training data There are two ways you can generate training data from AirSim for deep learning. The easiest way is to simply press the record button in the lower right corner. This will start writing pose and images for each frame. The data logging code is pretty simple and you can modify it to your heart's content. A better way to generate training data exactly the way you want is by accessing the APIs. This allows you to be in full control of how, what, where and when you want to log data. Computer Vision mode Yet another way to use AirSim is the so-called \"Computer Vision\" mode. In this mode, you don't have vehicles or physics. You can use the keyboard to move around the scene, or use APIs to position available cameras in any arbitrary pose, and collect images such as depth, disparity, surface normals or object segmentation. More details Tutorials Video - Setting up AirSim with Pixhawk Tutorial by Chris Lovett Video - Using AirSim with Pixhawk Tutorial by Chris Lovett Video - Using off-the-self environments with AirSim by Jim Piavis Reinforcement Learning with AirSim by Ashish Kapoor The Autonomous Driving Cookbook by Microsoft Deep Learning and Robotics Garage Chapter Using TensorFlow for simple collision avoidance by Simon Levy and WLU team Participate Paper More technical details are available in AirSim paper (FSR 2017 Conference) . Please cite this as: @inproceedings{airsim2017fsr, author = {Shital Shah and Debadeepta Dey and Chris Lovett and Ashish Kapoor}, title = {AirSim: High-Fidelity Visual and Physical Simulation for Autonomous Vehicles}, year = {2017}, booktitle = {Field and Service Robotics}, eprint = {arXiv:1705.05065}, url = {https://arxiv.org/abs/1705.05065} } Contribute Please take a look at open issues if you are looking for areas to contribute to. More on AirSim design More on code structure Contribution Guidelines Trello Board Who is Using AirSim? We are maintaining a list of a few projects, people and groups that we are aware of. If you would like to be featured in this list please make a request here . Contact Join the AirSim group on Facebook to stay up to date or ask any questions. FAQ If you run into problems, check the FAQ and feel free to post issues in the AirSim repository. License This project is released under the MIT License. Please review the License file for more details.","title":"Home"},{"location":"#welcome-to-airsim","text":"AirSim is a simulator for drones, cars and more, built on Unreal Engine . It is open-source, cross platform and supports hardware-in-loop with popular flight controllers such as PX4 for physically and visually realistic simulations. It is developed as an Unreal plugin that can simply be dropped into any Unreal environment you want. Our goal is to develop AirSim as a platform for AI research to experiment with deep learning, computer vision and reinforcement learning algorithms for autonomous vehicles. For this purpose, AirSim also exposes APIs to retrieve data and control vehicles in a platform independent way. Check out the quick 1.5 minute demo Drones in AirSim Cars in AirSim","title":"Welcome to AirSim"},{"location":"#whats-new","text":"New environments : Forest, Plains (windmill farm), TalkingHeads (human head simulation), TrapCam (animal detection via camera) Highly efficient NoDisplay view mode to turn off main screen rendering so you can capture images at high rate Lidar Sensor Case Study: Formula Student Technion Driverless Multi-Vehicle Capability ROS publisher Arducopter Solo Support AirSim 1.2 is released! This version has breaking changes in APIs and settings.json. Please see the API Upgrade and Settings Upgrade docs. We have upgraded to Unreal Engine 4.18 and Visual Studio 2017 (see upgrade instructions ) For complete list of changes, view our Changelog","title":"What's New"},{"location":"#how-to-get-it","text":"","title":"How to Get It"},{"location":"#windows","text":"Download binaries Build it","title":"Windows"},{"location":"#linux","text":"Build it","title":"Linux"},{"location":"#how-to-use-it","text":"","title":"How to Use It"},{"location":"#choosing-the-mode-car-multirotor-or-computervision","text":"By default AirSim will prompt you to choose Car or Multirotor mode. You can use SimMode setting to specify the default vehicle or the new ComputerVision mode .","title":"Choosing the Mode: Car, Multirotor or ComputerVision"},{"location":"#manual-drive","text":"If you have remote control (RC) as shown below, you can manually control the drone in the simulator. For cars, you can use arrow keys to drive manually. More details","title":"Manual drive"},{"location":"#programmatic-control","text":"AirSim exposes APIs so you can interact with the vehicle in the simulation programmatically. You can use these APIs to retrieve images, get state, control the vehicle and so on. The APIs are exposed through the RPC, and are accessible via a variety of languages, including C++, Python, C# and Java. These APIs are also available as part of a separate, independent cross-platform library, so you can deploy them on a companion computer on your vehicle. This way you can write and test your code in the simulator, and later execute it on the real vehicles. Transfer learning and related research is one of our focus areas. More details","title":"Programmatic control"},{"location":"#gathering-training-data","text":"There are two ways you can generate training data from AirSim for deep learning. The easiest way is to simply press the record button in the lower right corner. This will start writing pose and images for each frame. The data logging code is pretty simple and you can modify it to your heart's content. A better way to generate training data exactly the way you want is by accessing the APIs. This allows you to be in full control of how, what, where and when you want to log data.","title":"Gathering training data"},{"location":"#computer-vision-mode","text":"Yet another way to use AirSim is the so-called \"Computer Vision\" mode. In this mode, you don't have vehicles or physics. You can use the keyboard to move around the scene, or use APIs to position available cameras in any arbitrary pose, and collect images such as depth, disparity, surface normals or object segmentation. More details","title":"Computer Vision mode"},{"location":"#tutorials","text":"Video - Setting up AirSim with Pixhawk Tutorial by Chris Lovett Video - Using AirSim with Pixhawk Tutorial by Chris Lovett Video - Using off-the-self environments with AirSim by Jim Piavis Reinforcement Learning with AirSim by Ashish Kapoor The Autonomous Driving Cookbook by Microsoft Deep Learning and Robotics Garage Chapter Using TensorFlow for simple collision avoidance by Simon Levy and WLU team","title":"Tutorials"},{"location":"#participate","text":"","title":"Participate"},{"location":"#paper","text":"More technical details are available in AirSim paper (FSR 2017 Conference) . Please cite this as: @inproceedings{airsim2017fsr, author = {Shital Shah and Debadeepta Dey and Chris Lovett and Ashish Kapoor}, title = {AirSim: High-Fidelity Visual and Physical Simulation for Autonomous Vehicles}, year = {2017}, booktitle = {Field and Service Robotics}, eprint = {arXiv:1705.05065}, url = {https://arxiv.org/abs/1705.05065} }","title":"Paper"},{"location":"#contribute","text":"Please take a look at open issues if you are looking for areas to contribute to. More on AirSim design More on code structure Contribution Guidelines Trello Board","title":"Contribute"},{"location":"#who-is-using-airsim","text":"We are maintaining a list of a few projects, people and groups that we are aware of. If you would like to be featured in this list please make a request here .","title":"Who is Using AirSim?"},{"location":"#contact","text":"Join the AirSim group on Facebook to stay up to date or ask any questions.","title":"Contact"},{"location":"#faq","text":"If you run into problems, check the FAQ and feel free to post issues in the AirSim repository.","title":"FAQ"},{"location":"#license","text":"This project is released under the MIT License. Please review the License file for more details.","title":"License"},{"location":"AUTHORS/","text":"Authors AirSim was originally created by Shital Shah during late 2016. Shital authored physics engine, multirotor model, car model, environment models, sensor models, all Unreal Engine related code, APIs, SimpleFlight firmware, computer vision components, documentation etc. Chris Lovett , another original author, contributed the MavLink communication library, PX4 related components, Settings system, build system, several important bug fixes and so on. List of all contributors since our first release in February 2017 can be found here .","title":"Authors"},{"location":"AUTHORS/#authors","text":"AirSim was originally created by Shital Shah during late 2016. Shital authored physics engine, multirotor model, car model, environment models, sensor models, all Unreal Engine related code, APIs, SimpleFlight firmware, computer vision components, documentation etc. Chris Lovett , another original author, contributed the MavLink communication library, PX4 related components, Settings system, build system, several important bug fixes and so on. List of all contributors since our first release in February 2017 can be found here .","title":"Authors"},{"location":"CHANGELOG/","text":"What's new Below is summarized list of important changes. This does not include minor/less important changes or bug fixes or documentation update. This list updated every few months. For complete detailed changes, please review commit history . November, 2018 New environments : Forest, Plains (windmill farm), TalkingHeads (human head simulation), TrapCam (animal detection via camera) Highly efficient NoDisplay view mode to turn off main screen rendering so you can capture images at high rate Enable/disable sensors via settings Lidar Sensor Support for Flysky FS-SM100 RC USB adapter Case Study: Formula Student Technion Driverless Multi-Vehicle Capability Custom speed units ROS publisher simSetObjectPose API Character Control APIs (works on TalkingHeads binaries in release) Arducopter Solo Support Linux install without sudo access Kinect like ROS publisher June, 2018 Development workflow doc Better Python 2 compatibility OSX setup fixes Almost complete rewrite of our APIs with new threading model, merging old APIs and creating few newer ones April, 2018 Upgraded to Unreal Engine 4.18 and Visual Studio 2017 API framework refactoring to support world-level APIs Latest PX4 firmware now supported CarState with more information ThrustMaster wheel support pause and continueForTime APIs for drone as well as car Allow drone simulation run at higher clock rate without any degradation Forward-only mode fully functional for drone (do orbits while looking at center) Better PID tuning to reduce wobble for drones Ability to set arbitrary vehicle blueprint for drone as well as car gimbal stabilization via settings Ability to segment skinned and skeletal meshes by their name moveByAngleThrottle API Car physics tuning for better maneuverability Configure additional cameras via settings Time of day with geographically computed sun position Better car steering via keyboard Added MeshNamingMethod in segmentation setting gimbal API getCameraParameters API Ability turn off main rendering to save GPU resources Projection mode for capture settings getRCData, setRCData APIs Ability to turn off segmentation using negative IDs OSX build improvements Segmentation working for very large environments with initial IDs Better and extensible hash calculation for segmentation IDs Extensible PID controller for custom integration methods Sensor architecture now enables renderer specific features like ray casting Laser altimeter sensor Jan 2018 Config system rewrite, enable flexible config we are targeting in future Multi-Vehicle support Phase 1, core infrastructure changes MacOS support Infrared view 5 types of noise and interference for cameras WYSIWIG capture settings for cameras, preview recording settings in main view Azure support Phase 1, enable configurability of instances for headless mode Full kinematics APIs, ability to get pose, linear and angular velocities + accelerations via APIs Record multiple images from multiple cameras New segmentation APIs, ability to set configure object IDs, search via regex New object pose APIs, ability to get pose of objects (like animals) in environment Camera infrastructure enhancements, ability to add new image types like IR with just few lines Clock speed APIs for drone as well as car, simulation can be run with speed factor of 0 < x < infinity Support for Logitech G920 wheel Physics tuning of the car, Car doesn\u2019t roll over, responds to steering with better curve, releasing gas paddle behavior more realistic Debugging APIs Stress tested to 24+ hours of continuous runs Support for Landscape and sky segmentation Manual navigation with accelerated controls in CV mode, user can explore environment much more easily Collison APIs Recording enhancements, log several new data points including ground truth, multiple images, controls state Planner and Perspective Depth views Disparity view New Image APIs supports float, png or numpy formats 6 config settings for image capture, ability to set auto-exposure, motion blur, gamma etc Full multi-camera support through out including sub-windows, recording, APIs etc Command line script to build all environments in one shot Remove submodules, use rpclib as download Nov 2017 We now have the car model . No need to build the code. Just download binaries and you are good to go! The reinforcement learning example with AirSim New built-in flight controller called simple_flight that \"just works\" without any additional setup. It is also now default . AirSim now also generates depth as well as disparity images that is in camera plan. We also have official Linux build now! Sep 2017 We have added car model ! Aug 2017 simple_flight is now default flight controller for drones. If you want to use PX4, you will need to modify settings.json as per PX4 setup doc . Linux build is official and currently uses Unreal 4.17 due to various bug fixes required ImageType enum has breaking changes with several new additions and clarifying existing ones SubWindows are now configurable from settings.json PythonClient is now complete and has parity with C++ APIs. Some of these would have breaking changes. Feb 2017 First release!","title":"Whats New"},{"location":"CHANGELOG/#whats-new","text":"Below is summarized list of important changes. This does not include minor/less important changes or bug fixes or documentation update. This list updated every few months. For complete detailed changes, please review commit history .","title":"What's new"},{"location":"CHANGELOG/#november-2018","text":"New environments : Forest, Plains (windmill farm), TalkingHeads (human head simulation), TrapCam (animal detection via camera) Highly efficient NoDisplay view mode to turn off main screen rendering so you can capture images at high rate Enable/disable sensors via settings Lidar Sensor Support for Flysky FS-SM100 RC USB adapter Case Study: Formula Student Technion Driverless Multi-Vehicle Capability Custom speed units ROS publisher simSetObjectPose API Character Control APIs (works on TalkingHeads binaries in release) Arducopter Solo Support Linux install without sudo access Kinect like ROS publisher","title":"November, 2018"},{"location":"CHANGELOG/#june-2018","text":"Development workflow doc Better Python 2 compatibility OSX setup fixes Almost complete rewrite of our APIs with new threading model, merging old APIs and creating few newer ones","title":"June, 2018"},{"location":"CHANGELOG/#april-2018","text":"Upgraded to Unreal Engine 4.18 and Visual Studio 2017 API framework refactoring to support world-level APIs Latest PX4 firmware now supported CarState with more information ThrustMaster wheel support pause and continueForTime APIs for drone as well as car Allow drone simulation run at higher clock rate without any degradation Forward-only mode fully functional for drone (do orbits while looking at center) Better PID tuning to reduce wobble for drones Ability to set arbitrary vehicle blueprint for drone as well as car gimbal stabilization via settings Ability to segment skinned and skeletal meshes by their name moveByAngleThrottle API Car physics tuning for better maneuverability Configure additional cameras via settings Time of day with geographically computed sun position Better car steering via keyboard Added MeshNamingMethod in segmentation setting gimbal API getCameraParameters API Ability turn off main rendering to save GPU resources Projection mode for capture settings getRCData, setRCData APIs Ability to turn off segmentation using negative IDs OSX build improvements Segmentation working for very large environments with initial IDs Better and extensible hash calculation for segmentation IDs Extensible PID controller for custom integration methods Sensor architecture now enables renderer specific features like ray casting Laser altimeter sensor","title":"April, 2018"},{"location":"CHANGELOG/#jan-2018","text":"Config system rewrite, enable flexible config we are targeting in future Multi-Vehicle support Phase 1, core infrastructure changes MacOS support Infrared view 5 types of noise and interference for cameras WYSIWIG capture settings for cameras, preview recording settings in main view Azure support Phase 1, enable configurability of instances for headless mode Full kinematics APIs, ability to get pose, linear and angular velocities + accelerations via APIs Record multiple images from multiple cameras New segmentation APIs, ability to set configure object IDs, search via regex New object pose APIs, ability to get pose of objects (like animals) in environment Camera infrastructure enhancements, ability to add new image types like IR with just few lines Clock speed APIs for drone as well as car, simulation can be run with speed factor of 0 < x < infinity Support for Logitech G920 wheel Physics tuning of the car, Car doesn\u2019t roll over, responds to steering with better curve, releasing gas paddle behavior more realistic Debugging APIs Stress tested to 24+ hours of continuous runs Support for Landscape and sky segmentation Manual navigation with accelerated controls in CV mode, user can explore environment much more easily Collison APIs Recording enhancements, log several new data points including ground truth, multiple images, controls state Planner and Perspective Depth views Disparity view New Image APIs supports float, png or numpy formats 6 config settings for image capture, ability to set auto-exposure, motion blur, gamma etc Full multi-camera support through out including sub-windows, recording, APIs etc Command line script to build all environments in one shot Remove submodules, use rpclib as download","title":"Jan 2018"},{"location":"CHANGELOG/#nov-2017","text":"We now have the car model . No need to build the code. Just download binaries and you are good to go! The reinforcement learning example with AirSim New built-in flight controller called simple_flight that \"just works\" without any additional setup. It is also now default . AirSim now also generates depth as well as disparity images that is in camera plan. We also have official Linux build now!","title":"Nov 2017"},{"location":"CHANGELOG/#sep-2017","text":"We have added car model !","title":"Sep 2017"},{"location":"CHANGELOG/#aug-2017","text":"simple_flight is now default flight controller for drones. If you want to use PX4, you will need to modify settings.json as per PX4 setup doc . Linux build is official and currently uses Unreal 4.17 due to various bug fixes required ImageType enum has breaking changes with several new additions and clarifying existing ones SubWindows are now configurable from settings.json PythonClient is now complete and has parity with C++ APIs. Some of these would have breaking changes.","title":"Aug 2017"},{"location":"CHANGELOG/#feb-2017","text":"First release!","title":"Feb 2017"},{"location":"CONTRIBUTING/","text":"Contributing Quick Start Please read our short and sweet coding guidelines . For big changes such as adding new feature or refactoring, file an issue first . Use our recommended development workflow to make changes and test it. Use usual steps to make contributions just like other GitHub projects. If you are not familiar with Git Branch-Rebase-Merge workflow, please read this first . Checklist Use same style and formatting as rest of code even if it's not your preferred one. Change any documentation that goes with code changes. Do not include OS specific header files or new 3rd party dependencies. Keep your pull request small, ideally under 10 files. Make sure you don't include large binary files. When adding new includes, make dependency is absolutely necessary. Rebase your branch frequently with master (once every 2-3 days is ideal). Make sure your code would compile on Windows, Linux and OSX.","title":"Contribute"},{"location":"CONTRIBUTING/#contributing","text":"","title":"Contributing"},{"location":"CONTRIBUTING/#quick-start","text":"Please read our short and sweet coding guidelines . For big changes such as adding new feature or refactoring, file an issue first . Use our recommended development workflow to make changes and test it. Use usual steps to make contributions just like other GitHub projects. If you are not familiar with Git Branch-Rebase-Merge workflow, please read this first .","title":"Quick Start"},{"location":"CONTRIBUTING/#checklist","text":"Use same style and formatting as rest of code even if it's not your preferred one. Change any documentation that goes with code changes. Do not include OS specific header files or new 3rd party dependencies. Keep your pull request small, ideally under 10 files. Make sure you don't include large binary files. When adding new includes, make dependency is absolutely necessary. Rebase your branch frequently with master (once every 2-3 days is ideal). Make sure your code would compile on Windows, Linux and OSX.","title":"Checklist"},{"location":"ISSUE_TEMPLATE/","text":"Read This First If you are reporting a bug Make sure to write all reproduction steps Include full error message in text form Search issues for error message before filing issue Attach screenshot if applicable Include code to run if applicable If you have question Add clear and concise title Add OS, AirSim version, Python version, Unreal version if applicable Include context on what you are trying to achieve Include details of what you already did to find answers What's better than filing issue? Filing a pull request :). ------------------------------------ (Remove above before filing the issue) ------------------------------------","title":"Read This First"},{"location":"ISSUE_TEMPLATE/#read-this-first","text":"","title":"Read This First"},{"location":"ISSUE_TEMPLATE/#if-you-are-reporting-a-bug","text":"Make sure to write all reproduction steps Include full error message in text form Search issues for error message before filing issue Attach screenshot if applicable Include code to run if applicable","title":"If you are reporting a bug"},{"location":"ISSUE_TEMPLATE/#if-you-have-question","text":"Add clear and concise title Add OS, AirSim version, Python version, Unreal version if applicable Include context on what you are trying to achieve Include details of what you already did to find answers What's better than filing issue? Filing a pull request :). ------------------------------------ (Remove above before filing the issue) ------------------------------------","title":"If you have question"},{"location":"SUPPORT/","text":"Support We highly recommend to take a look at source code and contribute to the project. Due to large number of incoming feature request we may not be able to get to your request in your desired timeframe. So please contribute :). Join AirSim Facebook Group File GitHub Issue","title":"Support"},{"location":"SUPPORT/#support","text":"We highly recommend to take a look at source code and contribute to the project. Due to large number of incoming feature request we may not be able to get to your request in your desired timeframe. So please contribute :). Join AirSim Facebook Group File GitHub Issue","title":"Support"},{"location":"docs/apis/","text":"AirSim APIs Introduction AirSim exposes APIs so you can interact with vehicle in the simulation programmatically. You can use these APIs to retrieve images, get state, control the vehicle and so on. Python Quickstart If you want to use Python to call AirSim APIs, we recommend using Anaconda with Python 3.5 or later versions however some code may also work with Python 2.7 ( help us improve compatibility!). First install this package: pip install msgpack-rpc-python You can either get AirSim binaries from releases or compile from the source ( Windows , Linux ). Once you can run AirSim, choose Car as vehicle and then navigate to PythonClient\\car\\ folder and run: python hello_car.py If you are using Visual Studio 2017 then just open AirSim.sln, set PythonClient as startup project and choose car\\hello_car.py as your startup script. Installing AirSim Package You can also install airsim package simply by, pip install airsim You can find source code and samples for this package in PythonClient folder in your repo. Notes 1. You may notice a file setup_path.py in our example folders. This file has simple code to detect if airsim package is available in parent folder and in that case we use that instead of pip installed package so you always use latest code. 2. AirSim is still under heavy development which means you might frequently need to update the package to use new APIs. C++ Users If you want to use C++ APIs and examples, please see C++ APIs Guide . Hello Car Here's how to use AirSim APIs using Python to control simulated car (see also C++ example ): # ready to run example: PythonClient/car/hello_car.py import airsim import time # connect to the AirSim simulator client = airsim.CarClient() client.confirmConnection() client.enableApiControl(True) car_controls = airsim.CarControls() while True: # get state of the car car_state = client.getCarState() print(\"Speed %d, Gear %d\" % (car_state.speed, car_state.gear)) # set the controls for car car_controls.throttle = 1 car_controls.steering = 1 client.setCarControls(car_controls) # let car drive a bit time.sleep(1) # get camera images from the car responses = client.simGetImages([ airsim.ImageRequest(0, airsim.ImageType.DepthVis), airsim.ImageRequest(1, airsim.ImageType.DepthPlanner, True)]) print('Retrieved images: %d', len(responses)) # do something with images for response in responses: if response.pixels_as_float: print(\"Type %d, size %d\" % (response.image_type, len(response.image_data_float))) airsim.write_pfm('py1.pfm', airsim.get_pfm_array(response)) else: print(\"Type %d, size %d\" % (response.image_type, len(response.image_data_uint8))) airsim.write_file('py1.png', response.image_data_uint8) Hello Drone Here's how to use AirSim APIs using Python to control simulated quadrotor (see also C++ example ): # ready to run example: PythonClient/multirotor/hello_drone.py import airsim # connect to the AirSim simulator client = airsim.MultirotorClient() client.confirmConnection() client.enableApiControl(True) client.armDisarm(True) # Async methods returns Future. Call join() to wait for task to complete. client.takeoffAsync().join() client.moveToPositionAsync(-10, 10, -10, 5).join() # take images responses = client.simGetImages([ airsim.ImageRequest(\"0\", airsim.ImageType.DepthVis), airsim.ImageRequest(\"1\", airsim.ImageType.DepthPlanner, True)]) print('Retrieved images: %d', len(responses)) # do something with the images for response in responses: if response.pixels_as_float: print(\"Type %d, size %d\" % (response.image_type, len(response.image_data_float))) airsim.write_pfm(os.path.normpath('/temp/py1.pfm'), airsim.getPfmArray(response)) else: print(\"Type %d, size %d\" % (response.image_type, len(response.image_data_uint8))) airsim.write_file(os.path.normpath('/temp/py1.png'), response.image_data_uint8) Common APIs reset : This resets the vehicle to its original starting state. Note that you must call enableApiControl and armDisarm again after the call to reset . confirmConnection : Checks state of connection every 1 sec and reports it in Console so user can see the progress for connection. enableApiControl : For safety reasons, by default API control for autonomous vehicle is not enabled and human operator has full control (usually via RC or joystick in simulator). The client must make this call to request control via API. It is likely that human operator of vehicle might have disallowed API control which would mean that enableApiControl has no effect. This can be checked by isApiControlEnabled . isApiControlEnabled : Returns true if API control is established. If false (which is default) then API calls would be ignored. After a successful call to enableApiControl , the isApiControlEnabled should return true. ping : If connection is established then this call will return true otherwise it will be blocked until timeout. simPrintLogMessage : Prints the specified message in the simulator's window. If message_param is also supplied then its printed next to the message and in that case if this API is called with same message value but different message_param again then previous line is overwritten with new line (instead of API creating new line on display). For example, simPrintLogMessage(\"Iteration: \", to_string(i)) keeps updating same line on display when API is called with different values of i. The valid values of severity parameter is 0 to 3 inclusive that corresponds to different colors. simGetObjectPose , simSetObjectPose : Gets and sets the pose of specified object in Unreal environment. Here the object means \"actor\" in Unreal terminology. They are searched by tag as well as name. Please note that the names shown in UE Editor are auto-generated in each run and are not permanent. So if you want to refer to actor by name, you must change its auto-generated name in UE Editor. Alternatively you can add a tag to actor which can be done by clicking on that actor in Unreal Editor and then going to Tags property , click \"+\" sign and add some string value. If multiple actors have same tag then the first match is returned. If no matches are found then NaN pose is returned. The returned pose is in NED coordinates in SI units with its origin at Player Start. For simSetObjectPose , the specified actor must have Mobility set to Movable or otherwise you will get undefined behavior. The simSetObjectPose has parameter teleport which means object is moved through other objects in its way and it returns true if move was successful Image / Computer Vision APIs AirSim offers comprehensive images APIs to retrieve synchronized images from multiple cameras along with ground truth including depth, disparity, surface normals and vision. You can set the resolution, FOV, motion blur etc parameters in settings.json . There is also API for detecting collision state. See also complete code that generates specified number of stereo images and ground truth depth with normalization to camera plan, computation of disparity image and saving it to pfm format . More on image APIs and Computer Vision mode . Pause and Continue APIs AirSim allows to pause and continue the simulation through pause(is_paused) API. To pause the simulation call pause(True) and to continue the simulation call pause(False) . You may have scenario, especially while using reinforcement learning, to run the simulation for specified amount of time and then automatically pause. While simulation is paused, you may then do some expensive computation, send a new command and then again run the simulation for specified amount of time. This can be achieved by API continueForTime(seconds) . This API runs the simulation for the specified number of seconds and then pauses the simulation. For example usage, please see pause_continue_car.py and pause_continue_drone.py . Collision API The collision information can be obtained using simGetCollisionInfo API. This call returns a struct that has information not only whether collision occurred but also collision position, surface normal, penetration depth and so on. Multiple Vehicles AirSim supports multiple vehicles and control them through APIs. Please Multiple Vehicles doc. Coordinate System All AirSim API uses NED coordinate system, i.e., +X is North, +Y is East and +Z is Down. All units are in SI system. Please note that this is different from coordinate system used internally by Unreal Engine. In Unreal Engine, +Z is up instead of down and length unit is in centimeters instead of meters. AirSim APIs takes care of the appropriate conversions. The starting point of the vehicle is always coordinates (0, 0, 0) in NED system. Thus when converting from Unreal coordinates to NED, we first subtract the starting offset and then scale by 100 for cm to m conversion. The vehicle is spawned in Unreal environment where the Player Start component is placed. There is a setting called OriginGeopoint in settings.json which assigns geographic longitude, longitude and altitude to the Player Start component. Vehicle Specific APIs APIs for Car Car has followings APIs available: setCarControls : This allows you to set throttle, steering, handbrake and auto or manual gear. getCarState : This retrieves the state information including speed, current gear and 6 kinematics quantities: position, orientation, linear and angular velocity, linear and angular acceleration. All quantities are in NED coordinate system, SI units in world frame except for angular velocity and accelerations which are in body frame. Image APIs . APIs for Multirotor Multirotor can be controlled by specifying angles, velocity vector, destination position or some combination of these. There are corresponding move* APIs for this purpose. When doing position control, we need to use some path following algorithm. By default AirSim uses carrot following algorithm. This is often referred to as \"high level control\" because you just need to specify high level goal and the firmware takes care of the rest. Currently lowest level control available in AirSim is moveByAngleThrottleAsync API. getMultirotorState This API returns the state of the vehicle in one call. The state includes, collision, estimated kinematics (i.e. kinematics computed by fusing sensors), and timestamp (nano seconds since epoch). The kinematics here means 6 quantities: position, orientation, linear and angular velocity, linear and angular acceleration. Please note that simple_slight currently doesn't support state estimator which means estimated and ground truth kinematics values would be same for simple_flight. Estimated kinematics are however available for PX4 except for angular acceleration. All quantities are in NED coordinate system, SI units in world frame except for angular velocity and accelerations which are in body frame. Async methods, duration and max_wait_seconds Many API methods has parameters named duration or max_wait_seconds and they have Async as suffix, for example, takeoffAsync . These methods will return immediately after starting the task in AirSim so that your client code can do something else while that task is being executed. If you want to wait for this task to complete then you can call waitOnLastTask like this: //C++ client.takeoffAsync()->waitOnLastTask(); # Python client.takeoffAsync().join() If you start another command then it automatically cancels the previous task and starts new command. This allows to use pattern where your coded continuously does the sensing, computes a new trajectory to follow and issues that path to vehicle in AirSim. Each newly issued trajectory cancels the previous trajectory allowing your code to continuously do the update as new sensor data arrives. All Async method returns concurrent.futures.Future in Python ( std::future in C++). Please note that these future classes currently do not allow to check status or cancel the task; they only allow to wait for task to complete. AirSim does provide API cancelLastTask , however. drivetrain There are two modes you can fly vehicle: drivetrain parameter is set to airsim.Drivetrain.ForwardOnly or airsim.Drivetrain.MaxDegreeOfFreedom . When you specify ForwardOnly, you are saying that vehicle's front should always point in the direction of travel. So if you want drone to take left turn then it would first rotate so front points to left. This mode is useful when you have only front camera and you are operating vehicle using FPV view. This is more or less like travelling in car where you always have front view. The MaxDegreeOfFreedom means you don't care where the front points to. So when you take left turn, you just start going left like crab. Quadrotors can go in any direction regardless of where front points to. The MaxDegreeOfFreedom enables this mode. yaw_mode yaw_mode is a struct YawMode with two fields, yaw_or_rate and is_rate . If is_rate field is True then yaw_or_rate field is interpreted as angular velocity in degrees/sec which means you want vehicle to rotate continuously around its axis at that angular velocity while moving. If is_rate is False then yaw_or_rate is interpreted as angle in degrees which means you want vehicle to rotate to specific angle (i.e. yaw) and keep that angle while moving. You can probably see that when yaw_mode.is_rate == true , the drivetrain parameter shouldn't be set to ForwardOnly because you are contradicting by saying that keep front pointing ahead but also rotate continuously. However if you have yaw_mode.is_rate = false in ForwardOnly mode then you can do some funky stuff. For example, you can have drone do circles and have yaw_or_rate set to 90 so camera is always pointed to center (\"super cool selfie mode\"). In MaxDegreeofFreedom also you can get some funky stuff by setting yaw_mode.is_rate = true and say yaw_mode.yaw_or_rate = 20 . This will cause drone to go in its path while rotating which may allow to do 360 scanning. In most cases, you just don't want yaw to change which you can do by setting yaw rate of 0. The shorthand for this is airsim.YawMode.Zero() (or in C++: YawMode::Zero() ). lookahead and adaptive_lookahead When you ask vehicle to follow a path, AirSim uses \"carrot following\" algorithm. This algorithm operates by looking ahead on path and adjusting its velocity vector. The parameters for this algorithm is specified by lookahead and adaptive_lookahead . For most of the time you want algorithm to auto-decide the values by simply setting lookahead = -1 and adaptive_lookahead = 0 . Using APIs on Real Vehicles We want to be able to run same code that runs in simulation as on real vehicle. This allows you to test your code in simulator and deploy to real vehicle. Generally speaking, APIs therefore shouldn't allow you to do something that cannot be done on real vehicle (for example, getting the ground truth). But, of course, simulator has much more information and it would be useful in applications that may not care about running things on real vehicle. For this reason, we clearly delineate between sim-only APIs by attaching sim prefix, for example, simGetGroundTruthKinematics . This way you can avoid using these simulation-only APIs if you care about running your code on real vehicles. The AirLib is self-contained library that you can put on an offboard computing module such as the Gigabyte barebone Mini PC. This module then can talk to the flight controllers such as PX4 using exact same code and flight controller protocol. The code you write for testing in the simulator remains unchanged. See AirLib on custom drones . Adding New APIs to AirSim Adding new APIs requires modifying the source code. Much of the changes are mechanical and required for various levels of abstractions that AirSim supports. This commit demonstrates how to add a simple API simPrintLogMessage that prints message in simulator window. Some Internals The APIs use msgpack-rpc protocol over TCP/IP through rpclib developed by Tam\u00e1s Szelei which allows you to use variety of programming languages including C++, C#, Python, Java etc. When AirSim starts, it opens port 41451 (this can be changed via settings ) and listens for incoming request. The Python or C++ client code connects to this port and sends RPC calls using msgpack serialization format . References and Examples C++ API Examples Car Examples Multirotor Examples Computer Vision Examples Move on Path demo showing video of fast multirotor flight through Modular Neighborhood environment Building a Hexacopter Building Point Clouds FAQ Unreal is slowed down dramatically when I run API If you see Unreal getting slowed down dramatically when Unreal Engine window loses focus then go to 'Edit->Editor Preferences' in Unreal Editor, in the 'Search' box type 'CPU' and ensure that the 'Use Less CPU when in Background' is unchecked. Do I need anything else on Windows? You should install VS2017 with VC++, Windows SDK 8.1 and Python. To use Python APIs you will need Python 3.5 or later (install it using Anaconda). Which version of Python should I use? We recommend Anaconda to get Python tools and libraries. Our code is tested with Python 3.5.3 :: Anaconda 4.4.0. This is important because older version have been known to have problems . I get error on import cv2 You can install OpenCV using: conda install opencv pip install opencv-python","title":"Core APIs"},{"location":"docs/apis/#airsim-apis","text":"","title":"AirSim APIs"},{"location":"docs/apis/#introduction","text":"AirSim exposes APIs so you can interact with vehicle in the simulation programmatically. You can use these APIs to retrieve images, get state, control the vehicle and so on.","title":"Introduction"},{"location":"docs/apis/#python-quickstart","text":"If you want to use Python to call AirSim APIs, we recommend using Anaconda with Python 3.5 or later versions however some code may also work with Python 2.7 ( help us improve compatibility!). First install this package: pip install msgpack-rpc-python You can either get AirSim binaries from releases or compile from the source ( Windows , Linux ). Once you can run AirSim, choose Car as vehicle and then navigate to PythonClient\\car\\ folder and run: python hello_car.py If you are using Visual Studio 2017 then just open AirSim.sln, set PythonClient as startup project and choose car\\hello_car.py as your startup script.","title":"Python Quickstart"},{"location":"docs/apis/#installing-airsim-package","text":"You can also install airsim package simply by, pip install airsim You can find source code and samples for this package in PythonClient folder in your repo. Notes 1. You may notice a file setup_path.py in our example folders. This file has simple code to detect if airsim package is available in parent folder and in that case we use that instead of pip installed package so you always use latest code. 2. AirSim is still under heavy development which means you might frequently need to update the package to use new APIs.","title":"Installing AirSim Package"},{"location":"docs/apis/#c-users","text":"If you want to use C++ APIs and examples, please see C++ APIs Guide .","title":"C++ Users"},{"location":"docs/apis/#hello-car","text":"Here's how to use AirSim APIs using Python to control simulated car (see also C++ example ): # ready to run example: PythonClient/car/hello_car.py import airsim import time # connect to the AirSim simulator client = airsim.CarClient() client.confirmConnection() client.enableApiControl(True) car_controls = airsim.CarControls() while True: # get state of the car car_state = client.getCarState() print(\"Speed %d, Gear %d\" % (car_state.speed, car_state.gear)) # set the controls for car car_controls.throttle = 1 car_controls.steering = 1 client.setCarControls(car_controls) # let car drive a bit time.sleep(1) # get camera images from the car responses = client.simGetImages([ airsim.ImageRequest(0, airsim.ImageType.DepthVis), airsim.ImageRequest(1, airsim.ImageType.DepthPlanner, True)]) print('Retrieved images: %d', len(responses)) # do something with images for response in responses: if response.pixels_as_float: print(\"Type %d, size %d\" % (response.image_type, len(response.image_data_float))) airsim.write_pfm('py1.pfm', airsim.get_pfm_array(response)) else: print(\"Type %d, size %d\" % (response.image_type, len(response.image_data_uint8))) airsim.write_file('py1.png', response.image_data_uint8)","title":"Hello Car"},{"location":"docs/apis/#hello-drone","text":"Here's how to use AirSim APIs using Python to control simulated quadrotor (see also C++ example ): # ready to run example: PythonClient/multirotor/hello_drone.py import airsim # connect to the AirSim simulator client = airsim.MultirotorClient() client.confirmConnection() client.enableApiControl(True) client.armDisarm(True) # Async methods returns Future. Call join() to wait for task to complete. client.takeoffAsync().join() client.moveToPositionAsync(-10, 10, -10, 5).join() # take images responses = client.simGetImages([ airsim.ImageRequest(\"0\", airsim.ImageType.DepthVis), airsim.ImageRequest(\"1\", airsim.ImageType.DepthPlanner, True)]) print('Retrieved images: %d', len(responses)) # do something with the images for response in responses: if response.pixels_as_float: print(\"Type %d, size %d\" % (response.image_type, len(response.image_data_float))) airsim.write_pfm(os.path.normpath('/temp/py1.pfm'), airsim.getPfmArray(response)) else: print(\"Type %d, size %d\" % (response.image_type, len(response.image_data_uint8))) airsim.write_file(os.path.normpath('/temp/py1.png'), response.image_data_uint8)","title":"Hello Drone"},{"location":"docs/apis/#common-apis","text":"reset : This resets the vehicle to its original starting state. Note that you must call enableApiControl and armDisarm again after the call to reset . confirmConnection : Checks state of connection every 1 sec and reports it in Console so user can see the progress for connection. enableApiControl : For safety reasons, by default API control for autonomous vehicle is not enabled and human operator has full control (usually via RC or joystick in simulator). The client must make this call to request control via API. It is likely that human operator of vehicle might have disallowed API control which would mean that enableApiControl has no effect. This can be checked by isApiControlEnabled . isApiControlEnabled : Returns true if API control is established. If false (which is default) then API calls would be ignored. After a successful call to enableApiControl , the isApiControlEnabled should return true. ping : If connection is established then this call will return true otherwise it will be blocked until timeout. simPrintLogMessage : Prints the specified message in the simulator's window. If message_param is also supplied then its printed next to the message and in that case if this API is called with same message value but different message_param again then previous line is overwritten with new line (instead of API creating new line on display). For example, simPrintLogMessage(\"Iteration: \", to_string(i)) keeps updating same line on display when API is called with different values of i. The valid values of severity parameter is 0 to 3 inclusive that corresponds to different colors. simGetObjectPose , simSetObjectPose : Gets and sets the pose of specified object in Unreal environment. Here the object means \"actor\" in Unreal terminology. They are searched by tag as well as name. Please note that the names shown in UE Editor are auto-generated in each run and are not permanent. So if you want to refer to actor by name, you must change its auto-generated name in UE Editor. Alternatively you can add a tag to actor which can be done by clicking on that actor in Unreal Editor and then going to Tags property , click \"+\" sign and add some string value. If multiple actors have same tag then the first match is returned. If no matches are found then NaN pose is returned. The returned pose is in NED coordinates in SI units with its origin at Player Start. For simSetObjectPose , the specified actor must have Mobility set to Movable or otherwise you will get undefined behavior. The simSetObjectPose has parameter teleport which means object is moved through other objects in its way and it returns true if move was successful","title":"Common APIs"},{"location":"docs/apis/#image-computer-vision-apis","text":"AirSim offers comprehensive images APIs to retrieve synchronized images from multiple cameras along with ground truth including depth, disparity, surface normals and vision. You can set the resolution, FOV, motion blur etc parameters in settings.json . There is also API for detecting collision state. See also complete code that generates specified number of stereo images and ground truth depth with normalization to camera plan, computation of disparity image and saving it to pfm format . More on image APIs and Computer Vision mode .","title":"Image / Computer Vision APIs"},{"location":"docs/apis/#pause-and-continue-apis","text":"AirSim allows to pause and continue the simulation through pause(is_paused) API. To pause the simulation call pause(True) and to continue the simulation call pause(False) . You may have scenario, especially while using reinforcement learning, to run the simulation for specified amount of time and then automatically pause. While simulation is paused, you may then do some expensive computation, send a new command and then again run the simulation for specified amount of time. This can be achieved by API continueForTime(seconds) . This API runs the simulation for the specified number of seconds and then pauses the simulation. For example usage, please see pause_continue_car.py and pause_continue_drone.py .","title":"Pause and Continue APIs"},{"location":"docs/apis/#collision-api","text":"The collision information can be obtained using simGetCollisionInfo API. This call returns a struct that has information not only whether collision occurred but also collision position, surface normal, penetration depth and so on.","title":"Collision API"},{"location":"docs/apis/#multiple-vehicles","text":"AirSim supports multiple vehicles and control them through APIs. Please Multiple Vehicles doc.","title":"Multiple Vehicles"},{"location":"docs/apis/#coordinate-system","text":"All AirSim API uses NED coordinate system, i.e., +X is North, +Y is East and +Z is Down. All units are in SI system. Please note that this is different from coordinate system used internally by Unreal Engine. In Unreal Engine, +Z is up instead of down and length unit is in centimeters instead of meters. AirSim APIs takes care of the appropriate conversions. The starting point of the vehicle is always coordinates (0, 0, 0) in NED system. Thus when converting from Unreal coordinates to NED, we first subtract the starting offset and then scale by 100 for cm to m conversion. The vehicle is spawned in Unreal environment where the Player Start component is placed. There is a setting called OriginGeopoint in settings.json which assigns geographic longitude, longitude and altitude to the Player Start component.","title":"Coordinate System"},{"location":"docs/apis/#vehicle-specific-apis","text":"","title":"Vehicle Specific APIs"},{"location":"docs/apis/#apis-for-car","text":"Car has followings APIs available: setCarControls : This allows you to set throttle, steering, handbrake and auto or manual gear. getCarState : This retrieves the state information including speed, current gear and 6 kinematics quantities: position, orientation, linear and angular velocity, linear and angular acceleration. All quantities are in NED coordinate system, SI units in world frame except for angular velocity and accelerations which are in body frame. Image APIs .","title":"APIs for Car"},{"location":"docs/apis/#apis-for-multirotor","text":"Multirotor can be controlled by specifying angles, velocity vector, destination position or some combination of these. There are corresponding move* APIs for this purpose. When doing position control, we need to use some path following algorithm. By default AirSim uses carrot following algorithm. This is often referred to as \"high level control\" because you just need to specify high level goal and the firmware takes care of the rest. Currently lowest level control available in AirSim is moveByAngleThrottleAsync API.","title":"APIs for Multirotor"},{"location":"docs/apis/#getmultirotorstate","text":"This API returns the state of the vehicle in one call. The state includes, collision, estimated kinematics (i.e. kinematics computed by fusing sensors), and timestamp (nano seconds since epoch). The kinematics here means 6 quantities: position, orientation, linear and angular velocity, linear and angular acceleration. Please note that simple_slight currently doesn't support state estimator which means estimated and ground truth kinematics values would be same for simple_flight. Estimated kinematics are however available for PX4 except for angular acceleration. All quantities are in NED coordinate system, SI units in world frame except for angular velocity and accelerations which are in body frame.","title":"getMultirotorState"},{"location":"docs/apis/#async-methods-duration-and-max_wait_seconds","text":"Many API methods has parameters named duration or max_wait_seconds and they have Async as suffix, for example, takeoffAsync . These methods will return immediately after starting the task in AirSim so that your client code can do something else while that task is being executed. If you want to wait for this task to complete then you can call waitOnLastTask like this: //C++ client.takeoffAsync()->waitOnLastTask(); # Python client.takeoffAsync().join() If you start another command then it automatically cancels the previous task and starts new command. This allows to use pattern where your coded continuously does the sensing, computes a new trajectory to follow and issues that path to vehicle in AirSim. Each newly issued trajectory cancels the previous trajectory allowing your code to continuously do the update as new sensor data arrives. All Async method returns concurrent.futures.Future in Python ( std::future in C++). Please note that these future classes currently do not allow to check status or cancel the task; they only allow to wait for task to complete. AirSim does provide API cancelLastTask , however.","title":"Async methods, duration and max_wait_seconds"},{"location":"docs/apis/#drivetrain","text":"There are two modes you can fly vehicle: drivetrain parameter is set to airsim.Drivetrain.ForwardOnly or airsim.Drivetrain.MaxDegreeOfFreedom . When you specify ForwardOnly, you are saying that vehicle's front should always point in the direction of travel. So if you want drone to take left turn then it would first rotate so front points to left. This mode is useful when you have only front camera and you are operating vehicle using FPV view. This is more or less like travelling in car where you always have front view. The MaxDegreeOfFreedom means you don't care where the front points to. So when you take left turn, you just start going left like crab. Quadrotors can go in any direction regardless of where front points to. The MaxDegreeOfFreedom enables this mode.","title":"drivetrain"},{"location":"docs/apis/#yaw_mode","text":"yaw_mode is a struct YawMode with two fields, yaw_or_rate and is_rate . If is_rate field is True then yaw_or_rate field is interpreted as angular velocity in degrees/sec which means you want vehicle to rotate continuously around its axis at that angular velocity while moving. If is_rate is False then yaw_or_rate is interpreted as angle in degrees which means you want vehicle to rotate to specific angle (i.e. yaw) and keep that angle while moving. You can probably see that when yaw_mode.is_rate == true , the drivetrain parameter shouldn't be set to ForwardOnly because you are contradicting by saying that keep front pointing ahead but also rotate continuously. However if you have yaw_mode.is_rate = false in ForwardOnly mode then you can do some funky stuff. For example, you can have drone do circles and have yaw_or_rate set to 90 so camera is always pointed to center (\"super cool selfie mode\"). In MaxDegreeofFreedom also you can get some funky stuff by setting yaw_mode.is_rate = true and say yaw_mode.yaw_or_rate = 20 . This will cause drone to go in its path while rotating which may allow to do 360 scanning. In most cases, you just don't want yaw to change which you can do by setting yaw rate of 0. The shorthand for this is airsim.YawMode.Zero() (or in C++: YawMode::Zero() ).","title":"yaw_mode"},{"location":"docs/apis/#lookahead-and-adaptive_lookahead","text":"When you ask vehicle to follow a path, AirSim uses \"carrot following\" algorithm. This algorithm operates by looking ahead on path and adjusting its velocity vector. The parameters for this algorithm is specified by lookahead and adaptive_lookahead . For most of the time you want algorithm to auto-decide the values by simply setting lookahead = -1 and adaptive_lookahead = 0 .","title":"lookahead and adaptive_lookahead"},{"location":"docs/apis/#using-apis-on-real-vehicles","text":"We want to be able to run same code that runs in simulation as on real vehicle. This allows you to test your code in simulator and deploy to real vehicle. Generally speaking, APIs therefore shouldn't allow you to do something that cannot be done on real vehicle (for example, getting the ground truth). But, of course, simulator has much more information and it would be useful in applications that may not care about running things on real vehicle. For this reason, we clearly delineate between sim-only APIs by attaching sim prefix, for example, simGetGroundTruthKinematics . This way you can avoid using these simulation-only APIs if you care about running your code on real vehicles. The AirLib is self-contained library that you can put on an offboard computing module such as the Gigabyte barebone Mini PC. This module then can talk to the flight controllers such as PX4 using exact same code and flight controller protocol. The code you write for testing in the simulator remains unchanged. See AirLib on custom drones .","title":"Using APIs on Real Vehicles"},{"location":"docs/apis/#adding-new-apis-to-airsim","text":"Adding new APIs requires modifying the source code. Much of the changes are mechanical and required for various levels of abstractions that AirSim supports. This commit demonstrates how to add a simple API simPrintLogMessage that prints message in simulator window.","title":"Adding New APIs to AirSim"},{"location":"docs/apis/#some-internals","text":"The APIs use msgpack-rpc protocol over TCP/IP through rpclib developed by Tam\u00e1s Szelei which allows you to use variety of programming languages including C++, C#, Python, Java etc. When AirSim starts, it opens port 41451 (this can be changed via settings ) and listens for incoming request. The Python or C++ client code connects to this port and sends RPC calls using msgpack serialization format .","title":"Some Internals"},{"location":"docs/apis/#references-and-examples","text":"C++ API Examples Car Examples Multirotor Examples Computer Vision Examples Move on Path demo showing video of fast multirotor flight through Modular Neighborhood environment Building a Hexacopter Building Point Clouds","title":"References and Examples"},{"location":"docs/apis/#faq","text":"","title":"FAQ"},{"location":"docs/apis/#unreal-is-slowed-down-dramatically-when-i-run-api","text":"If you see Unreal getting slowed down dramatically when Unreal Engine window loses focus then go to 'Edit->Editor Preferences' in Unreal Editor, in the 'Search' box type 'CPU' and ensure that the 'Use Less CPU when in Background' is unchecked.","title":"Unreal is slowed down dramatically when I run API"},{"location":"docs/apis/#do-i-need-anything-else-on-windows","text":"You should install VS2017 with VC++, Windows SDK 8.1 and Python. To use Python APIs you will need Python 3.5 or later (install it using Anaconda).","title":"Do I need anything else on Windows?"},{"location":"docs/apis/#which-version-of-python-should-i-use","text":"We recommend Anaconda to get Python tools and libraries. Our code is tested with Python 3.5.3 :: Anaconda 4.4.0. This is important because older version have been known to have problems .","title":"Which version of Python should I use?"},{"location":"docs/apis/#i-get-error-on-import-cv2","text":"You can install OpenCV using: conda install opencv pip install opencv-python","title":"I get error on import cv2"},{"location":"docs/apis_cpp/","text":"Using C++ APIs for AirSim Please read general API doc first if you haven't already. This document describes C++ examples and other C++ specific details. Quick Start Fastest way to get started is to open AirSim.sln in Visual Studio 2017. You will see Hello Car and Hello Drone examples in the solution. These examples will show you the include paths and lib paths you will need to setup in your VC++ projects. If you are using Linux then you will specify these paths either in your cmake file or on compiler command line. Include and Lib Folders Include folders: $(ProjectDir)..\\AirLib\\deps\\rpclib\\include;include;$(ProjectDir)..\\AirLib\\deps\\eigen3;$(ProjectDir)..\\AirLib\\include Dependencies: rpc.lib Lib folders: $(ProjectDir)\\..\\AirLib\\deps\\MavLinkCom\\lib\\$(Platform)\\$(Configuration);$(ProjectDir)\\..\\AirLib\\deps\\rpclib\\lib\\$(Platform)\\$(Configuration);$(ProjectDir)\\..\\AirLib\\lib\\$(Platform)\\$(Configuration) Hello Car Here's how to use AirSim APIs using Python to control simulated car (see also Python example ): // ready to run example: https://github.com/Microsoft/AirSim/blob/master/HelloCar/main.cpp #include <iostream> #include \"vehicles/car/api/CarRpcLibClient.hpp\" int main() { msr::airlib::CarRpcLibClient client; client.enableApiControl(true); //this disables manual control CarControllerBase::CarControls controls; std::cout << \"Press enter to drive forward\" << std::endl; std::cin.get(); controls.throttle = 1; client.setCarControls(controls); std::cout << \"Press Enter to activate handbrake\" << std::endl; std::cin.get(); controls.handbrake = true; client.setCarControls(controls); std::cout << \"Press Enter to take turn and drive backward\" << std::endl; std::cin.get(); controls.handbrake = false; controls.throttle = -1; controls.steering = 1; client.setCarControls(controls); std::cout << \"Press Enter to stop\" << std::endl; std::cin.get(); client.setCarControls(CarControllerBase::CarControls()); return 0; } Hello Drone Here's how to use AirSim APIs using Python to control simulated car (see also Python example ): // ready to run example: https://github.com/Microsoft/AirSim/blob/master/HelloDrone/main.cpp #include <iostream> #include \"vehicles/multirotor/api/MultirotorRpcLibClient.hpp\" int main() { using namespace std; msr::airlib::MultirotorRpcLibClient client; cout << \"Press Enter to enable API control\" << endl; cin.get(); client.enableApiControl(true); cout << \"Press Enter to arm the drone\" << endl; cin.get(); client.armDisarm(true); cout << \"Press Enter to takeoff\" << endl; cin.get(); client.takeoffAsync(5)->waitOnLastTask(); cout << \"Press Enter to move 5 meters in x direction with 1 m/s velocity\" << endl; cin.get(); auto position = client.getPosition(); // from current location client.moveToPositionAsync(position.x() + 5, position.y(), position.z(), 1)->waitOnLastTask(); cout << \"Press Enter to land\" << endl; cin.get(); client.landAync()->waitOnLastTask(); return 0; } See Also Examples of how to use internal infrastructure in AirSim in your other projects DroneShell app shows how to make simple interface using C++ APIs to control drones Python APIs","title":"C++ APIs"},{"location":"docs/apis_cpp/#using-c-apis-for-airsim","text":"Please read general API doc first if you haven't already. This document describes C++ examples and other C++ specific details.","title":"Using C++ APIs for AirSim"},{"location":"docs/apis_cpp/#quick-start","text":"Fastest way to get started is to open AirSim.sln in Visual Studio 2017. You will see Hello Car and Hello Drone examples in the solution. These examples will show you the include paths and lib paths you will need to setup in your VC++ projects. If you are using Linux then you will specify these paths either in your cmake file or on compiler command line.","title":"Quick Start"},{"location":"docs/apis_cpp/#include-and-lib-folders","text":"Include folders: $(ProjectDir)..\\AirLib\\deps\\rpclib\\include;include;$(ProjectDir)..\\AirLib\\deps\\eigen3;$(ProjectDir)..\\AirLib\\include Dependencies: rpc.lib Lib folders: $(ProjectDir)\\..\\AirLib\\deps\\MavLinkCom\\lib\\$(Platform)\\$(Configuration);$(ProjectDir)\\..\\AirLib\\deps\\rpclib\\lib\\$(Platform)\\$(Configuration);$(ProjectDir)\\..\\AirLib\\lib\\$(Platform)\\$(Configuration)","title":"Include and Lib Folders"},{"location":"docs/apis_cpp/#hello-car","text":"Here's how to use AirSim APIs using Python to control simulated car (see also Python example ): // ready to run example: https://github.com/Microsoft/AirSim/blob/master/HelloCar/main.cpp #include <iostream> #include \"vehicles/car/api/CarRpcLibClient.hpp\" int main() { msr::airlib::CarRpcLibClient client; client.enableApiControl(true); //this disables manual control CarControllerBase::CarControls controls; std::cout << \"Press enter to drive forward\" << std::endl; std::cin.get(); controls.throttle = 1; client.setCarControls(controls); std::cout << \"Press Enter to activate handbrake\" << std::endl; std::cin.get(); controls.handbrake = true; client.setCarControls(controls); std::cout << \"Press Enter to take turn and drive backward\" << std::endl; std::cin.get(); controls.handbrake = false; controls.throttle = -1; controls.steering = 1; client.setCarControls(controls); std::cout << \"Press Enter to stop\" << std::endl; std::cin.get(); client.setCarControls(CarControllerBase::CarControls()); return 0; }","title":"Hello Car"},{"location":"docs/apis_cpp/#hello-drone","text":"Here's how to use AirSim APIs using Python to control simulated car (see also Python example ): // ready to run example: https://github.com/Microsoft/AirSim/blob/master/HelloDrone/main.cpp #include <iostream> #include \"vehicles/multirotor/api/MultirotorRpcLibClient.hpp\" int main() { using namespace std; msr::airlib::MultirotorRpcLibClient client; cout << \"Press Enter to enable API control\" << endl; cin.get(); client.enableApiControl(true); cout << \"Press Enter to arm the drone\" << endl; cin.get(); client.armDisarm(true); cout << \"Press Enter to takeoff\" << endl; cin.get(); client.takeoffAsync(5)->waitOnLastTask(); cout << \"Press Enter to move 5 meters in x direction with 1 m/s velocity\" << endl; cin.get(); auto position = client.getPosition(); // from current location client.moveToPositionAsync(position.x() + 5, position.y(), position.z(), 1)->waitOnLastTask(); cout << \"Press Enter to land\" << endl; cin.get(); client.landAync()->waitOnLastTask(); return 0; }","title":"Hello Drone"},{"location":"docs/apis_cpp/#see-also","text":"Examples of how to use internal infrastructure in AirSim in your other projects DroneShell app shows how to make simple interface using C++ APIs to control drones Python APIs","title":"See Also"},{"location":"docs/build_linux/","text":"Build AirSim on Linux The current recommended and tested environment is Ubuntu 16.04 LTS . Theoretically, you can build on other distros and OSX as well, but we haven't tested it. Install and Build It's super simple: 1-2-3! Make sure you are registered with Epic Games . This is required to get source code access for Unreal Engine. Clone Unreal in your favorite folder and build it (this may take a while!). Note : We only support Unreal 4.18 at present. bash # go to the folder where you clone GitHub projects git clone -b 4.18 https://github.com/EpicGames/UnrealEngine.git cd UnrealEngine ./Setup.sh ./GenerateProjectFiles.sh make Clone AirSim and build it: bash # go to the folder where you clone GitHub projects git clone https://github.com/Microsoft/AirSim.git cd AirSim ./setup.sh ./build.sh Build Unreal Environment Finally, you will need an Unreal project that hosts the environment for your vehicles. AirSim comes with a built-in \"Blocks Environment\" which you can use, or you can create your own. Please see setting up Unreal Environment . Setup Remote Control (Multirotor Only) A remote control is required if you want to fly manually. See the remote control setup for more details. Alternatively, you can use APIs for programmatic control or use the so-called Computer Vision mode to move around using the keyboard. How to Use AirSim Once AirSim is set up by following above steps, you can, Go to UnrealEngine folder and start Unreal by running UnrealEngine/Engine/Binaries/Linux/UE4Editor . When Unreal Engine prompts for opening or creating project, select Browse and choose AirSim/Unreal/Environments/Blocks (or your custom Unreal project). If you get prompts to convert project, look for More Options or Convert-In-Place option. If you get prompted to build, chose Yes. If you get prompted to disable AirSim plugin, choose No. After Unreal Editor loads, press Play button. Tip: go to 'Edit->Editor Preferences', in the 'Search' box type 'CPU' and ensure that the 'Use Less CPU when in Background' is unchecked. See Using APIs and settings.json for various options available. FAQ I'm getting error \" could not be compiled. Try rebuilding from source manually\". This could either happen because of compile error or the fact that your gch files are outdated. Look in to your console window. Do you see something like below? fatal errorfatal error: : file '/usr/include/linux/version.h''/usr/include/linux/version.h' has been modified since the precompiled header If this is the case then look for *.gch file(s) that follows after that message, delete them and try again. Here's relevant thread on Unreal Engine forums. If you see other compile errors in console then open up those source files and see if it is due to changes you made. If not, then report it as issue on GitHub. Unreal crashed! How do I know what went wrong? Go to the MyUnrealProject/Saved/Crashes folder and search for the file MyProject.log within its subdirectories. At the end of this file you will see the stack trace and messages. You can also take a look at the Diagnostics.txt file. How do I use an IDE on Linux? You can use Qt Creator or CodeLite. Instructions for Qt Creator are available here . Can I cross compile for Linux from a Windows machine? Yes, you can, but we haven't tested it. You can find the instructions here . What compiler and stdlib does AirSim use? We use the same compiler that Unreal Engine uses, Clang 5.0 , and stdlib, libc++ . AirSim's setup.sh will automatically download them both. The libc++ source code is cloned into the llvm-source-(version) folder and is built into the llvm-build folder, from where CMake uses libc++. What version of CMake does the AirSim build use? 3.9.0 or higher. This is not the default in Ubuntu 16.04 so setup.sh installs it for you. You can check your CMake version using cmake --version . If you have an older version, follow these instructions or see the CMake website . Can I compile AirSim in BashOnWindows? Yes, however, you can't run Unreal from BashOnWindows. So this is kind of useful to check a Linux compile, but not for an end-to-end run. See the BashOnWindows install guide . Make sure to have the latest version (Windows 10 Creators Edition) as previous versions had various issues. Also, don't invoke bash from Visual Studio Command Prompt , otherwise CMake might find VC++ and try and use that! Where can I find more info on running Unreal on Linux? Start here: Unreal on Linux Building Unreal on Linux Unreal Linux Support Unreal Cross Compilation","title":"Build on Linux"},{"location":"docs/build_linux/#build-airsim-on-linux","text":"The current recommended and tested environment is Ubuntu 16.04 LTS . Theoretically, you can build on other distros and OSX as well, but we haven't tested it.","title":"Build AirSim on Linux"},{"location":"docs/build_linux/#install-and-build","text":"It's super simple: 1-2-3! Make sure you are registered with Epic Games . This is required to get source code access for Unreal Engine. Clone Unreal in your favorite folder and build it (this may take a while!). Note : We only support Unreal 4.18 at present. bash # go to the folder where you clone GitHub projects git clone -b 4.18 https://github.com/EpicGames/UnrealEngine.git cd UnrealEngine ./Setup.sh ./GenerateProjectFiles.sh make Clone AirSim and build it: bash # go to the folder where you clone GitHub projects git clone https://github.com/Microsoft/AirSim.git cd AirSim ./setup.sh ./build.sh","title":"Install and Build"},{"location":"docs/build_linux/#build-unreal-environment","text":"Finally, you will need an Unreal project that hosts the environment for your vehicles. AirSim comes with a built-in \"Blocks Environment\" which you can use, or you can create your own. Please see setting up Unreal Environment .","title":"Build Unreal Environment"},{"location":"docs/build_linux/#setup-remote-control-multirotor-only","text":"A remote control is required if you want to fly manually. See the remote control setup for more details. Alternatively, you can use APIs for programmatic control or use the so-called Computer Vision mode to move around using the keyboard.","title":"Setup Remote Control (Multirotor Only)"},{"location":"docs/build_linux/#how-to-use-airsim","text":"Once AirSim is set up by following above steps, you can, Go to UnrealEngine folder and start Unreal by running UnrealEngine/Engine/Binaries/Linux/UE4Editor . When Unreal Engine prompts for opening or creating project, select Browse and choose AirSim/Unreal/Environments/Blocks (or your custom Unreal project). If you get prompts to convert project, look for More Options or Convert-In-Place option. If you get prompted to build, chose Yes. If you get prompted to disable AirSim plugin, choose No. After Unreal Editor loads, press Play button. Tip: go to 'Edit->Editor Preferences', in the 'Search' box type 'CPU' and ensure that the 'Use Less CPU when in Background' is unchecked. See Using APIs and settings.json for various options available.","title":"How to Use AirSim"},{"location":"docs/build_linux/#faq","text":"","title":"FAQ"},{"location":"docs/build_linux/#im-getting-error-could-not-be-compiled-try-rebuilding-from-source-manually","text":"This could either happen because of compile error or the fact that your gch files are outdated. Look in to your console window. Do you see something like below? fatal errorfatal error: : file '/usr/include/linux/version.h''/usr/include/linux/version.h' has been modified since the precompiled header If this is the case then look for *.gch file(s) that follows after that message, delete them and try again. Here's relevant thread on Unreal Engine forums. If you see other compile errors in console then open up those source files and see if it is due to changes you made. If not, then report it as issue on GitHub.","title":"I'm getting error \" could not be compiled. Try rebuilding from source manually\"."},{"location":"docs/build_linux/#unreal-crashed-how-do-i-know-what-went-wrong","text":"Go to the MyUnrealProject/Saved/Crashes folder and search for the file MyProject.log within its subdirectories. At the end of this file you will see the stack trace and messages. You can also take a look at the Diagnostics.txt file.","title":"Unreal crashed! How do I know what went wrong?"},{"location":"docs/build_linux/#how-do-i-use-an-ide-on-linux","text":"You can use Qt Creator or CodeLite. Instructions for Qt Creator are available here .","title":"How do I use an IDE on Linux?"},{"location":"docs/build_linux/#can-i-cross-compile-for-linux-from-a-windows-machine","text":"Yes, you can, but we haven't tested it. You can find the instructions here .","title":"Can I cross compile for Linux from a Windows machine?"},{"location":"docs/build_linux/#what-compiler-and-stdlib-does-airsim-use","text":"We use the same compiler that Unreal Engine uses, Clang 5.0 , and stdlib, libc++ . AirSim's setup.sh will automatically download them both. The libc++ source code is cloned into the llvm-source-(version) folder and is built into the llvm-build folder, from where CMake uses libc++.","title":"What compiler and stdlib does AirSim use?"},{"location":"docs/build_linux/#what-version-of-cmake-does-the-airsim-build-use","text":"3.9.0 or higher. This is not the default in Ubuntu 16.04 so setup.sh installs it for you. You can check your CMake version using cmake --version . If you have an older version, follow these instructions or see the CMake website .","title":"What version of CMake does the AirSim build use?"},{"location":"docs/build_linux/#can-i-compile-airsim-in-bashonwindows","text":"Yes, however, you can't run Unreal from BashOnWindows. So this is kind of useful to check a Linux compile, but not for an end-to-end run. See the BashOnWindows install guide . Make sure to have the latest version (Windows 10 Creators Edition) as previous versions had various issues. Also, don't invoke bash from Visual Studio Command Prompt , otherwise CMake might find VC++ and try and use that!","title":"Can I compile AirSim in BashOnWindows?"},{"location":"docs/build_linux/#where-can-i-find-more-info-on-running-unreal-on-linux","text":"Start here: Unreal on Linux Building Unreal on Linux Unreal Linux Support Unreal Cross Compilation","title":"Where can I find more info on running Unreal on Linux?"},{"location":"docs/build_windows/","text":"Build AirSim on Windows Install Unreal Engine Download the Epic Games Launcher. While the Unreal Engine is open source and free to download, registration is still required. Run the Epic Games Launcher, open the Library tab from left, click on the \"Add Versions\" which should show the option to download Unreal 4.18 as shown below. If you have multiple versions of Unreal installed then make sure 4.18 is \"Current\" by clicking down arrow next to the Launch button for the version. Note : If you have UE 4.16 or older projects, please see the upgrade guide to upgrade your projects. Build AirSim You will need Visual Studio 2017 ( make sure to install VC++ and Windows SDK 8.x). Start x64 Native Tools Command Prompt for VS 2017 . Create a folder for the repo and run git clone https://github.com/Microsoft/AirSim.git . Run build.cmd from the command line. This will create ready to use plugin bits in the Unreal\\Plugins folder that can be dropped into any Unreal project. Build Unreal Project Finally, you will need an Unreal project that hosts the environment for your vehicles. AirSim comes with a built-in \"Blocks Environment\" which you can use, or you can create your own. Please see setting up Unreal Environment . Setup Remote Control (Multirotor only) A remote control is required if you want to fly manually. See the remote control setup for more details. Alternatively, you can use APIs for programmatic control or use the so-called Computer Vision mode to move around using the keyboard. How to Use AirSim Once AirSim is set up by following above steps, you can, Double click on .sln file to load the Blocks project in Unreal\\Environments\\Blocks (or .sln file in your own custom Unreal project). If you don't see .sln file then you probably haven't completed steps in Build Unreal Project section above. Select your Unreal project as Start Up project (for example, Blocks project) and make sure Build config is set to \"Develop Editor\" and x64. After Unreal Editor loads, press Play button. Tip: go to 'Edit->Editor Preferences', in the 'Search' box type 'CPU' and ensure that the 'Use Less CPU when in Background' is unchecked. See Using APIs and settings.json for various options available. FAQ I get error \"'corecrt.h': No such file or directory\" or \"Windows SDK version 8.1 not found\" Very likely you don't have Windows SDK installed with Visual Studio. How do I use PX4 firmware with AirSim? By default, AirSim uses its own built-in firmware called simple_flight . There is no additional setup if you just want to go with it. If you want to switch to using PX4 instead then please see this guide . I made changes in Visual Studio but there is no effect Sometimes the Unreal + VS build system doesn't recompile if you make changes to only header files. To ensure a recompile, make some Unreal based cpp file \"dirty\" like AirSimGameMode.cpp. Unreal still uses VS2015 or I'm getting some link error Running several versions of VS can lead to issues when compiling UE projects. One problem that may arise is that UE will try to compile with an older version of VS which may or may not work. There are two settings in Unreal, one for for the engine and one for the project, to adjust the version of VS to be used. 1. Edit -> Editor preferences -> General -> Source code 2. Edit -> Project Settings -> Platforms -> Windows -> Toolchain ->CompilerVersion In some cases, these settings will still not lead to the desired result and errors such as the following might be produced: LINK : fatal error LNK1181: cannot open input file 'ws2_32.lib' To resolve such issues the following procedure can be applied: 1. Uninstall all old versions of VS using the VisualStudioUninstaller 2. Repair/Install VS2017 3. Restart machine and install Epic launcher and desired version of the engine","title":"Build on Windows"},{"location":"docs/build_windows/#build-airsim-on-windows","text":"","title":"Build AirSim on Windows"},{"location":"docs/build_windows/#install-unreal-engine","text":"Download the Epic Games Launcher. While the Unreal Engine is open source and free to download, registration is still required. Run the Epic Games Launcher, open the Library tab from left, click on the \"Add Versions\" which should show the option to download Unreal 4.18 as shown below. If you have multiple versions of Unreal installed then make sure 4.18 is \"Current\" by clicking down arrow next to the Launch button for the version. Note : If you have UE 4.16 or older projects, please see the upgrade guide to upgrade your projects.","title":"Install Unreal Engine"},{"location":"docs/build_windows/#build-airsim","text":"You will need Visual Studio 2017 ( make sure to install VC++ and Windows SDK 8.x). Start x64 Native Tools Command Prompt for VS 2017 . Create a folder for the repo and run git clone https://github.com/Microsoft/AirSim.git . Run build.cmd from the command line. This will create ready to use plugin bits in the Unreal\\Plugins folder that can be dropped into any Unreal project.","title":"Build AirSim"},{"location":"docs/build_windows/#build-unreal-project","text":"Finally, you will need an Unreal project that hosts the environment for your vehicles. AirSim comes with a built-in \"Blocks Environment\" which you can use, or you can create your own. Please see setting up Unreal Environment .","title":"Build Unreal Project"},{"location":"docs/build_windows/#setup-remote-control-multirotor-only","text":"A remote control is required if you want to fly manually. See the remote control setup for more details. Alternatively, you can use APIs for programmatic control or use the so-called Computer Vision mode to move around using the keyboard.","title":"Setup Remote Control (Multirotor only)"},{"location":"docs/build_windows/#how-to-use-airsim","text":"Once AirSim is set up by following above steps, you can, Double click on .sln file to load the Blocks project in Unreal\\Environments\\Blocks (or .sln file in your own custom Unreal project). If you don't see .sln file then you probably haven't completed steps in Build Unreal Project section above. Select your Unreal project as Start Up project (for example, Blocks project) and make sure Build config is set to \"Develop Editor\" and x64. After Unreal Editor loads, press Play button. Tip: go to 'Edit->Editor Preferences', in the 'Search' box type 'CPU' and ensure that the 'Use Less CPU when in Background' is unchecked. See Using APIs and settings.json for various options available.","title":"How to Use AirSim"},{"location":"docs/build_windows/#faq","text":"","title":"FAQ"},{"location":"docs/build_windows/#i-get-error-corecrth-no-such-file-or-directory-or-windows-sdk-version-81-not-found","text":"Very likely you don't have Windows SDK installed with Visual Studio.","title":"I get error \"'corecrt.h': No such file or directory\" or \"Windows SDK version 8.1 not found\""},{"location":"docs/build_windows/#how-do-i-use-px4-firmware-with-airsim","text":"By default, AirSim uses its own built-in firmware called simple_flight . There is no additional setup if you just want to go with it. If you want to switch to using PX4 instead then please see this guide .","title":"How do I use PX4 firmware with AirSim?"},{"location":"docs/build_windows/#i-made-changes-in-visual-studio-but-there-is-no-effect","text":"Sometimes the Unreal + VS build system doesn't recompile if you make changes to only header files. To ensure a recompile, make some Unreal based cpp file \"dirty\" like AirSimGameMode.cpp.","title":"I made changes in Visual Studio but there is no effect"},{"location":"docs/build_windows/#unreal-still-uses-vs2015-or-im-getting-some-link-error","text":"Running several versions of VS can lead to issues when compiling UE projects. One problem that may arise is that UE will try to compile with an older version of VS which may or may not work. There are two settings in Unreal, one for for the engine and one for the project, to adjust the version of VS to be used. 1. Edit -> Editor preferences -> General -> Source code 2. Edit -> Project Settings -> Platforms -> Windows -> Toolchain ->CompilerVersion In some cases, these settings will still not lead to the desired result and errors such as the following might be produced: LINK : fatal error LNK1181: cannot open input file 'ws2_32.lib' To resolve such issues the following procedure can be applied: 1. Uninstall all old versions of VS using the VisualStudioUninstaller 2. Repair/Install VS2017 3. Restart machine and install Epic launcher and desired version of the engine","title":"Unreal still uses VS2015 or I'm getting some link error"},{"location":"docs/camera_views/","text":"Camera Views The camera views that are shown on screen are the camera views you can fetch via the simGetImages API . From left to right is the depth view, segmentation view and the FPV view. See Image APIs for description of various available views. Turning ON/OFF Views Press F1 key to see keyboard shortcuts for turning on/off any or all views. You can also select various view modes there, such as \"Fly with Me\" mode, FPV mode and \"Ground View\" mode. Configuring Sub-Windows Now you can select what is shown by each of above sub windows. For instance, you can chose to show surface normals in first window (instead of depth) and disparity in second window (instead of segmentation). Below is the settings value you can use in settings.json : { \"SubWindows\": [ {\"Index\": 1, \"ImageType\": 5}, {\"Index\": 2, \"ImageType\": 3} ] } Performance Impact Note : This section is outdated and has not been updated for new performance enhancement changes. Now rendering these views does impact the FPS performance of the game, since this is additional work for the GPU. The following shows the impact on FPS when you open these views. This is measured on Intel core i7 computer with 32 gb RAM and a GeForce GTX 1080 graphics card running the Modular Neighborhood map, using cooked debug bits, no debugger or GameEditor open. The normal state with no subviews open is measuring around 16 ms per frame, which means it is keeping a nice steady 60 FPS (which is the target FPS). As it climbs up to 35ms the FPS drops to around 28 frames per second, spiking to 40ms means a few drops to 25 fps. The simulator can still function and fly correctly when all this is going on even in the worse case because the physics is decoupled from the rendering. However if the delay gets too high such that the communication with PX4 hardware is interrupted due to overly busy CPU then the flight can stall due to timeout in the offboard control messages. On the computer where this was measured the drone could fly the path.py program without any problems with all views open, and with 3 python scripts running to capture each view type. But there was one stall during this flight, but it recovered gracefully and completed the path. So it was right on the limit. The following shows the impact on CPU, perhaps a bit surprisingly, the CPU impact is also non trivial.","title":"Camera Views"},{"location":"docs/camera_views/#camera-views","text":"The camera views that are shown on screen are the camera views you can fetch via the simGetImages API . From left to right is the depth view, segmentation view and the FPV view. See Image APIs for description of various available views.","title":"Camera Views"},{"location":"docs/camera_views/#turning-onoff-views","text":"Press F1 key to see keyboard shortcuts for turning on/off any or all views. You can also select various view modes there, such as \"Fly with Me\" mode, FPV mode and \"Ground View\" mode.","title":"Turning ON/OFF Views"},{"location":"docs/camera_views/#configuring-sub-windows","text":"Now you can select what is shown by each of above sub windows. For instance, you can chose to show surface normals in first window (instead of depth) and disparity in second window (instead of segmentation). Below is the settings value you can use in settings.json : { \"SubWindows\": [ {\"Index\": 1, \"ImageType\": 5}, {\"Index\": 2, \"ImageType\": 3} ] }","title":"Configuring Sub-Windows"},{"location":"docs/camera_views/#performance-impact","text":"Note : This section is outdated and has not been updated for new performance enhancement changes. Now rendering these views does impact the FPS performance of the game, since this is additional work for the GPU. The following shows the impact on FPS when you open these views. This is measured on Intel core i7 computer with 32 gb RAM and a GeForce GTX 1080 graphics card running the Modular Neighborhood map, using cooked debug bits, no debugger or GameEditor open. The normal state with no subviews open is measuring around 16 ms per frame, which means it is keeping a nice steady 60 FPS (which is the target FPS). As it climbs up to 35ms the FPS drops to around 28 frames per second, spiking to 40ms means a few drops to 25 fps. The simulator can still function and fly correctly when all this is going on even in the worse case because the physics is decoupled from the rendering. However if the delay gets too high such that the communication with PX4 hardware is interrupted due to overly busy CPU then the flight can stall due to timeout in the offboard control messages. On the computer where this was measured the drone could fly the path.py program without any problems with all views open, and with 3 python scripts running to capture each view type. But there was one stall during this flight, but it recovered gracefully and completed the path. So it was right on the limit. The following shows the impact on CPU, perhaps a bit surprisingly, the CPU impact is also non trivial.","title":"Performance Impact"},{"location":"docs/cmake_linux/","text":"Installing cmake on Linux If you don't have cmake version 3.10 (for example, 3.2.2 is the default on Ubuntu 14) you can run the following: mkdir ~/cmake-3.10.2 cd ~/cmake-3.10.2 wget https://cmake.org/files/v3.10/cmake-3.10.2-Linux-x86_64.sh Now you have to run this command by itself (it is interactive) sh cmake-3.10.2-Linux-x86_64.sh --prefix ~/cmake-3.10.2 Answer 'n' to the question about creating another cmake-3.10.2-Linux-x86_64 folder and then sudo update-alternatives --install /usr/bin/cmake cmake ~/cmake-3.10.2/bin/cmake 60 Now type cmake --version to make sure your cmake version is 3.10.2.","title":"Installing cmake on Linux"},{"location":"docs/cmake_linux/#installing-cmake-on-linux","text":"If you don't have cmake version 3.10 (for example, 3.2.2 is the default on Ubuntu 14) you can run the following: mkdir ~/cmake-3.10.2 cd ~/cmake-3.10.2 wget https://cmake.org/files/v3.10/cmake-3.10.2-Linux-x86_64.sh Now you have to run this command by itself (it is interactive) sh cmake-3.10.2-Linux-x86_64.sh --prefix ~/cmake-3.10.2 Answer 'n' to the question about creating another cmake-3.10.2-Linux-x86_64 folder and then sudo update-alternatives --install /usr/bin/cmake cmake ~/cmake-3.10.2/bin/cmake 60 Now type cmake --version to make sure your cmake version is 3.10.2.","title":"Installing cmake on Linux"},{"location":"docs/code_structure/","text":"AirLib Majority of the code is located in AirLib. This is a self-contained library that you should be able to compile with any C++11 compiler. AirLib consists of the following components: 1. Physics engine: This is header-only physics engine. It is designed to be fast and extensible to implement different vehicles. 2. Sensor models: This is header-only models for Barometer, IMU, GPS and Magnetometer 3. Vehicle models: This is header-only models for vehicle configurations and models. Currently we have implemented model for a MultiRotor and a configuration for PX4 QuadRotor in the X config. 4. Control library: This part of AirLib provides abstract base class for our APIs and concrete implementation for specific vehicle platforms such as MavLink. It also has classes for the RPC client and server. Unreal/Plugins/AirSim This is the only portion of project which is dependent on Unreal engine. We have kept it isolated so we can implement simulator for other platforms as well (for example, Unity). The Unreal code takes advantage of its UObject based classes including Blueprints. 1. SimMode_ classes : We wish to support various simulator modes such as pure Computer Vision mode where there is no drone. The SimMode classes help implement many different modes. 2. VehiclePawnBase : This is the base class for all vehicle pawn visualizations. 3. VehicleBase : This class provides abstract interface to implement a combination of rendering component (i.e. Unreal pawn), physics component (i.e. MultiRotor) and controller (i.e. MavLinkHelper). MavLinkCom This is the library developed by our own team member Chris Lovett that provides C++ classes to talk to the MavLink devices. This library is stand alone and can be used in any project. See MavLinkCom for more info. Sample Programs We have created a few sample programs to demonstrate how to use the API. See HelloDrone and DroneShell. DroneShell demonstrates how to connect to the simulator using UDP. The simulator is running a server (similar to DroneServer). Contributing See Contribution Guidelines Unreal Framework The following picture illustrates how AirSim is loaded and invoked by the Unreal Game Engine:","title":"Code Structure"},{"location":"docs/code_structure/#airlib","text":"Majority of the code is located in AirLib. This is a self-contained library that you should be able to compile with any C++11 compiler. AirLib consists of the following components: 1. Physics engine: This is header-only physics engine. It is designed to be fast and extensible to implement different vehicles. 2. Sensor models: This is header-only models for Barometer, IMU, GPS and Magnetometer 3. Vehicle models: This is header-only models for vehicle configurations and models. Currently we have implemented model for a MultiRotor and a configuration for PX4 QuadRotor in the X config. 4. Control library: This part of AirLib provides abstract base class for our APIs and concrete implementation for specific vehicle platforms such as MavLink. It also has classes for the RPC client and server.","title":"AirLib"},{"location":"docs/code_structure/#unrealpluginsairsim","text":"This is the only portion of project which is dependent on Unreal engine. We have kept it isolated so we can implement simulator for other platforms as well (for example, Unity). The Unreal code takes advantage of its UObject based classes including Blueprints. 1. SimMode_ classes : We wish to support various simulator modes such as pure Computer Vision mode where there is no drone. The SimMode classes help implement many different modes. 2. VehiclePawnBase : This is the base class for all vehicle pawn visualizations. 3. VehicleBase : This class provides abstract interface to implement a combination of rendering component (i.e. Unreal pawn), physics component (i.e. MultiRotor) and controller (i.e. MavLinkHelper).","title":"Unreal/Plugins/AirSim"},{"location":"docs/code_structure/#mavlinkcom","text":"This is the library developed by our own team member Chris Lovett that provides C++ classes to talk to the MavLink devices. This library is stand alone and can be used in any project. See MavLinkCom for more info.","title":"MavLinkCom"},{"location":"docs/code_structure/#sample-programs","text":"We have created a few sample programs to demonstrate how to use the API. See HelloDrone and DroneShell. DroneShell demonstrates how to connect to the simulator using UDP. The simulator is running a server (similar to DroneServer).","title":"Sample Programs"},{"location":"docs/code_structure/#contributing","text":"See Contribution Guidelines","title":"Contributing"},{"location":"docs/code_structure/#unreal-framework","text":"The following picture illustrates how AirSim is loaded and invoked by the Unreal Game Engine:","title":"Unreal Framework"},{"location":"docs/coding_guidelines/","text":"Modern C++ Coding Guidelines We are using Modern C++11. Smart pointers, Lambdas, and C++11 multithreading primitives are your friend. Quick Note The great thing about \"standards\" is that there are many to chose from: ISO , Sutter & Stroustrup , ROS , LINUX , Google's , Microsoft's , CERN's , GCC's , ARM's , LLVM's and probably thousands of others. Unfortunately most of these can't even agree on something as basic as how to name a class or a constant. This is probably due to the fact that these standards often carry lots of legacy issues due to supporting existing code bases. The intention behind this document is to create guidance that remains as close to ISO, Sutter & Stroustrup and ROS while resolving as many conflicts, disadvantages and inconsistencies as possible among them. Naming Conventions Avoid using any sort of Hungarian notation on names and \"_ptr\" on pointers. Code Element Style Comment Namespace under_scored Differentiate from class names Class name CamelCase To differentiate from STL types which ISO recommends (do not use \"C\" or \"T\" prefixes) Function name camelCase Lower case start is almost universal except for .Net world Parameters/Locals under_scored Vast majority of standards recommends this because _ is more readable to C++ crowd (although not much to Java/.Net crowd) Member variables under_scored_with_ The prefix _ is heavily discouraged as ISO has rules around reserving _identifiers, so we recommend suffix instead Enums and its members CamelCase Most except very old standards agree with this one Globals g_under_scored You shouldn't have these in first place! Constants UPPER_CASE Very contentious and we just have to pick one here, unless if is a private constant in class or method, then use naming for Members or Locals File names Match case of class name in file Lot of pro and cons either way but this removes inconsistency in auto generated code (important for ROS) Header Files Use a namespace qualified #ifdef to protect against multiple inclusion: #ifndef msr_airsim_MyHeader_hpp #define msr_airsim_MyHeader_hpp //--your code #endif The reason we don't use #pragma once is because it's not supported if same header file exists at multiple places (which might be possible under ROS build system!). Bracketing Inside function or method body place curly bracket on same line. Outside that the Namespace, Class and methods levels use separate line. This is called K&R style and its variants are widely used in C++ vs other styles which are more popular in other languages. Notice that curlies are not required if you have single statement, but complex statements are easier to keep correct with the braces. int main(int argc, char* argv[]) { while (x == y) { f0(); if (cont()) { f1(); } else { f2(); f3(); } if (x > 100) break; } } Const and References Religiously review all non-scalar parameters you declare to be candidate for const and references. If you are coming from languages such as C#/Java/Python, the most often mistake you would make is to pass parameters by value instead of const T&; Especially most of the strings, vectors and maps you want to pass as const T&; (if they are readonly) or T& (if they are writable). Also add const suffix to methods as much as possible. Overriding When overriding virtual method, use override suffix. Pointers This is really about memory management. A simulator has much performance critical code, so we try and avoid overloading the memory manager with lots of calls to new/delete. We also want to avoid too much copying of things on the stack, so we pass things by reference when ever possible. But when the object really needs to live longer than the call stack you often need to allocate that object on the heap, and so you have a pointer. Now, if management of the lifetime of that object is going to be tricky we recommend using C++ 11 smart pointers . But smart pointers do have a cost, so don\u2019t use them blindly everywhere. For private code where performance is paramount, raw pointers can be used. Raw pointers are also often needed when interfacing with legacy systems that only accept pointer types, for example, sockets API. But we try to wrap those legacy interfaces as much as possible and avoid that style of programming from leaking into the larger code base. Religiously check if you can use const everywhere, for example, const float * const xP . Avoid using prefix or suffix to indicate pointer types in variable names, i.e. use my_obj instead of myobj_ptr except in cases where it might make sense to differentiate variables better, for example, int mynum = 5; int* mynum_ptr = mynum; This is Too Short, ye? Yes, and it's on purpose because no one likes to read 200 page coding guidelines. The goal here is to cover only most significant things which are already not covered by strict mode compilation in GCC and Level 4 warnings-as-errors in VC++. If you had like to know about how to write better code in C++, please see GotW and Effective Modern C++ book.","title":"Coding Guidelines"},{"location":"docs/coding_guidelines/#modern-c-coding-guidelines","text":"We are using Modern C++11. Smart pointers, Lambdas, and C++11 multithreading primitives are your friend.","title":"Modern C++ Coding Guidelines"},{"location":"docs/coding_guidelines/#quick-note","text":"The great thing about \"standards\" is that there are many to chose from: ISO , Sutter & Stroustrup , ROS , LINUX , Google's , Microsoft's , CERN's , GCC's , ARM's , LLVM's and probably thousands of others. Unfortunately most of these can't even agree on something as basic as how to name a class or a constant. This is probably due to the fact that these standards often carry lots of legacy issues due to supporting existing code bases. The intention behind this document is to create guidance that remains as close to ISO, Sutter & Stroustrup and ROS while resolving as many conflicts, disadvantages and inconsistencies as possible among them.","title":"Quick Note"},{"location":"docs/coding_guidelines/#naming-conventions","text":"Avoid using any sort of Hungarian notation on names and \"_ptr\" on pointers. Code Element Style Comment Namespace under_scored Differentiate from class names Class name CamelCase To differentiate from STL types which ISO recommends (do not use \"C\" or \"T\" prefixes) Function name camelCase Lower case start is almost universal except for .Net world Parameters/Locals under_scored Vast majority of standards recommends this because _ is more readable to C++ crowd (although not much to Java/.Net crowd) Member variables under_scored_with_ The prefix _ is heavily discouraged as ISO has rules around reserving _identifiers, so we recommend suffix instead Enums and its members CamelCase Most except very old standards agree with this one Globals g_under_scored You shouldn't have these in first place! Constants UPPER_CASE Very contentious and we just have to pick one here, unless if is a private constant in class or method, then use naming for Members or Locals File names Match case of class name in file Lot of pro and cons either way but this removes inconsistency in auto generated code (important for ROS)","title":"Naming Conventions"},{"location":"docs/coding_guidelines/#header-files","text":"Use a namespace qualified #ifdef to protect against multiple inclusion: #ifndef msr_airsim_MyHeader_hpp #define msr_airsim_MyHeader_hpp //--your code #endif The reason we don't use #pragma once is because it's not supported if same header file exists at multiple places (which might be possible under ROS build system!).","title":"Header Files"},{"location":"docs/coding_guidelines/#bracketing","text":"Inside function or method body place curly bracket on same line. Outside that the Namespace, Class and methods levels use separate line. This is called K&R style and its variants are widely used in C++ vs other styles which are more popular in other languages. Notice that curlies are not required if you have single statement, but complex statements are easier to keep correct with the braces. int main(int argc, char* argv[]) { while (x == y) { f0(); if (cont()) { f1(); } else { f2(); f3(); } if (x > 100) break; } }","title":"Bracketing"},{"location":"docs/coding_guidelines/#const-and-references","text":"Religiously review all non-scalar parameters you declare to be candidate for const and references. If you are coming from languages such as C#/Java/Python, the most often mistake you would make is to pass parameters by value instead of const T&; Especially most of the strings, vectors and maps you want to pass as const T&; (if they are readonly) or T& (if they are writable). Also add const suffix to methods as much as possible.","title":"Const and References"},{"location":"docs/coding_guidelines/#overriding","text":"When overriding virtual method, use override suffix.","title":"Overriding"},{"location":"docs/coding_guidelines/#pointers","text":"This is really about memory management. A simulator has much performance critical code, so we try and avoid overloading the memory manager with lots of calls to new/delete. We also want to avoid too much copying of things on the stack, so we pass things by reference when ever possible. But when the object really needs to live longer than the call stack you often need to allocate that object on the heap, and so you have a pointer. Now, if management of the lifetime of that object is going to be tricky we recommend using C++ 11 smart pointers . But smart pointers do have a cost, so don\u2019t use them blindly everywhere. For private code where performance is paramount, raw pointers can be used. Raw pointers are also often needed when interfacing with legacy systems that only accept pointer types, for example, sockets API. But we try to wrap those legacy interfaces as much as possible and avoid that style of programming from leaking into the larger code base. Religiously check if you can use const everywhere, for example, const float * const xP . Avoid using prefix or suffix to indicate pointer types in variable names, i.e. use my_obj instead of myobj_ptr except in cases where it might make sense to differentiate variables better, for example, int mynum = 5; int* mynum_ptr = mynum;","title":"Pointers"},{"location":"docs/coding_guidelines/#this-is-too-short-ye","text":"Yes, and it's on purpose because no one likes to read 200 page coding guidelines. The goal here is to cover only most significant things which are already not covered by strict mode compilation in GCC and Level 4 warnings-as-errors in VC++. If you had like to know about how to write better code in C++, please see GotW and Effective Modern C++ book.","title":"This is Too Short, ye?"},{"location":"docs/create_issue/","text":"How to Create Issue or Ask Question Effectively AirSim is open source project and contributors like you keeps it going. It is important to respect contributors time and effort when you are asking a question or filing an issue. Your chances of receiving helpful response would increase if you follow below guidelines: DOs Search issues to see if someone already has asked it. Chose title that is short and summarizes well. Copy and paste full error message. Precisely describe steps you used that produced the error message or symptom. Describe what vehicle, mode, OS, AirSim version and other settings you are using. Copy and paste minimal version of code that reproduces the problem. Tell us what the goal you want to achieve or expected output. Tell us what you did so far to debug this issue. DONT'S Do not use \"Please help\" etc in the title. See above. Do not copy and paste screen shot of error message. Copy and paste text. Do not use \"it doesn't work\". Precisely state what is the error message or symptom. Do not ask to write code for you. Contribute !","title":"Create Issue"},{"location":"docs/create_issue/#how-to-create-issue-or-ask-question-effectively","text":"AirSim is open source project and contributors like you keeps it going. It is important to respect contributors time and effort when you are asking a question or filing an issue. Your chances of receiving helpful response would increase if you follow below guidelines:","title":"How to Create Issue or Ask Question Effectively"},{"location":"docs/create_issue/#dos","text":"Search issues to see if someone already has asked it. Chose title that is short and summarizes well. Copy and paste full error message. Precisely describe steps you used that produced the error message or symptom. Describe what vehicle, mode, OS, AirSim version and other settings you are using. Copy and paste minimal version of code that reproduces the problem. Tell us what the goal you want to achieve or expected output. Tell us what you did so far to debug this issue.","title":"DOs"},{"location":"docs/create_issue/#donts","text":"Do not use \"Please help\" etc in the title. See above. Do not copy and paste screen shot of error message. Copy and paste text. Do not use \"it doesn't work\". Precisely state what is the error message or symptom. Do not ask to write code for you. Contribute !","title":"DONT'S"},{"location":"docs/custom_drone/","text":"AirLib on a Real Drone The AirLib library can be compiled and deployed on the companion computer on a real drone. For our testing, we mounted a Gigabyte Brix BXi7-5500 ultra compact PC on the drone connected to the Pixhawk flight controller over USB. The Gigabyte PC is running Ubuntu, so we are able to SSH into it over Wi-Fi: Once connected you can run MavLinkTest with this command line: MavLinkTest -serial:/dev/ttyACM0,115200 -logdir:. And this will produce a log file of the flight which can then be used for playback in the simulator . You can also add -proxy:192.168.1.100:14550 to connect MavLinkTest to a remote computer where you can run QGroundControl or our PX4 Log Viewer which is another handy way to see what is going on with your drone. MavLinkTest then has some simple commands for testing your drone, here's a simple example of some commands: arm takeoff 5 orbit 10 2 This will arm the drone, takeoff of 5 meters, then do an orbit pattern radius 10 meters, at 2 m/s. Type '?' to find all available commands. Note: Some commands (for example, orbit ) are named differently and have different syntax in MavLinkTest and DroneShell (for example, circlebypath -radius 10 -velocity 21 ). When you land the drone you can stop MavLinkTest and copy the *.mavlink log file that was generated. DroneServer and DroneShell Once you are happy that the MavLinkTest is working, you can also run DroneServer and DroneShell as follows. First, run MavLinkTest with a local proxy to send everything to DroneServer: MavLinkTest -serial:/dev/ttyACM0,115200 -logdir:. -proxy:127.0.0.1:14560 Change ~/Documents/AirSim/settings.json to say \"serial\":false, because we want DroneServer to look for this UDP connection. DroneServer 0 Lastly, you can now connect DroneShell to this instance of DroneServer and use the DroneShell commands to fly your drone: DroneShell ==||=> Welcome to DroneShell 1.0. Type ? for help. Microsoft Research (c) 2016. Waiting for drone to report a valid GPS location... ==||=> requestcontrol ==||=> arm ==||=> takeoff ==||=> circlebypath -radius 10 -velocity 2 PX4 Specific Tools You can run the MavlinkCom library and MavLinkTest app to test the connection between your companion computer and flight controller. How Does This Work? AirSim uses MavLinkCom component developed by @lovettchris. The MavLinkCom has a proxy architecture where you can open a connection to PX4 either using serial or UDP and then other components share this connection. When PX4 sends MavLink message, all components receive that message. If any component sends a message then it's received by PX4 only. This allows you to connect any number of components to PX4 This code opens a connection for LogViewer and QGC. You can add something more if you like. If you want to use QGC + AirSim together than you will need QGC to let own the serial port. QGC opens up TCP connection that acts as a proxy so any other component can connect to QGC and send MavLinkMessage to QGC and then QGC forwards that message to PX4. So you tell AirSim to connect to QGC and let QGC own serial port. For companion board, the way we did it earlier was to have Gigabyte Brix on the drone. This x86 full-fledged computer that will connect to PX4 through USB. We had Ubuntu on Brix and ran DroneServer . The DroneServer created an API endpoint that we can talk to via C++ client code (or Python code) and it translated API calls to MavLink messages. That way you can write your code against the same API, test it in the simulator and then run the same code on an actual vehicle. So the companion computer has DroneServer running along with client code.","title":"AirSim on Real Drones"},{"location":"docs/custom_drone/#airlib-on-a-real-drone","text":"The AirLib library can be compiled and deployed on the companion computer on a real drone. For our testing, we mounted a Gigabyte Brix BXi7-5500 ultra compact PC on the drone connected to the Pixhawk flight controller over USB. The Gigabyte PC is running Ubuntu, so we are able to SSH into it over Wi-Fi: Once connected you can run MavLinkTest with this command line: MavLinkTest -serial:/dev/ttyACM0,115200 -logdir:. And this will produce a log file of the flight which can then be used for playback in the simulator . You can also add -proxy:192.168.1.100:14550 to connect MavLinkTest to a remote computer where you can run QGroundControl or our PX4 Log Viewer which is another handy way to see what is going on with your drone. MavLinkTest then has some simple commands for testing your drone, here's a simple example of some commands: arm takeoff 5 orbit 10 2 This will arm the drone, takeoff of 5 meters, then do an orbit pattern radius 10 meters, at 2 m/s. Type '?' to find all available commands. Note: Some commands (for example, orbit ) are named differently and have different syntax in MavLinkTest and DroneShell (for example, circlebypath -radius 10 -velocity 21 ). When you land the drone you can stop MavLinkTest and copy the *.mavlink log file that was generated.","title":"AirLib on a Real Drone"},{"location":"docs/custom_drone/#droneserver-and-droneshell","text":"Once you are happy that the MavLinkTest is working, you can also run DroneServer and DroneShell as follows. First, run MavLinkTest with a local proxy to send everything to DroneServer: MavLinkTest -serial:/dev/ttyACM0,115200 -logdir:. -proxy:127.0.0.1:14560 Change ~/Documents/AirSim/settings.json to say \"serial\":false, because we want DroneServer to look for this UDP connection. DroneServer 0 Lastly, you can now connect DroneShell to this instance of DroneServer and use the DroneShell commands to fly your drone: DroneShell ==||=> Welcome to DroneShell 1.0. Type ? for help. Microsoft Research (c) 2016. Waiting for drone to report a valid GPS location... ==||=> requestcontrol ==||=> arm ==||=> takeoff ==||=> circlebypath -radius 10 -velocity 2","title":"DroneServer and DroneShell"},{"location":"docs/custom_drone/#px4-specific-tools","text":"You can run the MavlinkCom library and MavLinkTest app to test the connection between your companion computer and flight controller.","title":"PX4 Specific Tools"},{"location":"docs/custom_drone/#how-does-this-work","text":"AirSim uses MavLinkCom component developed by @lovettchris. The MavLinkCom has a proxy architecture where you can open a connection to PX4 either using serial or UDP and then other components share this connection. When PX4 sends MavLink message, all components receive that message. If any component sends a message then it's received by PX4 only. This allows you to connect any number of components to PX4 This code opens a connection for LogViewer and QGC. You can add something more if you like. If you want to use QGC + AirSim together than you will need QGC to let own the serial port. QGC opens up TCP connection that acts as a proxy so any other component can connect to QGC and send MavLinkMessage to QGC and then QGC forwards that message to PX4. So you tell AirSim to connect to QGC and let QGC own serial port. For companion board, the way we did it earlier was to have Gigabyte Brix on the drone. This x86 full-fledged computer that will connect to PX4 through USB. We had Ubuntu on Brix and ran DroneServer . The DroneServer created an API endpoint that we can talk to via C++ client code (or Python code) and it translated API calls to MavLink messages. That way you can write your code against the same API, test it in the simulator and then run the same code on an actual vehicle. So the companion computer has DroneServer running along with client code.","title":"How Does This Work?"},{"location":"docs/design/","text":"Paper You can read more about our architecture and design in our paper (work in progress) . You may cite this as, @techreport{MSR-TR-2017-9, title = {{A}erial {I}nformatics and {R}obotics Platform}, author = {Shital Shah and Debadeepta Dey and Chris Lovett and Ashish Kapoor}, year = {2017}, institution = {Microsoft Research}, number = {{M}{S}{R}-{T}{R}-2017-9}} } Architecture Below is high level overview of how different components interact with each other.","title":"Architecture"},{"location":"docs/design/#paper","text":"You can read more about our architecture and design in our paper (work in progress) . You may cite this as, @techreport{MSR-TR-2017-9, title = {{A}erial {I}nformatics and {R}obotics Platform}, author = {Shital Shah and Debadeepta Dey and Chris Lovett and Ashish Kapoor}, year = {2017}, institution = {Microsoft Research}, number = {{M}{S}{R}-{T}{R}-2017-9}} }","title":"Paper"},{"location":"docs/design/#architecture","text":"Below is high level overview of how different components interact with each other.","title":"Architecture"},{"location":"docs/dev_workflow/","text":"Development Workflow Below is the guide on how to perform different development activities while working with AirSim. If you are new to Unreal Engine based projects and want to contribute to AirSim or make your own forks for your custom requirements, this might save you some time. Development Environment OS We highly recommend Windows 10 and Visual Studio 2017 as your development environment. The support for other OSes and IDE is unfortunately not as mature on the Unreal Engine side and you may risk severe loss of productivity trying to do workarounds and jumping through the hoops. Hardware We recommend GPUs such as NVidia 1080 or NVidia Titan series with powerful desktop such as one with 64GB RAM, 6+ cores, SSDs and 2-3 displays (ideally 4K). We have found HP Z840 work quite well for our needs. The development experience on high-end laptops is generally sub-par compared to powerful desktops however they might be useful in a pinch. You generally want laptops with discrete NVidia GPU (at least M2000 or better) with 64GB RAM, SSDs and hopefully 4K display. We have found models such as Lenovo P50 work well for our needs. Laptops with only integrated graphics might not work well. Updating and Changing AirSim Code Overview AirSim is designed as plugin. This means it can't run by itself, you need to put it in an Unreal project (we call it \"environment\"). So building and testing AirSim has two steps: (1) build the plugin (2) deploy plugin in Unreal project and run the project. The first step is accomplished by build.cmd available in AirSim root. This command will update everything you need for the plugin in the Unreal\\Plugins folder. So to deploy the plugin, you just need to copy Unreal\\Plugins folder in to your Unreal project folder. Next you should remove all intermediate files in your Unreal project and then regenerate .sln file for your Unreal project. To do this, we have two handy .bat files in Unreal\\Environments\\Blocks folder: clean.bat and GenerateProjectFiles.bat . So just run these bat files in sequence from root of your Unreal project. Now you are ready to open new .sln in Visual Studio and press F5 to run it. Steps Below are the steps we use to make changes in AirSim and test them out. The best way to do development in AirSim code is to use Blocks project . This is the light weight project so compile time is relatively faster. Generally the workflow is, REM //Use x64 Native Tools Command Prompt for VS 2017 REM //Navigate to AirSim repo folder git pull build.cmd cd Unreal\\Environments\\Blocks update_from_git.bat start Blocks.sln Above commands first builds the AirSim plugin and then deploys it to Blocks project using handy update_from_git.bat . Now you can work inside Visual Studio solution, make changes to the code and just run F5 to build, run and test your changes. The debugging, break points etc should work as usual. After you are done with you code changes, you might want to push your changes back to AirSim repo or your own fork or you may deploy the new plugin to your custom Unreal project. To do this, go back to command prompt and first update the AirSim repo folder: REM //Use x64 Native Tools Command Prompt for VS 2017 REM //run this from Unreal\\Environments\\Blocks update_to_git.bat build.cmd Above command will transfer your code changes from Unreal project folder back to Unreal\\Plugins folder. Now your changes are ready to be pushed to AirSim repo or your own fork. You can also copy Unreal\\Plugins to your custom Unreal engine project and see if everything works in your custom project as well. Take Away Once you understand how Unreal Build system and plugin model works as well as why we are doing above steps, you should feel quite comfortable in following this workflow. Don't be afraid of opening up .bat files to peek inside and see what its doing. They are quite minimal and straightforward (except, of course, build.cmd - don't look in to that one). FAQ I made changes in code in Blocks project but its not working. When you press F5 or F6 in Visual Studio to start build, the Unreal Build system kicks in and it tries to find out if any files are dirty and what it needs to build. Unfortunately, it often fails to recognize dirty files that is not the code that uses Unreal headers and object hierarchy. So, the trick is to just make some file dirty that Unreal Build system always recognizes. My favorite one is AirSimGameMode.cpp. Just insert a line, delete it and save the file. I made changes in the code outside of Visual Studio but its not working. Don't do that! Unreal Build system assumes that you are using Visual Studio and it does bunch of things to integrate with Visual Studio. If you do insist on using other editors then look up how to do command line builds in Unreal projects OR see docs on your editor on how it can integrate with Unreal build system OR run clean.bat + GenerateProjectFiles.bat to make sure VS solution is in sync. I'm trying to add new file in the Unreal Project and its not working. It won't! While you are indeed using Visual Studio solution, remember that this solution was actually generated by Unreal Build system. If you want to add new files in your project, first shut down Visual Studio, add an empty file at desired location and then run GenerateProjectFiles.bat which will scan all files in your project and then re-create the .sln file. Now open this new .sln file and you are in business. I copied Unreal\\Plugins folder but nothing happens in Unreal Project. First make sure your project's .uproject file is referencing the plugin. Then make sure you have run clean.bat and then GenerateProjectFiles.bat as described in Overview above. I have multiple Unreal projects with AirSim plugin. How do I update them easily? You are in luck! We have build_all_ue_projects.bat which exactly does that. Don't treat it as black box (at least not yet), open it up and see what it does. It has 4 variables that are being set from command line args. If these args is not supplied they are set to default values in next set of statements. You might want to change default values for the paths. This batch file builds AirSim plugin, deploys it to all listed projects (see CALL statements later in the batch file), runs packaging for those projects and puts final binaries in specified folder - all in one step! This is what we use to create our own binary releases. How do I contribute back to AirSim? Before making any changes make sure you have created your feature branch. After you test your code changes in Blocks environment, follow the usual steps to make contributions just like any other GitHub projects. If you are not familiar with Git Branch-Rebase-Merge workflow, please read this first .","title":"Development Workflow"},{"location":"docs/dev_workflow/#development-workflow","text":"Below is the guide on how to perform different development activities while working with AirSim. If you are new to Unreal Engine based projects and want to contribute to AirSim or make your own forks for your custom requirements, this might save you some time.","title":"Development Workflow"},{"location":"docs/dev_workflow/#development-environment","text":"","title":"Development Environment"},{"location":"docs/dev_workflow/#os","text":"We highly recommend Windows 10 and Visual Studio 2017 as your development environment. The support for other OSes and IDE is unfortunately not as mature on the Unreal Engine side and you may risk severe loss of productivity trying to do workarounds and jumping through the hoops.","title":"OS"},{"location":"docs/dev_workflow/#hardware","text":"We recommend GPUs such as NVidia 1080 or NVidia Titan series with powerful desktop such as one with 64GB RAM, 6+ cores, SSDs and 2-3 displays (ideally 4K). We have found HP Z840 work quite well for our needs. The development experience on high-end laptops is generally sub-par compared to powerful desktops however they might be useful in a pinch. You generally want laptops with discrete NVidia GPU (at least M2000 or better) with 64GB RAM, SSDs and hopefully 4K display. We have found models such as Lenovo P50 work well for our needs. Laptops with only integrated graphics might not work well.","title":"Hardware"},{"location":"docs/dev_workflow/#updating-and-changing-airsim-code","text":"","title":"Updating and Changing AirSim Code"},{"location":"docs/dev_workflow/#overview","text":"AirSim is designed as plugin. This means it can't run by itself, you need to put it in an Unreal project (we call it \"environment\"). So building and testing AirSim has two steps: (1) build the plugin (2) deploy plugin in Unreal project and run the project. The first step is accomplished by build.cmd available in AirSim root. This command will update everything you need for the plugin in the Unreal\\Plugins folder. So to deploy the plugin, you just need to copy Unreal\\Plugins folder in to your Unreal project folder. Next you should remove all intermediate files in your Unreal project and then regenerate .sln file for your Unreal project. To do this, we have two handy .bat files in Unreal\\Environments\\Blocks folder: clean.bat and GenerateProjectFiles.bat . So just run these bat files in sequence from root of your Unreal project. Now you are ready to open new .sln in Visual Studio and press F5 to run it.","title":"Overview"},{"location":"docs/dev_workflow/#steps","text":"Below are the steps we use to make changes in AirSim and test them out. The best way to do development in AirSim code is to use Blocks project . This is the light weight project so compile time is relatively faster. Generally the workflow is, REM //Use x64 Native Tools Command Prompt for VS 2017 REM //Navigate to AirSim repo folder git pull build.cmd cd Unreal\\Environments\\Blocks update_from_git.bat start Blocks.sln Above commands first builds the AirSim plugin and then deploys it to Blocks project using handy update_from_git.bat . Now you can work inside Visual Studio solution, make changes to the code and just run F5 to build, run and test your changes. The debugging, break points etc should work as usual. After you are done with you code changes, you might want to push your changes back to AirSim repo or your own fork or you may deploy the new plugin to your custom Unreal project. To do this, go back to command prompt and first update the AirSim repo folder: REM //Use x64 Native Tools Command Prompt for VS 2017 REM //run this from Unreal\\Environments\\Blocks update_to_git.bat build.cmd Above command will transfer your code changes from Unreal project folder back to Unreal\\Plugins folder. Now your changes are ready to be pushed to AirSim repo or your own fork. You can also copy Unreal\\Plugins to your custom Unreal engine project and see if everything works in your custom project as well.","title":"Steps"},{"location":"docs/dev_workflow/#take-away","text":"Once you understand how Unreal Build system and plugin model works as well as why we are doing above steps, you should feel quite comfortable in following this workflow. Don't be afraid of opening up .bat files to peek inside and see what its doing. They are quite minimal and straightforward (except, of course, build.cmd - don't look in to that one).","title":"Take Away"},{"location":"docs/dev_workflow/#faq","text":"","title":"FAQ"},{"location":"docs/dev_workflow/#i-made-changes-in-code-in-blocks-project-but-its-not-working","text":"When you press F5 or F6 in Visual Studio to start build, the Unreal Build system kicks in and it tries to find out if any files are dirty and what it needs to build. Unfortunately, it often fails to recognize dirty files that is not the code that uses Unreal headers and object hierarchy. So, the trick is to just make some file dirty that Unreal Build system always recognizes. My favorite one is AirSimGameMode.cpp. Just insert a line, delete it and save the file.","title":"I made changes in code in Blocks project but its not working."},{"location":"docs/dev_workflow/#i-made-changes-in-the-code-outside-of-visual-studio-but-its-not-working","text":"Don't do that! Unreal Build system assumes that you are using Visual Studio and it does bunch of things to integrate with Visual Studio. If you do insist on using other editors then look up how to do command line builds in Unreal projects OR see docs on your editor on how it can integrate with Unreal build system OR run clean.bat + GenerateProjectFiles.bat to make sure VS solution is in sync.","title":"I made changes in the code outside of Visual Studio but its not working."},{"location":"docs/dev_workflow/#im-trying-to-add-new-file-in-the-unreal-project-and-its-not-working","text":"It won't! While you are indeed using Visual Studio solution, remember that this solution was actually generated by Unreal Build system. If you want to add new files in your project, first shut down Visual Studio, add an empty file at desired location and then run GenerateProjectFiles.bat which will scan all files in your project and then re-create the .sln file. Now open this new .sln file and you are in business.","title":"I'm trying to add new file in the Unreal Project and its not working."},{"location":"docs/dev_workflow/#i-copied-unrealplugins-folder-but-nothing-happens-in-unreal-project","text":"First make sure your project's .uproject file is referencing the plugin. Then make sure you have run clean.bat and then GenerateProjectFiles.bat as described in Overview above.","title":"I copied Unreal\\Plugins folder but nothing happens in Unreal Project."},{"location":"docs/dev_workflow/#i-have-multiple-unreal-projects-with-airsim-plugin-how-do-i-update-them-easily","text":"You are in luck! We have build_all_ue_projects.bat which exactly does that. Don't treat it as black box (at least not yet), open it up and see what it does. It has 4 variables that are being set from command line args. If these args is not supplied they are set to default values in next set of statements. You might want to change default values for the paths. This batch file builds AirSim plugin, deploys it to all listed projects (see CALL statements later in the batch file), runs packaging for those projects and puts final binaries in specified folder - all in one step! This is what we use to create our own binary releases.","title":"I have multiple Unreal projects with AirSim plugin. How do I update them easily?"},{"location":"docs/dev_workflow/#how-do-i-contribute-back-to-airsim","text":"Before making any changes make sure you have created your feature branch. After you test your code changes in Blocks environment, follow the usual steps to make contributions just like any other GitHub projects. If you are not familiar with Git Branch-Rebase-Merge workflow, please read this first .","title":"How do I contribute back to AirSim?"},{"location":"docs/faq/","text":"FAQ General Unreal editor is slow when it is not the active window Go to Edit/Editor Preferences, select \"All Settings\" and type \"CPU\" in the search box. It should find the setting titled \"Use Less CPU when in Background\", and you want to uncheck this checkbox. My mouse disappears in Unreal Yes, Unreal steals the mouse, and we don't draw one. So to get your mouse back just use Alt+TAB to switch to a different window. To avoid this entirely, go to Project settings in Unreal Editor, go to Input tab and disable all settings for mouse capture. Where is the setting file and how do I modify it? AirSim will create empty settings file at ~/Documents/AirSim/settings.json . You can view the available settings options . How do I arm my drone? If you're using simple_flight, your vehicle is already armed and ready to fly. For PX4 you can arm by holding both sticks on remote control down and to the center. Something went wrong. How do I debug? First turn on C++ exceptions from the Exceptions window: and copy the stack trace of all exceptions you see there during execution that look relevant (for example, there might be an initial exception from VSPerf140 that you can ignore) then paste these call stacks into a new AirSim GitHub issue, thanks. What do the colors mean in the Segmentation View ? See Camera Views for information on the camera views and how to change them. Unreal 4.xx doesn't look as good as 4.yy Unreal 4.15 added the ability for Foliage LOD dithering to be disabled on a case-by-case basis by unchecking the Dithered LOD Transition checkbox in the foliage materials. Note that all materials used on all LODs need to have the checkbox checked in order for dithered LOD transitions to work. When checked the transition of generated foliage will be a lot smoother and will look better than 4.14. Can I use an XBox controller to fly? See XBox controller for details. Can I build a hexacopter with AirSim? See how to build a hexacopter . How do I use AirSim with multiple vehicles? Here is multi-vehicle setup guide . What computer do you need? It depends on how big your Unreal Environment is. The Blocks environment that comes with AirSim is very basic and works on typical laptops. The Modular Neighborhood Pack that we use ourselves for research requires GPUs with at least 4GB of RAM. The Open World environment needs GPU with 8GB RAM. Our typical development machines have 32GB of RAM and NVIDIA TitanX and a fast hard drive . How do I report issues? It's a good idea to include your configuration like below. If you can also include logs, that could also expedite the investigation. Operating System: Windows 10 64bit CPU: Intel Core i7 GPU: Nvidia GTX 1080 RAM: 32 GB Flight Controller: Pixhawk v2 Remote Control: Futaba If you have modified the default ~/Document/AirSim/settings.json , please include your settings also. If you are using PX4 then try to capture log from MavLink or PX4 . File an issue through GitHub Issues . Others Linux Build FAQ Windows Build FAQ PX4 Setup FAQ Remote Control FAQ Unreal Blocks Environment FAQ Unreal Custom Environment FAQ","title":"FAQ"},{"location":"docs/faq/#faq","text":"","title":"FAQ"},{"location":"docs/faq/#general","text":"","title":"General"},{"location":"docs/faq/#unreal-editor-is-slow-when-it-is-not-the-active-window","text":"Go to Edit/Editor Preferences, select \"All Settings\" and type \"CPU\" in the search box. It should find the setting titled \"Use Less CPU when in Background\", and you want to uncheck this checkbox.","title":"Unreal editor is slow when it is not the active window"},{"location":"docs/faq/#my-mouse-disappears-in-unreal","text":"Yes, Unreal steals the mouse, and we don't draw one. So to get your mouse back just use Alt+TAB to switch to a different window. To avoid this entirely, go to Project settings in Unreal Editor, go to Input tab and disable all settings for mouse capture.","title":"My mouse disappears in Unreal"},{"location":"docs/faq/#where-is-the-setting-file-and-how-do-i-modify-it","text":"AirSim will create empty settings file at ~/Documents/AirSim/settings.json . You can view the available settings options .","title":"Where is the setting file and how do I modify it?"},{"location":"docs/faq/#how-do-i-arm-my-drone","text":"If you're using simple_flight, your vehicle is already armed and ready to fly. For PX4 you can arm by holding both sticks on remote control down and to the center.","title":"How do I arm my drone?"},{"location":"docs/faq/#something-went-wrong-how-do-i-debug","text":"First turn on C++ exceptions from the Exceptions window: and copy the stack trace of all exceptions you see there during execution that look relevant (for example, there might be an initial exception from VSPerf140 that you can ignore) then paste these call stacks into a new AirSim GitHub issue, thanks.","title":"Something went wrong. How do I debug?"},{"location":"docs/faq/#what-do-the-colors-mean-in-the-segmentation-view","text":"See Camera Views for information on the camera views and how to change them.","title":"What do the colors mean in the Segmentation View ?"},{"location":"docs/faq/#unreal-4xx-doesnt-look-as-good-as-4yy","text":"Unreal 4.15 added the ability for Foliage LOD dithering to be disabled on a case-by-case basis by unchecking the Dithered LOD Transition checkbox in the foliage materials. Note that all materials used on all LODs need to have the checkbox checked in order for dithered LOD transitions to work. When checked the transition of generated foliage will be a lot smoother and will look better than 4.14.","title":"Unreal 4.xx doesn't look as good as 4.yy"},{"location":"docs/faq/#can-i-use-an-xbox-controller-to-fly","text":"See XBox controller for details.","title":"Can I use an XBox controller to fly?"},{"location":"docs/faq/#can-i-build-a-hexacopter-with-airsim","text":"See how to build a hexacopter .","title":"Can I build a hexacopter with AirSim?"},{"location":"docs/faq/#how-do-i-use-airsim-with-multiple-vehicles","text":"Here is multi-vehicle setup guide .","title":"How do I use AirSim with multiple vehicles?"},{"location":"docs/faq/#what-computer-do-you-need","text":"It depends on how big your Unreal Environment is. The Blocks environment that comes with AirSim is very basic and works on typical laptops. The Modular Neighborhood Pack that we use ourselves for research requires GPUs with at least 4GB of RAM. The Open World environment needs GPU with 8GB RAM. Our typical development machines have 32GB of RAM and NVIDIA TitanX and a fast hard drive .","title":"What computer do you need?"},{"location":"docs/faq/#how-do-i-report-issues","text":"It's a good idea to include your configuration like below. If you can also include logs, that could also expedite the investigation. Operating System: Windows 10 64bit CPU: Intel Core i7 GPU: Nvidia GTX 1080 RAM: 32 GB Flight Controller: Pixhawk v2 Remote Control: Futaba If you have modified the default ~/Document/AirSim/settings.json , please include your settings also. If you are using PX4 then try to capture log from MavLink or PX4 . File an issue through GitHub Issues .","title":"How do I report issues?"},{"location":"docs/faq/#others","text":"Linux Build FAQ Windows Build FAQ PX4 Setup FAQ Remote Control FAQ Unreal Blocks Environment FAQ Unreal Custom Environment FAQ","title":"Others"},{"location":"docs/flight_controller/","text":"Flight Controller What is Flight Controller? \"Wait!\" you ask, \"Why do you need flight controller for a simulator?\". The primary job of flight controller is to take in desired state as input, estimate actual state using sensors data and then drive the actuators in such a way so that actual state comes as close to the desired state. For quadrotors, desired state can be specified as roll, pitch and yaw, for example. It then estimates actual roll, pitch and yaw using gyroscope and accelerometer. Then it generates appropriate motor signals so actual state becomes desired state. You can find more in-depth in our paper . How Simulator uses Flight Controller? Simulator consumes the motor signals generated by flight controller to figure out force and thrust generated by each actuator (i.e. propellers in case of quadrotor). This is then used by the physics engine to compute the kinetic properties of the vehicle. This in turn generates simulated sensor data and feed it back to the flight controller. You can find more in-depth in our paper . What is Hardware- and Software-in-Loop? Hardware-in-Loop (HITL or HIL) means flight controller runs in actual hardware such as Naze32 or Pixhawk chip. You then connect this hardware to PC using USB port. Simulator talks to the device to retrieve actuator signals and send it simulated sensor data. This is obviously as close as you can get to real thing. However, it typically requires more steps to set up and usually hard to debug. One big issue is that simulator clock and device clock runs on their own speed and accuracy. Also, USB connection (which is usually only USB 2.0) may not be enough for real-time communication. In \"software-in-loop\" simulation (SITL or SIL) mode the firmware runs in your computer as opposed to separate board. This is generally fine except that now you are not touching any code paths that are specific to your device. Also, none of your code now runs with real-time clock usually provided by specialized hardware board. For well-designed flight controllers with software clock, these are usually not concerning issues. What Flight Controllers are Supported? AirSim has built-in flight controller called simple_flight and it is used by default. You don't need to do anything to use or configure it. AirSim also supports PX4 as another flight controller for advanced users. In the future, we also plan to support ROSFlight and Hackflight . ## Using AirSim Without Flight Controller Yes, now it's possible to use AirSim without flight controller. Please see the instructions here for how to use so-called \"Computer Vision\" mode. If you don't need vehicle dynamics, we highly recommend using this mode.","title":"Flight Controller"},{"location":"docs/flight_controller/#flight-controller","text":"","title":"Flight Controller"},{"location":"docs/flight_controller/#what-is-flight-controller","text":"\"Wait!\" you ask, \"Why do you need flight controller for a simulator?\". The primary job of flight controller is to take in desired state as input, estimate actual state using sensors data and then drive the actuators in such a way so that actual state comes as close to the desired state. For quadrotors, desired state can be specified as roll, pitch and yaw, for example. It then estimates actual roll, pitch and yaw using gyroscope and accelerometer. Then it generates appropriate motor signals so actual state becomes desired state. You can find more in-depth in our paper .","title":"What is Flight Controller?"},{"location":"docs/flight_controller/#how-simulator-uses-flight-controller","text":"Simulator consumes the motor signals generated by flight controller to figure out force and thrust generated by each actuator (i.e. propellers in case of quadrotor). This is then used by the physics engine to compute the kinetic properties of the vehicle. This in turn generates simulated sensor data and feed it back to the flight controller. You can find more in-depth in our paper .","title":"How Simulator uses Flight Controller?"},{"location":"docs/flight_controller/#what-is-hardware-and-software-in-loop","text":"Hardware-in-Loop (HITL or HIL) means flight controller runs in actual hardware such as Naze32 or Pixhawk chip. You then connect this hardware to PC using USB port. Simulator talks to the device to retrieve actuator signals and send it simulated sensor data. This is obviously as close as you can get to real thing. However, it typically requires more steps to set up and usually hard to debug. One big issue is that simulator clock and device clock runs on their own speed and accuracy. Also, USB connection (which is usually only USB 2.0) may not be enough for real-time communication. In \"software-in-loop\" simulation (SITL or SIL) mode the firmware runs in your computer as opposed to separate board. This is generally fine except that now you are not touching any code paths that are specific to your device. Also, none of your code now runs with real-time clock usually provided by specialized hardware board. For well-designed flight controllers with software clock, these are usually not concerning issues.","title":"What is Hardware- and Software-in-Loop?"},{"location":"docs/flight_controller/#what-flight-controllers-are-supported","text":"AirSim has built-in flight controller called simple_flight and it is used by default. You don't need to do anything to use or configure it. AirSim also supports PX4 as another flight controller for advanced users. In the future, we also plan to support ROSFlight and Hackflight . ## Using AirSim Without Flight Controller Yes, now it's possible to use AirSim without flight controller. Please see the instructions here for how to use so-called \"Computer Vision\" mode. If you don't need vehicle dynamics, we highly recommend using this mode.","title":"What Flight Controllers are Supported?"},{"location":"docs/hard_drive/","text":"Busy Hard Drive It is not required, but we recommend running your Unreal Environment on a Solid State Drive (SSD). Between debugging, logging, and Unreal asset loading the hard drive can become your bottle neck. It is normal that your hard drive will be slammed while Unreal is loading the environment, but if your hard drive performance looks like this while the Unreal game is running then you will probably not get a good flying experience. In fact, if the hard drive is this busy, chances are the drone will not fly properly at all. For some unknown reason this I/O bottle neck also interferes with the drone control loop and if that loop doesn't run at a high rate (300-500 Hz) then the drone will not fly. Not surprising, the control loop inside the PX4 firmware that runs on a Pixhawk flight controller runs at 1000 Hz. Reducing I/O If you can't whip off to Fry's Electronics and pick up an overpriced super fast SSD this weekend, then the following steps can be taken to reduce the hard drive I/O: First run the Unreal Environment using Cooked content outside of the UE Editor or any debugging environment, and package the content to your fastest SSD drive. You can do that using this menu option: If you must use the UE editor (because you are actively modifying game assets), then at least don't run that in a debugger. If you are using Visual Studio use start without debugging. If you must debug the app, and you are using Visual Studio debugger, stop then Visual Studio from logging Intellitrace information. Go to Tools/Options/Debugging/Intellitrace, and turn off the main checkbox. Turn off any Unreal Analytics that your environment may have enabled, especially any file logging. I/O from Page Faults If your system is running out of RAM it may start paging memory to disk. If your operating system has enabled paging to disk, make sure it is paging to your fastest SSD. Or if you have enough RAM disable paging all together. In fact, if you disable paging and the game stops working you will know for sure you are running out of RAM. Obviously, shutting down any other unnecessary apps should also free up memory so you don't run out. Ideal Runtime performance This is what my slow hard drive looks like when flying from UE editor. You can see it's very busy, but the drone still flies ok: This is what my fast SSD looks like when the drone is flying in an Unreal Cooked app (no UE editor, no debugger). Not surprisingly it is flying perfectly in this case:","title":"Tips for Busy HDD"},{"location":"docs/hard_drive/#busy-hard-drive","text":"It is not required, but we recommend running your Unreal Environment on a Solid State Drive (SSD). Between debugging, logging, and Unreal asset loading the hard drive can become your bottle neck. It is normal that your hard drive will be slammed while Unreal is loading the environment, but if your hard drive performance looks like this while the Unreal game is running then you will probably not get a good flying experience. In fact, if the hard drive is this busy, chances are the drone will not fly properly at all. For some unknown reason this I/O bottle neck also interferes with the drone control loop and if that loop doesn't run at a high rate (300-500 Hz) then the drone will not fly. Not surprising, the control loop inside the PX4 firmware that runs on a Pixhawk flight controller runs at 1000 Hz.","title":"Busy Hard Drive"},{"location":"docs/hard_drive/#reducing-io","text":"If you can't whip off to Fry's Electronics and pick up an overpriced super fast SSD this weekend, then the following steps can be taken to reduce the hard drive I/O: First run the Unreal Environment using Cooked content outside of the UE Editor or any debugging environment, and package the content to your fastest SSD drive. You can do that using this menu option: If you must use the UE editor (because you are actively modifying game assets), then at least don't run that in a debugger. If you are using Visual Studio use start without debugging. If you must debug the app, and you are using Visual Studio debugger, stop then Visual Studio from logging Intellitrace information. Go to Tools/Options/Debugging/Intellitrace, and turn off the main checkbox. Turn off any Unreal Analytics that your environment may have enabled, especially any file logging.","title":"Reducing I/O"},{"location":"docs/hard_drive/#io-from-page-faults","text":"If your system is running out of RAM it may start paging memory to disk. If your operating system has enabled paging to disk, make sure it is paging to your fastest SSD. Or if you have enough RAM disable paging all together. In fact, if you disable paging and the game stops working you will know for sure you are running out of RAM. Obviously, shutting down any other unnecessary apps should also free up memory so you don't run out.","title":"I/O from Page Faults"},{"location":"docs/hard_drive/#ideal-runtime-performance","text":"This is what my slow hard drive looks like when flying from UE editor. You can see it's very busy, but the drone still flies ok: This is what my fast SSD looks like when the drone is flying in an Unreal Cooked app (no UE editor, no debugger). Not surprisingly it is flying perfectly in this case:","title":"Ideal Runtime performance"},{"location":"docs/hello_drone/","text":"Hello Drone How does Hello Drone work? Hello Drone uses the RPC client to connect to the RPC server that is automatically started by the AirSim. The RPC server routes all the commands to a class that implements MultirotorApiBase . In essence, MultirotorApiBase defines our abstract interface for getting data from the quadrotor and sending back commands. We currently have concrete implementation for MultirotorApiBase for MavLink based vehicles. The implementation for DJI drone platforms, specifically Matrice, is in works.","title":"Hello Drone"},{"location":"docs/hello_drone/#hello-drone","text":"","title":"Hello Drone"},{"location":"docs/hello_drone/#how-does-hello-drone-work","text":"Hello Drone uses the RPC client to connect to the RPC server that is automatically started by the AirSim. The RPC server routes all the commands to a class that implements MultirotorApiBase . In essence, MultirotorApiBase defines our abstract interface for getting data from the quadrotor and sending back commands. We currently have concrete implementation for MultirotorApiBase for MavLink based vehicles. The implementation for DJI drone platforms, specifically Matrice, is in works.","title":"How does Hello Drone work?"},{"location":"docs/image_apis/","text":"Image APIs Please read general API doc first if you are not familiar with AirSim APIs. Getting a Single Image Here's a sample code to get a single image from camera named \"0\". The returned value is bytes of png format image. To get uncompressed and other format as well as available cameras please see next sections. Python import airsim #pip install airsim # for car use CarClient() client = airsim.MultirotorClient() png_image = client.simGetImage(\"0\", airsim.ImageType.Scene) # do something with image C++ #include \"vehicles/multirotor/api/MultirotorRpcLibClient.hpp\" int getOneImage() { using namespace std; using namespace msr::airlib; //for car use CarRpcLibClient msr::airlib::MultirotorRpcLibClient client; vector<uint8_t> png_image = client.simGetImage(\"0\", VehicleCameraBase::ImageType::Scene); //do something with images } Getting Images with More Flexibility The simGetImages API which is slightly more complex to use than simGetImage API, for example, you can get left camera view, right camera view and depth image from left camera in a single API call. The simGetImages API also allows you to get uncompressed images as well as floating point single channel images (instead of 3 channel (RGB), each 8 bit). Python import airsim #pip install airsim # for car use CarClient() client = airsim.MultirotorClient() responses = client.simGetImages([ # png format airsim.ImageRequest(0, airsim.ImageType.Scene), # uncompressed RGBA array bytes airsim.ImageRequest(1, airsim.ImageType.Scene, False, False), # floating point uncompressed image airsim.ImageRequest(1, airsim.ImageType.DepthPlanner, True)]) # do something with response which contains image data, pose, timestamp etc Using AirSim Images with NumPy If you plan to use numpy for image manipulation, you should get uncompressed RGBA image and then convert to numpy like this: responses = client.simGetImages([ImageRequest(\"0\", airsim.ImageType.Scene, False, False)]) response = responses[0] # get numpy array img1d = np.fromstring(response.image_data_uint8, dtype=np.uint8) # reshape array to 4 channel image array H X W X 4 img_rgba = img1d.reshape(response.height, response.width, 4) # original image is fliped vertically img_rgba = np.flipud(img_rgba) # just for fun add little bit of green in all pixels img_rgba[:,:,1:2] = 100 # write to png airsim.write_png(os.path.normpath(filename + '.greener.png'), img_rgba) Quick Tips The API simGetImage returns binary string literal which means you can simply dump it in binary file to create a .png file. However if you want to process it in any other way than you can handy function airsim.string_to_uint8_array . This converts binary string literal to NumPy uint8 array. The API simGetImages can accept request for multiple image types from any cameras in single call. You can specify if image is png compressed, RGB uncompressed or float array. For png compressed images, you get binary string literal . For float array you get Python list of float64. You can convert this float array to NumPy 2D array using airsim.list_to_2d_float_array(response.image_data_float, response.width, response.height) You can also save float array to .pfm file (Portable Float Map format) using airsim.write_pfm() function. C++ int getStereoAndDepthImages() { using namespace std; using namespace msr::airlib; typedef VehicleCameraBase::ImageRequest ImageRequest; typedef VehicleCameraBase::ImageResponse ImageResponse; typedef VehicleCameraBase::ImageType ImageType; //for car use //msr::airlib::CarRpcLibClient client; msr::airlib::MultirotorRpcLibClient client; //get right, left and depth images. First two as png, second as float16. vector<ImageRequest> request = { //png format ImageRequest(\"0\", ImageType::Scene), //uncompressed RGBA array bytes ImageRequest(\"1\", ImageType::Scene, false, false), //floating point uncompressed image ImageRequest(\"1\", ImageType::DepthPlanner, true) }; const vector<ImageResponse>& response = client.simGetImages(request); //do something with response which contains image data, pose, timestamp etc } Ready to Run Complete Examples Python For a more complete ready to run sample code please see sample code in AirSimClient project for multirotors or HelloCar sample . This code also demonstrates simple activities such as saving images in files or using numpy to manipulate images. C++ For a more complete ready to run sample code please see sample code in HelloDrone project for multirotors or HelloCar project . See also other example code that generates specified number of stereo images along with ground truth depth and disparity and saving it to pfm format . Available Cameras Car The cameras on car can be accessed by following names in API calls: front_center , front_right , front_left , fpv and back_center . Here FPV camera is driver's head position in the car. Multirotor The cameras in CV mode can be accessed by following names in API calls: front_center , front_right , front_left , bottom_center and back_center . Computer Vision Mode Camera names are same as in multirotor. Backward compatibility for camera names Before AirSim v1.2, cameras were accessed using ID numbers instead of names. For backward compatibility you can still use following ID numbers for above camera names in same order as above: \"0\" , \"1\" , \"2\" , \"3\" , \"4\" . In addition, camera name \"\" is also available to access the default camera which is generally the camera \"0\" . \"Computer Vision\" Mode You can use AirSim in so-called \"Computer Vision\" mode. In this mode, physics engine is disabled and there is no vehicle, just cameras. You can move around using keyboard (use F1 to see help on keys). You can press Record button to continuously generate images. Or you can call APIs to move cameras around and take images. To active this mode, edit settings.json that you can find in your Documents\\AirSim folder (or ~/Documents/AirSim on Linux) and make sure following values exist at root level: { \"SettingsVersion\": 1.2, \"SimMode\": \"ComputerVision\" } Here's the Python code example to move camera around and capture images. This mode was inspired from UnrealCV project . Setting Pose in Computer Vision Mode To move around the environment using APIs you can use simSetVehiclePose API. This API takes position and orientation and sets that on the invisible vehicle where the front-center camera is located. All rest of the cameras move along keeping the relative position. If you don't want to change position (or orientation) then just set components of position (or orientation) to floating point nan values. The simGetVehiclePose allows to retrieve the current pose. You can also use simGetGroundTruthKinematics to get the quantities kinematics quantities for the movement. Many other non-vehicle specific APIs are also available such as segmentation APIs, collision APIs and camera APIs. Camera APIs The simGetCameraInfo returns the pose (in world frame, NED coordinates, SI units) and FOV (in degrees) for the specified camera. Please see example usage . The simSetCameraOrientation sets the orientation for the specified camera as quaternion in NED frame. The handy airsim.to_quaternion() function allows to convert pitch, roll, yaw to quaternion. For example, to set camera-0 to 15-degree pitch, you can use: client.simSetCameraOrientation(0, airsim.toQuaternion(0.261799, 0, 0)); #radians Gimbal You can set stabilization for pitch, roll or yaw for any camera using settings . Please see example usage . Changing Resolution and Camera Parameters To change resolution, FOV etc, you can use settings.json . For example, below addition in settings.json sets parameters for scene capture and uses \"Computer Vision\" mode described above. If you omit any setting then below default values will be used. For more information see settings doc . If you are using stereo camera, currently the distance between left and right is fixed at 25 cm. { \"SettingsVersion\": 1.2, \"CameraDefaults\": { \"CaptureSettings\": [ { \"ImageType\": 0, \"Width\": 256, \"Height\": 144, \"FOV_Degrees\": 90, \"AutoExposureSpeed\": 100, \"MotionBlurAmount\": 0 } ] }, \"SimMode\": \"ComputerVision\" } What Does Pixel Values Mean in Different Image Types? Available ImageType Values Scene = 0, DepthPlanner = 1, DepthPerspective = 2, DepthVis = 3, DisparityNormalized = 4, Segmentation = 5, SurfaceNormals = 6, Infrared = 7 DepthPlanner and DepthPerspective You normally want to retrieve the depth image as float (i.e. set pixels_as_float = true ) and specify ImageType = DepthPlanner or ImageType = DepthPerspective in ImageRequest . For ImageType = DepthPlanner , you get depth in camera plan, i.e., all points that are in plan parallel to camera have same depth. For ImageType = DepthPerspective , you get depth from camera using a projection ray that hits that pixel. Depending on your use case, planner depth or perspective depth may be the ground truth image that you want. For example, you may be able to feed perspective depth to ROS package such as depth_image_proc to generate a point cloud. Or planner depth may be more compatible with estimated depth image generated by stereo algorithms such as SGM. DepthVis When you specify ImageType = DepthVis in ImageRequest , you get an image that helps depth visualization. In this case, each pixel value is interpolated from black to white depending on depth in camera plane in meters. The pixels with pure white means depth of 100m or more while pure black means depth of 0 meters. DisparityNormalized You normally want to retrieve disparity image as float (i.e. set pixels_as_float = true and specify ImageType = DisparityNormalized in ImageRequest ) in which case each pixel is (Xl - Xr)/Xmax , which is thereby normalized to values between 0 to 1. Segmentation When you specify ImageType = Segmentation in ImageRequest , you get an image that gives you ground truth segmentation of the scene. At the startup, AirSim assigns value 0 to 255 to each mesh available in environment. This value is than mapped to a specific color in the pallet . The RGB values for each object ID can be found in this file . You can assign a specific value (limited to the range 0-255) to a specific mesh using APIs. For example, below Python code sets the object ID for the mesh called \"Ground\" to 20 in Blocks environment and hence changes its color in Segmentation view: success = client.simSetSegmentationObjectID(\"Ground\", 20); The return value is a boolean type that lets you know if the mesh was found. Notice that typical Unreal environments, like Blocks, usually have many other meshes that comprises of same object, for example, \"Ground_2\", \"Ground_3\" and so on. As it is tedious to set object ID for all of these meshes, AirSim also supports regular expressions. For example, the code below sets all meshes which have names starting with \"ground\" (ignoring case) to 21 with just one line: success = client.simSetSegmentationObjectID(\"ground[\\w]*\", 21, True); The return value is true if at least one mesh was found using regular expression matching. It is recommended that you request uncompressed image using this API to ensure you get precise RGB values for segmentation image: responses = client.simGetImages([ImageRequest(0, AirSimImageType.Segmentation, False, False)]) img1d = np.fromstring(response.image_data_uint8, dtype=np.uint8) #get numpy array img_rgba = img1d.reshape(response.height, response.width, 4) #reshape array to 4 channel image array H X W X 4 img_rgba = np.flipud(img_rgba) #original image is fliped vertically #find unique colors print(np.unique(img_rgba[:,:,0], return_counts=True)) #red print(np.unique(img_rgba[:,:,1], return_counts=True)) #green print(np.unique(img_rgba[:,:,2], return_counts=True)) #blue A complete ready-to-run example can be found in segmentation.py . Unsetting object ID An object's ID can be set to -1 to make it not show up on the segmentation image. How to Find Mesh Names? To get desired ground truth segmentation you will need to know the names of the meshes in your Unreal environment. To do this, you will need to open up Unreal Environment in Unreal Editor and then inspect the names of the meshes you are interested in using the World Outliner. For example, below we see the mesh names for he ground in Blocks environment in right panel in the editor: If you don't know how to open Unreal Environment in Unreal Editor then try following the guide for building from source . Once you decide on the meshes you are interested, note down their names and use above API to set their object IDs. There are few settings available to change object ID generation behavior. Changing Colors for Object IDs At present the color for each object ID is fixed as in this palate . We will be adding ability to change colors for object IDs to desired values shortly. In the meantime you can open the segmentation image in your favorite image editor and get the RGB values you are interested in. Startup Object IDs At the start, AirSim assigns object ID to each object found in environment of type UStaticMeshComponent or ALandscapeProxy . It then either uses mesh name or owner name (depending on settings), lower cases it, removes any chars below ASCII 97 to remove numbers and some punctuations, sums int value of all chars and modulo 255 to generate the object ID. In other words, all object with same alphabet chars would get same object ID. This heuristic is simple and effective for many Unreal environments but may not be what you want. In that case, please use above APIs to change object IDs to your desired values. There are few settings available to change this behavior. Getting Object ID for Mesh The simGetSegmentationObjectID API allows you get object ID for given mesh name. Infrared Currently this is just a map from object ID to grey scale 0-255. So any mesh with object ID 42 shows up with color (42, 42, 42). Please see segmentation section for more details on how to set object IDs. Typically noise setting can be applied for this image type to get slightly more realistic effect. We are still working on adding other infrared artifacts and any contributions are welcome. Example Code A complete example of setting vehicle positions at random locations and orientations and then taking images can be found in GenerateImageGenerator.hpp . This example generates specified number of stereo images and ground truth disparity image and saving it to pfm format .","title":"Image APIs"},{"location":"docs/image_apis/#image-apis","text":"Please read general API doc first if you are not familiar with AirSim APIs.","title":"Image APIs"},{"location":"docs/image_apis/#getting-a-single-image","text":"Here's a sample code to get a single image from camera named \"0\". The returned value is bytes of png format image. To get uncompressed and other format as well as available cameras please see next sections.","title":"Getting a Single Image"},{"location":"docs/image_apis/#python","text":"import airsim #pip install airsim # for car use CarClient() client = airsim.MultirotorClient() png_image = client.simGetImage(\"0\", airsim.ImageType.Scene) # do something with image","title":"Python"},{"location":"docs/image_apis/#c","text":"#include \"vehicles/multirotor/api/MultirotorRpcLibClient.hpp\" int getOneImage() { using namespace std; using namespace msr::airlib; //for car use CarRpcLibClient msr::airlib::MultirotorRpcLibClient client; vector<uint8_t> png_image = client.simGetImage(\"0\", VehicleCameraBase::ImageType::Scene); //do something with images }","title":"C++"},{"location":"docs/image_apis/#getting-images-with-more-flexibility","text":"The simGetImages API which is slightly more complex to use than simGetImage API, for example, you can get left camera view, right camera view and depth image from left camera in a single API call. The simGetImages API also allows you to get uncompressed images as well as floating point single channel images (instead of 3 channel (RGB), each 8 bit).","title":"Getting Images with More Flexibility"},{"location":"docs/image_apis/#python_1","text":"import airsim #pip install airsim # for car use CarClient() client = airsim.MultirotorClient() responses = client.simGetImages([ # png format airsim.ImageRequest(0, airsim.ImageType.Scene), # uncompressed RGBA array bytes airsim.ImageRequest(1, airsim.ImageType.Scene, False, False), # floating point uncompressed image airsim.ImageRequest(1, airsim.ImageType.DepthPlanner, True)]) # do something with response which contains image data, pose, timestamp etc","title":"Python"},{"location":"docs/image_apis/#using-airsim-images-with-numpy","text":"If you plan to use numpy for image manipulation, you should get uncompressed RGBA image and then convert to numpy like this: responses = client.simGetImages([ImageRequest(\"0\", airsim.ImageType.Scene, False, False)]) response = responses[0] # get numpy array img1d = np.fromstring(response.image_data_uint8, dtype=np.uint8) # reshape array to 4 channel image array H X W X 4 img_rgba = img1d.reshape(response.height, response.width, 4) # original image is fliped vertically img_rgba = np.flipud(img_rgba) # just for fun add little bit of green in all pixels img_rgba[:,:,1:2] = 100 # write to png airsim.write_png(os.path.normpath(filename + '.greener.png'), img_rgba)","title":"Using AirSim Images with NumPy"},{"location":"docs/image_apis/#quick-tips","text":"The API simGetImage returns binary string literal which means you can simply dump it in binary file to create a .png file. However if you want to process it in any other way than you can handy function airsim.string_to_uint8_array . This converts binary string literal to NumPy uint8 array. The API simGetImages can accept request for multiple image types from any cameras in single call. You can specify if image is png compressed, RGB uncompressed or float array. For png compressed images, you get binary string literal . For float array you get Python list of float64. You can convert this float array to NumPy 2D array using airsim.list_to_2d_float_array(response.image_data_float, response.width, response.height) You can also save float array to .pfm file (Portable Float Map format) using airsim.write_pfm() function.","title":"Quick Tips"},{"location":"docs/image_apis/#c_1","text":"int getStereoAndDepthImages() { using namespace std; using namespace msr::airlib; typedef VehicleCameraBase::ImageRequest ImageRequest; typedef VehicleCameraBase::ImageResponse ImageResponse; typedef VehicleCameraBase::ImageType ImageType; //for car use //msr::airlib::CarRpcLibClient client; msr::airlib::MultirotorRpcLibClient client; //get right, left and depth images. First two as png, second as float16. vector<ImageRequest> request = { //png format ImageRequest(\"0\", ImageType::Scene), //uncompressed RGBA array bytes ImageRequest(\"1\", ImageType::Scene, false, false), //floating point uncompressed image ImageRequest(\"1\", ImageType::DepthPlanner, true) }; const vector<ImageResponse>& response = client.simGetImages(request); //do something with response which contains image data, pose, timestamp etc }","title":"C++"},{"location":"docs/image_apis/#ready-to-run-complete-examples","text":"","title":"Ready to Run Complete Examples"},{"location":"docs/image_apis/#python_2","text":"For a more complete ready to run sample code please see sample code in AirSimClient project for multirotors or HelloCar sample . This code also demonstrates simple activities such as saving images in files or using numpy to manipulate images.","title":"Python"},{"location":"docs/image_apis/#c_2","text":"For a more complete ready to run sample code please see sample code in HelloDrone project for multirotors or HelloCar project . See also other example code that generates specified number of stereo images along with ground truth depth and disparity and saving it to pfm format .","title":"C++"},{"location":"docs/image_apis/#available-cameras","text":"","title":"Available Cameras"},{"location":"docs/image_apis/#car","text":"The cameras on car can be accessed by following names in API calls: front_center , front_right , front_left , fpv and back_center . Here FPV camera is driver's head position in the car.","title":"Car"},{"location":"docs/image_apis/#multirotor","text":"The cameras in CV mode can be accessed by following names in API calls: front_center , front_right , front_left , bottom_center and back_center .","title":"Multirotor"},{"location":"docs/image_apis/#computer-vision-mode","text":"Camera names are same as in multirotor.","title":"Computer Vision Mode"},{"location":"docs/image_apis/#backward-compatibility-for-camera-names","text":"Before AirSim v1.2, cameras were accessed using ID numbers instead of names. For backward compatibility you can still use following ID numbers for above camera names in same order as above: \"0\" , \"1\" , \"2\" , \"3\" , \"4\" . In addition, camera name \"\" is also available to access the default camera which is generally the camera \"0\" .","title":"Backward compatibility for camera names"},{"location":"docs/image_apis/#computer-vision-mode_1","text":"You can use AirSim in so-called \"Computer Vision\" mode. In this mode, physics engine is disabled and there is no vehicle, just cameras. You can move around using keyboard (use F1 to see help on keys). You can press Record button to continuously generate images. Or you can call APIs to move cameras around and take images. To active this mode, edit settings.json that you can find in your Documents\\AirSim folder (or ~/Documents/AirSim on Linux) and make sure following values exist at root level: { \"SettingsVersion\": 1.2, \"SimMode\": \"ComputerVision\" } Here's the Python code example to move camera around and capture images. This mode was inspired from UnrealCV project .","title":"\"Computer Vision\" Mode"},{"location":"docs/image_apis/#setting-pose-in-computer-vision-mode","text":"To move around the environment using APIs you can use simSetVehiclePose API. This API takes position and orientation and sets that on the invisible vehicle where the front-center camera is located. All rest of the cameras move along keeping the relative position. If you don't want to change position (or orientation) then just set components of position (or orientation) to floating point nan values. The simGetVehiclePose allows to retrieve the current pose. You can also use simGetGroundTruthKinematics to get the quantities kinematics quantities for the movement. Many other non-vehicle specific APIs are also available such as segmentation APIs, collision APIs and camera APIs.","title":"Setting Pose in Computer Vision Mode"},{"location":"docs/image_apis/#camera-apis","text":"The simGetCameraInfo returns the pose (in world frame, NED coordinates, SI units) and FOV (in degrees) for the specified camera. Please see example usage . The simSetCameraOrientation sets the orientation for the specified camera as quaternion in NED frame. The handy airsim.to_quaternion() function allows to convert pitch, roll, yaw to quaternion. For example, to set camera-0 to 15-degree pitch, you can use: client.simSetCameraOrientation(0, airsim.toQuaternion(0.261799, 0, 0)); #radians","title":"Camera APIs"},{"location":"docs/image_apis/#gimbal","text":"You can set stabilization for pitch, roll or yaw for any camera using settings . Please see example usage .","title":"Gimbal"},{"location":"docs/image_apis/#changing-resolution-and-camera-parameters","text":"To change resolution, FOV etc, you can use settings.json . For example, below addition in settings.json sets parameters for scene capture and uses \"Computer Vision\" mode described above. If you omit any setting then below default values will be used. For more information see settings doc . If you are using stereo camera, currently the distance between left and right is fixed at 25 cm. { \"SettingsVersion\": 1.2, \"CameraDefaults\": { \"CaptureSettings\": [ { \"ImageType\": 0, \"Width\": 256, \"Height\": 144, \"FOV_Degrees\": 90, \"AutoExposureSpeed\": 100, \"MotionBlurAmount\": 0 } ] }, \"SimMode\": \"ComputerVision\" }","title":"Changing Resolution and Camera Parameters"},{"location":"docs/image_apis/#what-does-pixel-values-mean-in-different-image-types","text":"","title":"What Does Pixel Values Mean in Different Image Types?"},{"location":"docs/image_apis/#available-imagetype-values","text":"Scene = 0, DepthPlanner = 1, DepthPerspective = 2, DepthVis = 3, DisparityNormalized = 4, Segmentation = 5, SurfaceNormals = 6, Infrared = 7","title":"Available ImageType Values"},{"location":"docs/image_apis/#depthplanner-and-depthperspective","text":"You normally want to retrieve the depth image as float (i.e. set pixels_as_float = true ) and specify ImageType = DepthPlanner or ImageType = DepthPerspective in ImageRequest . For ImageType = DepthPlanner , you get depth in camera plan, i.e., all points that are in plan parallel to camera have same depth. For ImageType = DepthPerspective , you get depth from camera using a projection ray that hits that pixel. Depending on your use case, planner depth or perspective depth may be the ground truth image that you want. For example, you may be able to feed perspective depth to ROS package such as depth_image_proc to generate a point cloud. Or planner depth may be more compatible with estimated depth image generated by stereo algorithms such as SGM.","title":"DepthPlanner and DepthPerspective"},{"location":"docs/image_apis/#depthvis","text":"When you specify ImageType = DepthVis in ImageRequest , you get an image that helps depth visualization. In this case, each pixel value is interpolated from black to white depending on depth in camera plane in meters. The pixels with pure white means depth of 100m or more while pure black means depth of 0 meters.","title":"DepthVis"},{"location":"docs/image_apis/#disparitynormalized","text":"You normally want to retrieve disparity image as float (i.e. set pixels_as_float = true and specify ImageType = DisparityNormalized in ImageRequest ) in which case each pixel is (Xl - Xr)/Xmax , which is thereby normalized to values between 0 to 1.","title":"DisparityNormalized"},{"location":"docs/image_apis/#segmentation","text":"When you specify ImageType = Segmentation in ImageRequest , you get an image that gives you ground truth segmentation of the scene. At the startup, AirSim assigns value 0 to 255 to each mesh available in environment. This value is than mapped to a specific color in the pallet . The RGB values for each object ID can be found in this file . You can assign a specific value (limited to the range 0-255) to a specific mesh using APIs. For example, below Python code sets the object ID for the mesh called \"Ground\" to 20 in Blocks environment and hence changes its color in Segmentation view: success = client.simSetSegmentationObjectID(\"Ground\", 20); The return value is a boolean type that lets you know if the mesh was found. Notice that typical Unreal environments, like Blocks, usually have many other meshes that comprises of same object, for example, \"Ground_2\", \"Ground_3\" and so on. As it is tedious to set object ID for all of these meshes, AirSim also supports regular expressions. For example, the code below sets all meshes which have names starting with \"ground\" (ignoring case) to 21 with just one line: success = client.simSetSegmentationObjectID(\"ground[\\w]*\", 21, True); The return value is true if at least one mesh was found using regular expression matching. It is recommended that you request uncompressed image using this API to ensure you get precise RGB values for segmentation image: responses = client.simGetImages([ImageRequest(0, AirSimImageType.Segmentation, False, False)]) img1d = np.fromstring(response.image_data_uint8, dtype=np.uint8) #get numpy array img_rgba = img1d.reshape(response.height, response.width, 4) #reshape array to 4 channel image array H X W X 4 img_rgba = np.flipud(img_rgba) #original image is fliped vertically #find unique colors print(np.unique(img_rgba[:,:,0], return_counts=True)) #red print(np.unique(img_rgba[:,:,1], return_counts=True)) #green print(np.unique(img_rgba[:,:,2], return_counts=True)) #blue A complete ready-to-run example can be found in segmentation.py .","title":"Segmentation"},{"location":"docs/image_apis/#unsetting-object-id","text":"An object's ID can be set to -1 to make it not show up on the segmentation image.","title":"Unsetting object ID"},{"location":"docs/image_apis/#how-to-find-mesh-names","text":"To get desired ground truth segmentation you will need to know the names of the meshes in your Unreal environment. To do this, you will need to open up Unreal Environment in Unreal Editor and then inspect the names of the meshes you are interested in using the World Outliner. For example, below we see the mesh names for he ground in Blocks environment in right panel in the editor: If you don't know how to open Unreal Environment in Unreal Editor then try following the guide for building from source . Once you decide on the meshes you are interested, note down their names and use above API to set their object IDs. There are few settings available to change object ID generation behavior.","title":"How to Find Mesh Names?"},{"location":"docs/image_apis/#changing-colors-for-object-ids","text":"At present the color for each object ID is fixed as in this palate . We will be adding ability to change colors for object IDs to desired values shortly. In the meantime you can open the segmentation image in your favorite image editor and get the RGB values you are interested in.","title":"Changing Colors for Object IDs"},{"location":"docs/image_apis/#startup-object-ids","text":"At the start, AirSim assigns object ID to each object found in environment of type UStaticMeshComponent or ALandscapeProxy . It then either uses mesh name or owner name (depending on settings), lower cases it, removes any chars below ASCII 97 to remove numbers and some punctuations, sums int value of all chars and modulo 255 to generate the object ID. In other words, all object with same alphabet chars would get same object ID. This heuristic is simple and effective for many Unreal environments but may not be what you want. In that case, please use above APIs to change object IDs to your desired values. There are few settings available to change this behavior.","title":"Startup Object IDs"},{"location":"docs/image_apis/#getting-object-id-for-mesh","text":"The simGetSegmentationObjectID API allows you get object ID for given mesh name.","title":"Getting Object ID for Mesh"},{"location":"docs/image_apis/#infrared","text":"Currently this is just a map from object ID to grey scale 0-255. So any mesh with object ID 42 shows up with color (42, 42, 42). Please see segmentation section for more details on how to set object IDs. Typically noise setting can be applied for this image type to get slightly more realistic effect. We are still working on adding other infrared artifacts and any contributions are welcome.","title":"Infrared"},{"location":"docs/image_apis/#example-code","text":"A complete example of setting vehicle positions at random locations and orientations and then taking images can be found in GenerateImageGenerator.hpp . This example generates specified number of stereo images and ground truth disparity image and saving it to pfm format .","title":"Example Code"},{"location":"docs/lidar/","text":"How to Use Lidar in AirSim AirSim supports Lidar for multirotors and cars. The enablement of lidar and the other lidar settings can be configured via AirSimSettings json. Please see general sensors for information on configruation of general/shared sensor settings. Enabling lidar on a vehicle By default, lidars are not enabled. To enable lidar, set the SensorType and Enabled attributes in settings json. \"Lidar1\": { \"SensorType\": 6, \"Enabled\" : true, Multiple lidars can be enabled on a vehicle. Lidar configuration The following parameters can be configured right now via settings json. Parameter Description NumberOfChannels Number of channels/lasers of the lidar Range Range, in meters PointsPerSecond Number of points captured per second RotationsPerSecond Rotations per second VerticalFOVUpper Vertical FOV upper limit for the lidar, in degrees VerticalFOVLower Vertical FOV lower limit for the lidar, in degrees X Y Z Position of the lidar relative to the vehicle (in NED, in meters) Roll Pitch Yaw Roation of the lidar relative to the vehicle (in degrees) e.g., \"Lidar1\": { \"SensorType\": 6, \"Enabled\" : true, \"NumberOfChannels\": 16, \"PointsPerSecond\": 10000, \"X\": 0, \"Y\": 0, \"Z\": -1, Server side visualization for debugging Be default, the lidar points are not drawn on the viewport. To enable the drawing of hit laser points on the viewport, please enable setting 'DrawDebugPoints' via settings json. e.g., \"Lidar1\": { ... \"DrawDebugPoints\": true }, Client API Use getLidarData() API to retrieve the Lidar data. The API returns a Point-Cloud as a flat array of floats along with a timestamp of the capture. The floats represent [x,y,z] coordinate for each point hit within the range in the last scan. * The coordinates are in the local vehicle NED like all other AirSim APIs. Python Examples drone_lidar.py car_lidar.py Coming soon Visualization of lidar data on client side.","title":"LIDAR"},{"location":"docs/lidar/#how-to-use-lidar-in-airsim","text":"AirSim supports Lidar for multirotors and cars. The enablement of lidar and the other lidar settings can be configured via AirSimSettings json. Please see general sensors for information on configruation of general/shared sensor settings.","title":"How to Use Lidar in AirSim"},{"location":"docs/lidar/#enabling-lidar-on-a-vehicle","text":"By default, lidars are not enabled. To enable lidar, set the SensorType and Enabled attributes in settings json. \"Lidar1\": { \"SensorType\": 6, \"Enabled\" : true, Multiple lidars can be enabled on a vehicle.","title":"Enabling lidar on a vehicle"},{"location":"docs/lidar/#lidar-configuration","text":"The following parameters can be configured right now via settings json. Parameter Description NumberOfChannels Number of channels/lasers of the lidar Range Range, in meters PointsPerSecond Number of points captured per second RotationsPerSecond Rotations per second VerticalFOVUpper Vertical FOV upper limit for the lidar, in degrees VerticalFOVLower Vertical FOV lower limit for the lidar, in degrees X Y Z Position of the lidar relative to the vehicle (in NED, in meters) Roll Pitch Yaw Roation of the lidar relative to the vehicle (in degrees) e.g., \"Lidar1\": { \"SensorType\": 6, \"Enabled\" : true, \"NumberOfChannels\": 16, \"PointsPerSecond\": 10000, \"X\": 0, \"Y\": 0, \"Z\": -1,","title":"Lidar configuration"},{"location":"docs/lidar/#server-side-visualization-for-debugging","text":"Be default, the lidar points are not drawn on the viewport. To enable the drawing of hit laser points on the viewport, please enable setting 'DrawDebugPoints' via settings json. e.g., \"Lidar1\": { ... \"DrawDebugPoints\": true },","title":"Server side visualization for debugging"},{"location":"docs/lidar/#client-api","text":"Use getLidarData() API to retrieve the Lidar data. The API returns a Point-Cloud as a flat array of floats along with a timestamp of the capture. The floats represent [x,y,z] coordinate for each point hit within the range in the last scan. * The coordinates are in the local vehicle NED like all other AirSim APIs.","title":"Client API"},{"location":"docs/lidar/#python-examples","text":"drone_lidar.py car_lidar.py","title":"Python Examples"},{"location":"docs/lidar/#coming-soon","text":"Visualization of lidar data on client side.","title":"Coming soon"},{"location":"docs/log_viewer/","text":"Log Viewer The LogViewer is a Windows WPF app that presents the MavLink streams that it is getting from the Unreal Simulator. You can use this to monitor what is happening on the drone while it is flying. For example, the picture below shows a real time graph of the x, y an z gyro sensor information being generated by the simulator. Usage To use this LogViewer, connect the simulator before you run the simulation. Simply press the blue connector button on the top right corner of the window, select the Socket tab , enter the port number 14388, and your localhost network. Then press the record button (triangle on the right hand side of the toolbar). Now start the simulator, pick some mavlink items to graph, you should see something like this: The drone view here is the actual estimated position coming from the PX4, so that is a great way to check whether the PX4 is in sync with the simulator. Sometimes you can see some drift here as the attitude estimation catches up with reality, this is more visible after a bad crash. Installation If you can't build the LogViewer.sln, there is also a click once installer . Configuration The magic port number 14388 can be configured in the simulator by editing the settings.json file .","title":"MavLink LogViewer"},{"location":"docs/log_viewer/#log-viewer","text":"The LogViewer is a Windows WPF app that presents the MavLink streams that it is getting from the Unreal Simulator. You can use this to monitor what is happening on the drone while it is flying. For example, the picture below shows a real time graph of the x, y an z gyro sensor information being generated by the simulator.","title":"Log Viewer"},{"location":"docs/log_viewer/#usage","text":"To use this LogViewer, connect the simulator before you run the simulation. Simply press the blue connector button on the top right corner of the window, select the Socket tab , enter the port number 14388, and your localhost network. Then press the record button (triangle on the right hand side of the toolbar). Now start the simulator, pick some mavlink items to graph, you should see something like this: The drone view here is the actual estimated position coming from the PX4, so that is a great way to check whether the PX4 is in sync with the simulator. Sometimes you can see some drift here as the attitude estimation catches up with reality, this is more visible after a bad crash.","title":"Usage"},{"location":"docs/log_viewer/#installation","text":"If you can't build the LogViewer.sln, there is also a click once installer .","title":"Installation"},{"location":"docs/log_viewer/#configuration","text":"The magic port number 14388 can be configured in the simulator by editing the settings.json file .","title":"Configuration"},{"location":"docs/multi_vehicle/","text":"Multiple Vehicles in AirSim Since release 1.2, AirSim is fully enabled for multiple vehicles. This capability allows you to create multiple vehicles easily and use APIs to control them. Creating Multiple Vehicles It's as easy as specifying them in settings.json . The Vehicles element allows you to specify list of vehicles you want to create along with their initial positions and orientations. The positions are specified in NED coordinates in SI units with origin set at Player Start component in Unreal environment. The orientation is specified as Yaw, Pitch and Roll in degrees. Creating Multiple Cars { \"SettingsVersion\": 1.2, \"SimMode\": \"Car\", \"Vehicles\": { \"Car1\": { \"VehicleType\": \"PhysXCar\", \"X\": 4, \"Y\": 0, \"Z\": -2 }, \"Car2\": { \"VehicleType\": \"PhysXCar\", \"X\": -4, \"Y\": 0, \"Z\": -2, \"Yaw\": 90 } } } Creating Multiple Drones { \"SettingsVersion\": 1.2, \"SimMode\": \"Multirotor\", \"Vehicles\": { \"Drone1\": { \"VehicleType\": \"SimpleFlight\", \"X\": 4, \"Y\": 0, \"Z\": -2, \"Yaw\": -180 }, \"Drone2\": { \"VehicleType\": \"SimpleFlight\", \"X\": 8, \"Y\": 0, \"Z\": -2 } } } Using APIs for Multiple Vehicles The new APIs since AirSim 1.2 allows you to specify vehicle_name . This name corresponds to keys in json settings (for example, Car1 or Drone2 above). Example code for cars Example code for multirotors Demo","title":"Multiple Vehicles"},{"location":"docs/multi_vehicle/#multiple-vehicles-in-airsim","text":"Since release 1.2, AirSim is fully enabled for multiple vehicles. This capability allows you to create multiple vehicles easily and use APIs to control them.","title":"Multiple Vehicles in AirSim"},{"location":"docs/multi_vehicle/#creating-multiple-vehicles","text":"It's as easy as specifying them in settings.json . The Vehicles element allows you to specify list of vehicles you want to create along with their initial positions and orientations. The positions are specified in NED coordinates in SI units with origin set at Player Start component in Unreal environment. The orientation is specified as Yaw, Pitch and Roll in degrees.","title":"Creating Multiple Vehicles"},{"location":"docs/multi_vehicle/#creating-multiple-cars","text":"{ \"SettingsVersion\": 1.2, \"SimMode\": \"Car\", \"Vehicles\": { \"Car1\": { \"VehicleType\": \"PhysXCar\", \"X\": 4, \"Y\": 0, \"Z\": -2 }, \"Car2\": { \"VehicleType\": \"PhysXCar\", \"X\": -4, \"Y\": 0, \"Z\": -2, \"Yaw\": 90 } } }","title":"Creating Multiple Cars"},{"location":"docs/multi_vehicle/#creating-multiple-drones","text":"{ \"SettingsVersion\": 1.2, \"SimMode\": \"Multirotor\", \"Vehicles\": { \"Drone1\": { \"VehicleType\": \"SimpleFlight\", \"X\": 4, \"Y\": 0, \"Z\": -2, \"Yaw\": -180 }, \"Drone2\": { \"VehicleType\": \"SimpleFlight\", \"X\": 8, \"Y\": 0, \"Z\": -2 } } }","title":"Creating Multiple Drones"},{"location":"docs/multi_vehicle/#using-apis-for-multiple-vehicles","text":"The new APIs since AirSim 1.2 allows you to specify vehicle_name . This name corresponds to keys in json settings (for example, Car1 or Drone2 above). Example code for cars Example code for multirotors","title":"Using APIs for Multiple Vehicles"},{"location":"docs/multi_vehicle/#demo","text":"","title":"Demo"},{"location":"docs/pfm/","text":"pfm Format Pfm (or Portable FloatMap) image format stores image as floating point pixels and hence are not restricted to usual 0-255 pixel value range. This is useful for HDR images or images that describes something other than colors like depth. One of the good viewer to view this file format is PfmPad . We don't recommend Maverick photo viewer because it doesn't seem to show depth images properly. AirSim has code to write pfm file for C++ and read as well as write for Python .","title":"pfm format"},{"location":"docs/pfm/#pfm-format","text":"Pfm (or Portable FloatMap) image format stores image as floating point pixels and hence are not restricted to usual 0-255 pixel value range. This is useful for HDR images or images that describes something other than colors like depth. One of the good viewer to view this file format is PfmPad . We don't recommend Maverick photo viewer because it doesn't seem to show depth images properly. AirSim has code to write pfm file for C++ and read as well as write for Python .","title":"pfm Format"},{"location":"docs/playback/","text":"Playback AirSim supports playing back the high level commands in a *.mavlink log file that were recorded using the MavLinkTest app for the purpose of comparing real and simulated flight. The recording.mavlink is an example of a log file captured using a real drone using the following command line: MavLinkTest -serial:/dev/ttyACM0,115200 -logdir:. Then the log file contains the commands performed, which included several \"orbit\" commands, the resulting GPS map of the flight looks like this: Side-by-side comparison Now we can copy the *.mavlink log file recorded by MavLinkTest to the PC running the Unreal simulator with AirSim plugin. When the Simulator is running and the drone is parked in a place in a map that has room to do the same maneuvers we can run this MavLinkTest command line: MavLinkTest -server:127.0.0.1:14550 This should connect to the simulator. Now you can enter this command: PlayLog recording.mavlink The same commands you performed on the real drone will now play again in the simulator. You can then press 't' to see the trace, and it will show you the trace of the real drone and the simulated drone. Every time you press 't' again you can reset the lines so they are sync'd to the current position, this way I was able to capture a side-by-side trace of the \"orbit\" command performed in this recording, which generates the picture below. The pink line is the simulated flight and the red line is the real flight: Note: I'm using the ';' key in the simulator to take control of camera position using keyboard to get this shot. Parameters It may help to set the simulator up with some of the same flight parameters that your real drone is using, for example, in my case I was using a lower than normal cruise speed, slow takeoff speed, and it helps to tell the simulator to wait a long time before disarming (COM_DISARM_LAND) and to turn off the safety switches NAV_RCL_ACT and NAV_DLL_ACT ( don't do that on a real drone). param MPC_XY_CRUISE 2 param MPC_XY_VEL_MAX 2 param MPC_TKO_SPEED 1 param COM_DISARM_LAND 60 param NAV_RCL_ACT 0 param NAV_DLL_ACT 0","title":"Playing Logs"},{"location":"docs/playback/#playback","text":"AirSim supports playing back the high level commands in a *.mavlink log file that were recorded using the MavLinkTest app for the purpose of comparing real and simulated flight. The recording.mavlink is an example of a log file captured using a real drone using the following command line: MavLinkTest -serial:/dev/ttyACM0,115200 -logdir:. Then the log file contains the commands performed, which included several \"orbit\" commands, the resulting GPS map of the flight looks like this:","title":"Playback"},{"location":"docs/playback/#side-by-side-comparison","text":"Now we can copy the *.mavlink log file recorded by MavLinkTest to the PC running the Unreal simulator with AirSim plugin. When the Simulator is running and the drone is parked in a place in a map that has room to do the same maneuvers we can run this MavLinkTest command line: MavLinkTest -server:127.0.0.1:14550 This should connect to the simulator. Now you can enter this command: PlayLog recording.mavlink The same commands you performed on the real drone will now play again in the simulator. You can then press 't' to see the trace, and it will show you the trace of the real drone and the simulated drone. Every time you press 't' again you can reset the lines so they are sync'd to the current position, this way I was able to capture a side-by-side trace of the \"orbit\" command performed in this recording, which generates the picture below. The pink line is the simulated flight and the red line is the real flight: Note: I'm using the ';' key in the simulator to take control of camera position using keyboard to get this shot.","title":"Side-by-side comparison"},{"location":"docs/playback/#parameters","text":"It may help to set the simulator up with some of the same flight parameters that your real drone is using, for example, in my case I was using a lower than normal cruise speed, slow takeoff speed, and it helps to tell the simulator to wait a long time before disarming (COM_DISARM_LAND) and to turn off the safety switches NAV_RCL_ACT and NAV_DLL_ACT ( don't do that on a real drone). param MPC_XY_CRUISE 2 param MPC_XY_VEL_MAX 2 param MPC_TKO_SPEED 1 param COM_DISARM_LAND 60 param NAV_RCL_ACT 0 param NAV_DLL_ACT 0","title":"Parameters"},{"location":"docs/px4_build/","text":"Building PX4 Source code Getting the PX4 source code is easy: git clone https://github.com/PX4/Firmware.git cd Firmware Oh, and if you don't have git yet just run this: sudo apt-get install git We are currently testing using the 1.6.0rc1 version, but the latest master branch should be ok too. Now to build it you will need the right tools. PX4 Build tools The full instructions are available on the dev.px4.io website, but we've copied the relevant subset of those instructions here for your convenience. (Note that BashOnWindows ) can be used to build the SITL version, but not the ARM firmware for pixhawk harddware). First run this command to cache your admin credentials: sudo ls Now you can block copy/paste the following to a bash terminal and it should run them all to completion, but be sure to check each command for success: sudo add-apt-repository ppa:george-edison55/cmake-3.x -y sudo apt-get update sudo apt-get install python-argparse git-core wget zip \\ python-empy cmake build-essential genromfs -y sudo apt-get install python-serial openocd \\ flex bison libncurses5-dev autoconf texinfo libftdi-dev libtool zlib1g-dev -y sudo apt-get install python-pip python-jinja2 -y Build SITL version Now you can make the SITL version that runs in posix, from the Firmware folder you created above: make posix_sitl_default Note: this build system is quite special, it knows how to update git submodules (and there's a lot of them), then it runs cmake (if necessary), then it runs the build itself. So in a way the root Makefile is a meta-meta makefile :-) It shouldn't take long, about 2 minutes. If all succeeds, the last line will link the px4 app, which you can then run using the following: ./build_posix_sitl_default/src/firmware/posix/px4 ./posix-configs/SITL/init/ekf2/iris And you should see output that looks like this: creating new parameters file creating new dataman file ______ __ __ ___ | ___ \\ \\ \\ / / / | | |_/ / \\ V / / /| | | __/ / \\ / /_| | | | / /^\\ \\ \\___ | \\_| \\/ \\/ |_/ px4 starting. 18446744073709551615 WARNING: setRealtimeSched failed (not run as root?) ERROR [param] importing from 'rootfs/eeprom/parameters' failed (-1) Command 'param' failed, returned 1 SYS_AUTOSTART: curr: 0 -> new: 4010 SYS_MC_EST_GROUP: curr: 2 -> new: 1 INFO [dataman] Unkown restart, data manager file 'rootfs/fs/microsd/dataman' size is 11797680 bytes BAT_N_CELLS: curr: 0 -> new: 3 CAL_GYRO0_ID: curr: 0 -> new: 2293768 CAL_ACC0_ID: curr: 0 -> new: 1376264 CAL_ACC1_ID: curr: 0 -> new: 1310728 CAL_MAG0_ID: curr: 0 -> new: 196616 so this is good, first run sets up the px4 parameters for SITL mode. Second run has less output. This app is also an interactive console where you can type commands. Type 'help' to see what they are and just type ctrl-C to kill it. You can do that and restart it any time, that's a great way to reset any wonky state if you need to (it's equivalent to a Pixhawk hardware reboot). ARM embedded tools If you plan to build the PX4 firmware for real Pixhawk hardware then you will need the gcc cross-compiler for ARM Cortex-M4 chipset. You can find out what version, if any, you may already have by typing this command arm-none-eabi-gcc --version . Note: you do not need this to build the SITL version of PX4. Note: This does not work in BashOnWindows because the arm-none-eabi-gcc tool is a 32-bit app which BashOnWindows cannot run. See installing arm-none-eabi-gcc on BashOnWindows at the bottom of this page. Anyway, first we make sure to remove any old version of arm-none-eabi-gcc: sudo apt-get remove gcc-arm-none-eabi gdb-arm-none-eabi binutils-arm-none-eabi gcc-arm-embedded -y sudo add-apt-repository --remove ppa:team-gcc-arm-embedded/ppa -y That previous command prompts you to hit ENTER, so be sure to run that separately before the following: pushd . cd ~ wget https://launchpad.net/gcc-arm-embedded/5.0/5-2016-q2-update/+download/gcc-arm-none-eabi-5_4-2016q2-20160622-linux.tar.bz2 tar -jxf gcc-arm-none-eabi-5_4-2016q2-20160622-linux.tar.bz2 exportline=\"export PATH=$HOME/gcc-arm-none-eabi-5_4-2016q2/bin:\\$PATH\" if grep -Fxq \"$exportline\" ~/.profile; then echo nothing to do ; else echo $exportline >> ~/.profile; fi . ~/.profile popd sudo dpkg --add-architecture i386 sudo apt-get update sudo apt-get install libc6:i386 libgcc1:i386 libstdc++5:i386 libstdc++6:i386 -y So now when you type this command arm-none-eabi-gcc --version and you should see: arm-none-eabi-gcc (GNU Tools for ARM Embedded Processors) 5.4.1 20160609 (release) [ARM/embedded-5-branch revision 237715] Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. Build PX4 for ARM hardware Now you can build the PX4 firmware for running on real pixhawk hardware: make px4fmu-v2_default This build will take a little longer because it is building a lot more including the NuttX real time OS, all the drivers for the sensors in the Pixhawk flight controller, and more. It is also running the compiler in super size-squeezing mode so it can fit all that in a 1 megabyte ROM !! One nice tid bit is you can plug in your pixhawk USB, and type make px4fmu-v2_default upload to flash the hardware with these brand new bits, so you don't need to use QGroundControl for that. Some Useful Parameters PX4 has many customizable parameters (over 700 of them, in fact) and to get best results with AirSim we have found the following parameters are handy: // be sure to enable the new position estimator module: param set SYS_MC_EST_GROUP 2 // increase default limits on cruise speed so you can move around a large map more quickly. param MPC_XY_CRUISE 10 param MPC_XY_VEL_MAX 10 param MPC_Z_VEL_MAX_DN 2 // increase timeout for auto-disarm on landing so that any long running app doesn't have to worry about it param COM_DISARM_LAND 60 // make it possible to fly without radio control attached (do NOT do this one on a real drone) param NAV_RCL_ACT 0 // enable new syslogger to get more information from PX4 logs param set SYS_LOGGER 1 Installing arm-none-eabi-gcc in BashOnWindows SolinGuo built a 64 bit version of gcc-arm-none-eabi so that it will run inside BashOnWindows . See gcc-arm-none-eabi-5_4-2017q2-20170512-linux.tar.bz2 . If you download the *.tar.bz2 file to your machine and unpack it using this command line in BashOnWindows console: tar -xvf gcc-arm-none-eabi-5_4-2017q2-20170512-linux.tar.bz2 you will get the following folder which contains the arm gcc cross-compiler: gcc-arm-none-eabi-5_4-2017q2/bin If you add this folder to your PATH using the usual export PATH=... trick then the PX4 build will be able to find and run this compiler. After that, you can run make px4fmu-v2_default in BashOnWindows and the firmware will appear here: build_px4fmu-v2_default/src/firmware/nuttx/px4fmu-v2_default.px4 . You can then flash this new firmware on your Pixhawk using QGroundControl.","title":"Building PX4"},{"location":"docs/px4_build/#building-px4","text":"","title":"Building PX4"},{"location":"docs/px4_build/#source-code","text":"Getting the PX4 source code is easy: git clone https://github.com/PX4/Firmware.git cd Firmware Oh, and if you don't have git yet just run this: sudo apt-get install git We are currently testing using the 1.6.0rc1 version, but the latest master branch should be ok too. Now to build it you will need the right tools.","title":"Source code"},{"location":"docs/px4_build/#px4-build-tools","text":"The full instructions are available on the dev.px4.io website, but we've copied the relevant subset of those instructions here for your convenience. (Note that BashOnWindows ) can be used to build the SITL version, but not the ARM firmware for pixhawk harddware). First run this command to cache your admin credentials: sudo ls Now you can block copy/paste the following to a bash terminal and it should run them all to completion, but be sure to check each command for success: sudo add-apt-repository ppa:george-edison55/cmake-3.x -y sudo apt-get update sudo apt-get install python-argparse git-core wget zip \\ python-empy cmake build-essential genromfs -y sudo apt-get install python-serial openocd \\ flex bison libncurses5-dev autoconf texinfo libftdi-dev libtool zlib1g-dev -y sudo apt-get install python-pip python-jinja2 -y","title":"PX4 Build tools"},{"location":"docs/px4_build/#build-sitl-version","text":"Now you can make the SITL version that runs in posix, from the Firmware folder you created above: make posix_sitl_default Note: this build system is quite special, it knows how to update git submodules (and there's a lot of them), then it runs cmake (if necessary), then it runs the build itself. So in a way the root Makefile is a meta-meta makefile :-) It shouldn't take long, about 2 minutes. If all succeeds, the last line will link the px4 app, which you can then run using the following: ./build_posix_sitl_default/src/firmware/posix/px4 ./posix-configs/SITL/init/ekf2/iris And you should see output that looks like this: creating new parameters file creating new dataman file ______ __ __ ___ | ___ \\ \\ \\ / / / | | |_/ / \\ V / / /| | | __/ / \\ / /_| | | | / /^\\ \\ \\___ | \\_| \\/ \\/ |_/ px4 starting. 18446744073709551615 WARNING: setRealtimeSched failed (not run as root?) ERROR [param] importing from 'rootfs/eeprom/parameters' failed (-1) Command 'param' failed, returned 1 SYS_AUTOSTART: curr: 0 -> new: 4010 SYS_MC_EST_GROUP: curr: 2 -> new: 1 INFO [dataman] Unkown restart, data manager file 'rootfs/fs/microsd/dataman' size is 11797680 bytes BAT_N_CELLS: curr: 0 -> new: 3 CAL_GYRO0_ID: curr: 0 -> new: 2293768 CAL_ACC0_ID: curr: 0 -> new: 1376264 CAL_ACC1_ID: curr: 0 -> new: 1310728 CAL_MAG0_ID: curr: 0 -> new: 196616 so this is good, first run sets up the px4 parameters for SITL mode. Second run has less output. This app is also an interactive console where you can type commands. Type 'help' to see what they are and just type ctrl-C to kill it. You can do that and restart it any time, that's a great way to reset any wonky state if you need to (it's equivalent to a Pixhawk hardware reboot).","title":"Build SITL version"},{"location":"docs/px4_build/#arm-embedded-tools","text":"If you plan to build the PX4 firmware for real Pixhawk hardware then you will need the gcc cross-compiler for ARM Cortex-M4 chipset. You can find out what version, if any, you may already have by typing this command arm-none-eabi-gcc --version . Note: you do not need this to build the SITL version of PX4. Note: This does not work in BashOnWindows because the arm-none-eabi-gcc tool is a 32-bit app which BashOnWindows cannot run. See installing arm-none-eabi-gcc on BashOnWindows at the bottom of this page. Anyway, first we make sure to remove any old version of arm-none-eabi-gcc: sudo apt-get remove gcc-arm-none-eabi gdb-arm-none-eabi binutils-arm-none-eabi gcc-arm-embedded -y sudo add-apt-repository --remove ppa:team-gcc-arm-embedded/ppa -y That previous command prompts you to hit ENTER, so be sure to run that separately before the following: pushd . cd ~ wget https://launchpad.net/gcc-arm-embedded/5.0/5-2016-q2-update/+download/gcc-arm-none-eabi-5_4-2016q2-20160622-linux.tar.bz2 tar -jxf gcc-arm-none-eabi-5_4-2016q2-20160622-linux.tar.bz2 exportline=\"export PATH=$HOME/gcc-arm-none-eabi-5_4-2016q2/bin:\\$PATH\" if grep -Fxq \"$exportline\" ~/.profile; then echo nothing to do ; else echo $exportline >> ~/.profile; fi . ~/.profile popd sudo dpkg --add-architecture i386 sudo apt-get update sudo apt-get install libc6:i386 libgcc1:i386 libstdc++5:i386 libstdc++6:i386 -y So now when you type this command arm-none-eabi-gcc --version and you should see: arm-none-eabi-gcc (GNU Tools for ARM Embedded Processors) 5.4.1 20160609 (release) [ARM/embedded-5-branch revision 237715] Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.","title":"ARM embedded tools"},{"location":"docs/px4_build/#build-px4-for-arm-hardware","text":"Now you can build the PX4 firmware for running on real pixhawk hardware: make px4fmu-v2_default This build will take a little longer because it is building a lot more including the NuttX real time OS, all the drivers for the sensors in the Pixhawk flight controller, and more. It is also running the compiler in super size-squeezing mode so it can fit all that in a 1 megabyte ROM !! One nice tid bit is you can plug in your pixhawk USB, and type make px4fmu-v2_default upload to flash the hardware with these brand new bits, so you don't need to use QGroundControl for that.","title":"Build PX4 for ARM hardware"},{"location":"docs/px4_build/#some-useful-parameters","text":"PX4 has many customizable parameters (over 700 of them, in fact) and to get best results with AirSim we have found the following parameters are handy: // be sure to enable the new position estimator module: param set SYS_MC_EST_GROUP 2 // increase default limits on cruise speed so you can move around a large map more quickly. param MPC_XY_CRUISE 10 param MPC_XY_VEL_MAX 10 param MPC_Z_VEL_MAX_DN 2 // increase timeout for auto-disarm on landing so that any long running app doesn't have to worry about it param COM_DISARM_LAND 60 // make it possible to fly without radio control attached (do NOT do this one on a real drone) param NAV_RCL_ACT 0 // enable new syslogger to get more information from PX4 logs param set SYS_LOGGER 1","title":"Some Useful Parameters"},{"location":"docs/px4_build/#installing-arm-none-eabi-gcc-in-bashonwindows","text":"SolinGuo built a 64 bit version of gcc-arm-none-eabi so that it will run inside BashOnWindows . See gcc-arm-none-eabi-5_4-2017q2-20170512-linux.tar.bz2 . If you download the *.tar.bz2 file to your machine and unpack it using this command line in BashOnWindows console: tar -xvf gcc-arm-none-eabi-5_4-2017q2-20170512-linux.tar.bz2 you will get the following folder which contains the arm gcc cross-compiler: gcc-arm-none-eabi-5_4-2017q2/bin If you add this folder to your PATH using the usual export PATH=... trick then the PX4 build will be able to find and run this compiler. After that, you can run make px4fmu-v2_default in BashOnWindows and the firmware will appear here: build_px4fmu-v2_default/src/firmware/nuttx/px4fmu-v2_default.px4 . You can then flash this new firmware on your Pixhawk using QGroundControl.","title":"Installing arm-none-eabi-gcc in BashOnWindows"},{"location":"docs/px4_logging/","text":"PX4/MavLink Logging Thanks to Chris Lovett for developing various tools for PX4/MavLink logging mentioned on this page! Logging MavLink Messages The following command will connect MavLinkTest app to the Simulator and enable logging of all mavlink commands to and from the PX4. MavLinkTest -server:127.0.0.1:14550 -logdir:d:\\temp Sometimes you will also want to log the \"output\" from the Simulator that is being sent to the PX4. Specifically this will capture the \"hilgps\" and \"hilsensor\" messages that are generated by the Simulator. To do that run this as well: MavLinkTest -server:127.0.0.1:14389 -logdir:d:\\temp\\output You will then see log files organized by date in d:\\temp\\logs, specifically input.mavlink and output.mavlink files. MavLink LogViewer For MavLink enabled drones, you can also use our Log Viewer to visualize the streams of data. PX4 Log in SITL Mode In SITL mode, please a log file is produced when drone is armed. The SITL terminal will contain the path to the log file, it should look something like this INFO [logger] Opened log file: rootfs/fs/microsd/log/2017-03-27/20_02_49.ulg PX4 Log in SITL Mode If you are using Pixhawk hardware in HIL mode, then set parameter SYS_LOGGER=1 using QGroundControl. PX4 will write log file on device which you can download at later date using QGroundControl.","title":"PX4/MavLink Logging"},{"location":"docs/px4_logging/#px4mavlink-logging","text":"Thanks to Chris Lovett for developing various tools for PX4/MavLink logging mentioned on this page!","title":"PX4/MavLink Logging"},{"location":"docs/px4_logging/#logging-mavlink-messages","text":"The following command will connect MavLinkTest app to the Simulator and enable logging of all mavlink commands to and from the PX4. MavLinkTest -server:127.0.0.1:14550 -logdir:d:\\temp Sometimes you will also want to log the \"output\" from the Simulator that is being sent to the PX4. Specifically this will capture the \"hilgps\" and \"hilsensor\" messages that are generated by the Simulator. To do that run this as well: MavLinkTest -server:127.0.0.1:14389 -logdir:d:\\temp\\output You will then see log files organized by date in d:\\temp\\logs, specifically input.mavlink and output.mavlink files.","title":"Logging MavLink Messages"},{"location":"docs/px4_logging/#mavlink-logviewer","text":"For MavLink enabled drones, you can also use our Log Viewer to visualize the streams of data.","title":"MavLink LogViewer"},{"location":"docs/px4_logging/#px4-log-in-sitl-mode","text":"In SITL mode, please a log file is produced when drone is armed. The SITL terminal will contain the path to the log file, it should look something like this INFO [logger] Opened log file: rootfs/fs/microsd/log/2017-03-27/20_02_49.ulg","title":"PX4 Log in SITL Mode"},{"location":"docs/px4_logging/#px4-log-in-sitl-mode_1","text":"If you are using Pixhawk hardware in HIL mode, then set parameter SYS_LOGGER=1 using QGroundControl. PX4 will write log file on device which you can download at later date using QGroundControl.","title":"PX4 Log in SITL Mode"},{"location":"docs/px4_setup/","text":"PX4 Setup for AirSim The PX4 software stack is an open source very popular flight controller with support for wide variety of boards and sensors as well as built-in capability for higher level tasks such as mission planning. Please visit px4.io for more information. Warning : While all releases of AirSim are always tested with PX4 to ensure the support, setting up PX4 is not a trivial task. Unless you have at least intermediate level of experience with PX4 stack, we recommend you use simple_flight , which is now a default in AirSim. Supported Hardware The following Pixhawk hardware has been tested with AirSim: 3DR Pixhawk v2 3DR Pixhawk mini Pixhawk PX4 2.4.8 PixFalcon PixRacer Pixhawk 2.1 (using PX4 Flight Stack) The 3DR Pixhawk Mini works out of the box, the others you may need to re-flash with the latest firmware. Setting up PX4 Hardware-in-Loop For this you will need one of the supported device listed above. For manual flight you will also need RC + transmitter. Make sure your RC receiver is bound with its RC transmitter. Connect the RC transmitter to the flight controller's RC port. Refer to your RC manual and PX4 docs for more information. Download QGroundControl , launch it and connect your flight controller to the USB port. Use QGroundControl to flash the latest PX4 Flight Stack. See also initial firmware setup video . In QGroundControl, configure your Pixhawk for HIL simulation by selecting the HIL Quadrocopter X airframe. After PX4 reboots, check that \"HIL Quadrocopter X\" is indeed selected. In QGroundControl, go to Radio tab and calibrate (make sure the remote control is on and the receiver is showing the indicator for the binding). Go to the Flight Mode tab and chose one of the remote control switches as \"Mode Channel\". Then set (for example) Stabilized and Attitude flight modes for two positions of the switch. Go to the Tuning section of QGroundControl and set appropriate values. For example, for Fly Sky's FS-TH9X remote control, the following settings give a more realistic feel: Hover Throttle = mid+1 mark, Roll and pitch sensitivity = mid-3 mark, Altitude and position control sensitivity = mid-2 mark. In AirSim settings file, specify PX4 for your vehicle config like this: { \"SettingsVersion\": 1.2, \"SimMode\": \"Multirotor\", \"Vehicles\": { \"PX4\": { \"VehicleType\": \"PX4Multirotor\" } } } After above setup you should be able to use RC to fly in the AirSim. You can usually arm the vehicle by lowering and bringing two sticks of RC together in-wards. You don't need QGroundControl after the initial setup. Typically the Stabilized (instead of Manual) mode gives better experience for beginners. You can also control the drone from Python APIs . See Walkthrough Demo Video and Unreal AirSim Setup Video that shows you all the setup steps in this document. Setting up PX4 Software-in-Loop The PX4 SITL mode doesn't require you to have separate device such as a Pixhawk or Pixracer. This is in fact the recommended way to use PX4 with simulators by PX4 team. However, this is indeed harder to set up. Please see this dedicated page for setting up PX4 in SITL mode. FAQ Drone doesn't fly properly, it just goes \"crazy\". There are a few reasons that can cause this. First, make sure your drone doesn't fall down large distance when starting the simulator. This might happen if you have created a custom Unreal environment and Player Start is placed too high above the ground. It seems that when this happens internal calibration in PX4 gets confused. You should also use QGroundControl and make sure you can arm and takeoff in QGroundControl properly. Finally, this also can be a machine performance issue in some rare cases, check your hard drive performance . Can I use Arducopter or other MavLink implementations? Our code is tested with the PX4 firmware . We have not tested Arducopter or other mavlink implementations. Some of the flight API's do use the PX4 custom modes in the MAV_CMD_DO_SET_MODE messages (like PX4_CUSTOM_MAIN_MODE_AUTO) It is not finding my Pixhawk hardware Check your settings.json file for this line \"SerialPort\":\"*,115200\". The asterisk here means \"find any serial port that looks like a Pixhawk device, but this doesn't always work for all types of Pixhawk hardware. So on Windows you can find the actual COM port using Device Manager, look under \"Ports (COM & LPT), plug the device in and see what new COM port shows up. Let's say you see a new port named \"USB Serial Port (COM5)\". Well, then change the SerialPort setting to this: \"SerialPort\":\"COM5,115200\". On Linux, the device can be found by running \"ls /dev/serial/by-id\" if you see a device name listed that looks like this usb-3D_Robotics_PX4_FMU_v2.x_0-if00 then you can use that name to connect, like this: \"SerialPort\":\"/dev/serial/by-id/usb-3D_Robotics_PX4_FMU_v2.x_0-if00\". Note this long name is actually a symbolic link to the real name, if you use \"ls -l ...\" you can find that symbolic link, it is usually something like \"/dev/ttyACM0\", so this will also work \"SerialPort\":\"/dev/ttyACM0,115200\". But that mapping is similar to windows, it is automatically assigned and can change, whereas the long name will work even if the actual TTY serial device mapping changes. WARN [commander] Takeoff denied, disarm and re-try This happens if you try and take off when PX4 still has not computed the home position. PX4 will report the home position once it is happy with the GPS signal, and you will see these messages: INFO [commander] home: 47.6414680, -122.1401672, 119.99 INFO [tone_alarm] home_set Up until this point in time, however, the PX4 will reject takeoff commands. When I tell the drone to do something it always lands For example, you use DroneShell moveToPosition -z -20 -x 50 -y 0 which it does, but when it gets to the target location the drone starts to land. This is the default behavior of PX4 when offboard mode completes. To set the drone to hover instead set this PX4 parameter: param set COM_OBL_ACT 1 I get message length mismatches errors You might need to set MAV_PROTO_VER parameter in QGC to \"Always use version 1\". Please see this issue more details.","title":"PX4 Setup for AirSim"},{"location":"docs/px4_setup/#px4-setup-for-airsim","text":"The PX4 software stack is an open source very popular flight controller with support for wide variety of boards and sensors as well as built-in capability for higher level tasks such as mission planning. Please visit px4.io for more information. Warning : While all releases of AirSim are always tested with PX4 to ensure the support, setting up PX4 is not a trivial task. Unless you have at least intermediate level of experience with PX4 stack, we recommend you use simple_flight , which is now a default in AirSim.","title":"PX4 Setup for AirSim"},{"location":"docs/px4_setup/#supported-hardware","text":"The following Pixhawk hardware has been tested with AirSim: 3DR Pixhawk v2 3DR Pixhawk mini Pixhawk PX4 2.4.8 PixFalcon PixRacer Pixhawk 2.1 (using PX4 Flight Stack) The 3DR Pixhawk Mini works out of the box, the others you may need to re-flash with the latest firmware.","title":"Supported Hardware"},{"location":"docs/px4_setup/#setting-up-px4-hardware-in-loop","text":"For this you will need one of the supported device listed above. For manual flight you will also need RC + transmitter. Make sure your RC receiver is bound with its RC transmitter. Connect the RC transmitter to the flight controller's RC port. Refer to your RC manual and PX4 docs for more information. Download QGroundControl , launch it and connect your flight controller to the USB port. Use QGroundControl to flash the latest PX4 Flight Stack. See also initial firmware setup video . In QGroundControl, configure your Pixhawk for HIL simulation by selecting the HIL Quadrocopter X airframe. After PX4 reboots, check that \"HIL Quadrocopter X\" is indeed selected. In QGroundControl, go to Radio tab and calibrate (make sure the remote control is on and the receiver is showing the indicator for the binding). Go to the Flight Mode tab and chose one of the remote control switches as \"Mode Channel\". Then set (for example) Stabilized and Attitude flight modes for two positions of the switch. Go to the Tuning section of QGroundControl and set appropriate values. For example, for Fly Sky's FS-TH9X remote control, the following settings give a more realistic feel: Hover Throttle = mid+1 mark, Roll and pitch sensitivity = mid-3 mark, Altitude and position control sensitivity = mid-2 mark. In AirSim settings file, specify PX4 for your vehicle config like this: { \"SettingsVersion\": 1.2, \"SimMode\": \"Multirotor\", \"Vehicles\": { \"PX4\": { \"VehicleType\": \"PX4Multirotor\" } } } After above setup you should be able to use RC to fly in the AirSim. You can usually arm the vehicle by lowering and bringing two sticks of RC together in-wards. You don't need QGroundControl after the initial setup. Typically the Stabilized (instead of Manual) mode gives better experience for beginners. You can also control the drone from Python APIs . See Walkthrough Demo Video and Unreal AirSim Setup Video that shows you all the setup steps in this document.","title":"Setting up PX4 Hardware-in-Loop"},{"location":"docs/px4_setup/#setting-up-px4-software-in-loop","text":"The PX4 SITL mode doesn't require you to have separate device such as a Pixhawk or Pixracer. This is in fact the recommended way to use PX4 with simulators by PX4 team. However, this is indeed harder to set up. Please see this dedicated page for setting up PX4 in SITL mode.","title":"Setting up PX4 Software-in-Loop"},{"location":"docs/px4_setup/#faq","text":"","title":"FAQ"},{"location":"docs/px4_setup/#drone-doesnt-fly-properly-it-just-goes-crazy","text":"There are a few reasons that can cause this. First, make sure your drone doesn't fall down large distance when starting the simulator. This might happen if you have created a custom Unreal environment and Player Start is placed too high above the ground. It seems that when this happens internal calibration in PX4 gets confused. You should also use QGroundControl and make sure you can arm and takeoff in QGroundControl properly. Finally, this also can be a machine performance issue in some rare cases, check your hard drive performance .","title":"Drone doesn't fly properly, it just goes \"crazy\"."},{"location":"docs/px4_setup/#can-i-use-arducopter-or-other-mavlink-implementations","text":"Our code is tested with the PX4 firmware . We have not tested Arducopter or other mavlink implementations. Some of the flight API's do use the PX4 custom modes in the MAV_CMD_DO_SET_MODE messages (like PX4_CUSTOM_MAIN_MODE_AUTO)","title":"Can I use Arducopter or other MavLink implementations?"},{"location":"docs/px4_setup/#it-is-not-finding-my-pixhawk-hardware","text":"Check your settings.json file for this line \"SerialPort\":\"*,115200\". The asterisk here means \"find any serial port that looks like a Pixhawk device, but this doesn't always work for all types of Pixhawk hardware. So on Windows you can find the actual COM port using Device Manager, look under \"Ports (COM & LPT), plug the device in and see what new COM port shows up. Let's say you see a new port named \"USB Serial Port (COM5)\". Well, then change the SerialPort setting to this: \"SerialPort\":\"COM5,115200\". On Linux, the device can be found by running \"ls /dev/serial/by-id\" if you see a device name listed that looks like this usb-3D_Robotics_PX4_FMU_v2.x_0-if00 then you can use that name to connect, like this: \"SerialPort\":\"/dev/serial/by-id/usb-3D_Robotics_PX4_FMU_v2.x_0-if00\". Note this long name is actually a symbolic link to the real name, if you use \"ls -l ...\" you can find that symbolic link, it is usually something like \"/dev/ttyACM0\", so this will also work \"SerialPort\":\"/dev/ttyACM0,115200\". But that mapping is similar to windows, it is automatically assigned and can change, whereas the long name will work even if the actual TTY serial device mapping changes.","title":"It is not finding my Pixhawk hardware"},{"location":"docs/px4_setup/#warn-commander-takeoff-denied-disarm-and-re-try","text":"This happens if you try and take off when PX4 still has not computed the home position. PX4 will report the home position once it is happy with the GPS signal, and you will see these messages: INFO [commander] home: 47.6414680, -122.1401672, 119.99 INFO [tone_alarm] home_set Up until this point in time, however, the PX4 will reject takeoff commands.","title":"WARN  [commander] Takeoff denied, disarm and re-try"},{"location":"docs/px4_setup/#when-i-tell-the-drone-to-do-something-it-always-lands","text":"For example, you use DroneShell moveToPosition -z -20 -x 50 -y 0 which it does, but when it gets to the target location the drone starts to land. This is the default behavior of PX4 when offboard mode completes. To set the drone to hover instead set this PX4 parameter: param set COM_OBL_ACT 1","title":"When I tell the drone to do something it always lands"},{"location":"docs/px4_setup/#i-get-message-length-mismatches-errors","text":"You might need to set MAV_PROTO_VER parameter in QGC to \"Always use version 1\". Please see this issue more details.","title":"I get message length mismatches errors"},{"location":"docs/px4_sitl/","text":"Setting up PX4 Software-in-Loop The PX4 software provides a \"software-in-loop\" simulation (SITL) version of their stack that runs in Linux. Sorry it doesn't run in Windows, but if you install BashOnWindows you can build and run it there. From your Linux bash terminal follow these steps for Linux and follow all the instructions under NuttX based hardware to install prerequisites. We've also included out own copy of the PX4 build instructions which is a bit more concise about what we need exactly. Get the PX4 source code and build the posix SITL version of PX4: mkdir -p PX4 cd PX4 git clone https://github.com/PX4/Firmware.git cd Firmware make posix_sitl_default Use following command to start PX4 firmware in SITL mode: ./build/posix_sitl_default/px4 ./posix-configs/SITL/init/ekf2/iris You should see a message like this you INFO [simulator] Waiting for initial data on UDP port 14560 which means the SITL PX4 app is waiting for someone to connect. Now edit AirSim settings file to make sure you have followings: json { \"SettingsVersion\": 1.2, \"SimMode\": \"Multirotor\", \"Vehicles\": { \"PX4\": { \"VehicleType\": \"PX4Multirotor\", \"UseSerial\": false } } } Run Unreal environment and it should connect to SITL via UDP. You should see a bunch of messages from the SITL PX4 window from things like [mavlink] and [commander] and so on. You should also be able to use QGroundControl just like with flight controller hardware. Note that as we don't have physical board, RC cannot be connected directly to it. So the alternatives are either use XBox 360 Controller or connect your RC using USB (for example, in case of FrSky Taranis X9D Plus) or using trainer USB cable to PC. This makes your RC look like joystick. You will need to do extra set up in QGroundControl to use virtual joystick for RC control. Setting GPS origin PX4 SITL mode needs to be configured to get the home location correct. Run the following in the PX4 console window so that the origin matches that which is setup in AirSim AVehiclePawnBase::HomeLatitude and HomeLongitude. param set LPE_LAT 47.641468 param set LPE_LON -122.140165 You might also want to set this one so that the drone automatically hovers after each offboard control command (the default setting is to land): param set COM_OBL_ACT 1 Now close Unreal app, restart ./build_posix_sitl_default/src/firmware/posix/px4 and re-start the unreal app. Check the Home Position If you are using DroneShell to execute commands (arm, takeoff, etc) then you should wait until the Home position is set. You will see the PX4 SITL console output this message: INFO [commander] home: 47.6414680, -122.1401672, 119.99 INFO [tone_alarm] home_set Now DroneShell 'pos' command should report this position and the commands should be accepted by PX4. If you attempt to takeoff without a home position you will see the message: WARN [commander] Takeoff denied, disarm and re-try After home position is set check the local position reported by 'pos' command : Local position: x=-0.0326988, y=0.00656854, z=5.48506 If the z coordinate is large like this then takeoff might not work as expected. Resetting the SITL and simulation should fix that problem. No Remote Control If you plan to fly with no remote control, just using DroneShell commands for example, then you will need to set the following parameters to stop the PX4 from triggering \"failsafe mode on\" every time a move command is finished. param set NAV_RCL_ACT 0 param set NAV_DLL_ACT 0 NOTE: Do NOT do this on a real drone as it is too dangerous to fly without these failsafe measures. Using VirtualBox Ubuntu If you want to run the above posix_sitl in a VirtualBox Ubuntu machine then it will have a different ip address from localhost. So in this case you need to edit the settings file and change the UdpIp and SitlIp to the ip address of your virtual machine set the LocalIpAddress to the address of your host machine running the Unreal engine. Remote Controller There are several options for flying the simulated drone using a remote control or joystick like xbox gamepad. See remote controllers","title":"PX4 in SITL"},{"location":"docs/px4_sitl/#setting-up-px4-software-in-loop","text":"The PX4 software provides a \"software-in-loop\" simulation (SITL) version of their stack that runs in Linux. Sorry it doesn't run in Windows, but if you install BashOnWindows you can build and run it there. From your Linux bash terminal follow these steps for Linux and follow all the instructions under NuttX based hardware to install prerequisites. We've also included out own copy of the PX4 build instructions which is a bit more concise about what we need exactly. Get the PX4 source code and build the posix SITL version of PX4: mkdir -p PX4 cd PX4 git clone https://github.com/PX4/Firmware.git cd Firmware make posix_sitl_default Use following command to start PX4 firmware in SITL mode: ./build/posix_sitl_default/px4 ./posix-configs/SITL/init/ekf2/iris You should see a message like this you INFO [simulator] Waiting for initial data on UDP port 14560 which means the SITL PX4 app is waiting for someone to connect. Now edit AirSim settings file to make sure you have followings: json { \"SettingsVersion\": 1.2, \"SimMode\": \"Multirotor\", \"Vehicles\": { \"PX4\": { \"VehicleType\": \"PX4Multirotor\", \"UseSerial\": false } } } Run Unreal environment and it should connect to SITL via UDP. You should see a bunch of messages from the SITL PX4 window from things like [mavlink] and [commander] and so on. You should also be able to use QGroundControl just like with flight controller hardware. Note that as we don't have physical board, RC cannot be connected directly to it. So the alternatives are either use XBox 360 Controller or connect your RC using USB (for example, in case of FrSky Taranis X9D Plus) or using trainer USB cable to PC. This makes your RC look like joystick. You will need to do extra set up in QGroundControl to use virtual joystick for RC control.","title":"Setting up PX4 Software-in-Loop"},{"location":"docs/px4_sitl/#setting-gps-origin","text":"PX4 SITL mode needs to be configured to get the home location correct. Run the following in the PX4 console window so that the origin matches that which is setup in AirSim AVehiclePawnBase::HomeLatitude and HomeLongitude. param set LPE_LAT 47.641468 param set LPE_LON -122.140165 You might also want to set this one so that the drone automatically hovers after each offboard control command (the default setting is to land): param set COM_OBL_ACT 1 Now close Unreal app, restart ./build_posix_sitl_default/src/firmware/posix/px4 and re-start the unreal app.","title":"Setting GPS origin"},{"location":"docs/px4_sitl/#check-the-home-position","text":"If you are using DroneShell to execute commands (arm, takeoff, etc) then you should wait until the Home position is set. You will see the PX4 SITL console output this message: INFO [commander] home: 47.6414680, -122.1401672, 119.99 INFO [tone_alarm] home_set Now DroneShell 'pos' command should report this position and the commands should be accepted by PX4. If you attempt to takeoff without a home position you will see the message: WARN [commander] Takeoff denied, disarm and re-try After home position is set check the local position reported by 'pos' command : Local position: x=-0.0326988, y=0.00656854, z=5.48506 If the z coordinate is large like this then takeoff might not work as expected. Resetting the SITL and simulation should fix that problem.","title":"Check the Home Position"},{"location":"docs/px4_sitl/#no-remote-control","text":"If you plan to fly with no remote control, just using DroneShell commands for example, then you will need to set the following parameters to stop the PX4 from triggering \"failsafe mode on\" every time a move command is finished. param set NAV_RCL_ACT 0 param set NAV_DLL_ACT 0 NOTE: Do NOT do this on a real drone as it is too dangerous to fly without these failsafe measures.","title":"No Remote Control"},{"location":"docs/px4_sitl/#using-virtualbox-ubuntu","text":"If you want to run the above posix_sitl in a VirtualBox Ubuntu machine then it will have a different ip address from localhost. So in this case you need to edit the settings file and change the UdpIp and SitlIp to the ip address of your virtual machine set the LocalIpAddress to the address of your host machine running the Unreal engine.","title":"Using VirtualBox Ubuntu"},{"location":"docs/px4_sitl/#remote-controller","text":"There are several options for flying the simulated drone using a remote control or joystick like xbox gamepad. See remote controllers","title":"Remote Controller"},{"location":"docs/python/","text":"Using Python APIs for AirSim This document is now merged with general APIs document .","title":"Using Python APIs for AirSim"},{"location":"docs/python/#using-python-apis-for-airsim","text":"This document is now merged with general APIs document .","title":"Using Python APIs for AirSim"},{"location":"docs/reinforcement_learning/","text":"Reinforcement Learning in AirSim We below describe how we can implement DQN in AirSim using CNTK. The easiest way is to first install python only CNTK ( instructions ). CNTK provides several demo examples of deep RL . We will modify the DeepQNeuralNetwork.py to work with AirSim. We can utilize most of the classes and methods corresponding to the DQN algorithm. However, there are certain additions we need to make for AirSim. Disclaimer This is still in active development. What we share below is a framework that can be extended and tweaked to obtain better performance. RL with Car Source code This example works with AirSimNeighborhood environment available in releases . First, we need to get the images from simulation and transform them appropriately. Below, we show how a depth image can be obtained from the ego camera and transformed to an 84X84 input to the network. (you can use other sensor modalities, and sensor inputs as well \u2013 of course you\u2019ll have to modify the code accordingly). responses = client.simGetImages([ImageRequest(0, AirSimImageType.DepthPerspective, True, False)]) current_state = transform_input(responses) We further define the six actions (breaking, straight with throttle, full-left with throttle, full-right with throttle, half-left with throttle, half-right with throttle) that an agent can execute. This is done via the function interpret_action : def interpret_action(action): car_controls.brake = 0 car_controls.throttle = 1 if action == 0: car_controls.throttle = 0 car_controls.brake = 1 elif action == 1: car_controls.steering = 0 elif action == 2: car_controls.steering = 0.5 elif action == 3: car_controls.steering = -0.5 elif action == 4: car_controls.steering = 0.25 else: car_controls.steering = -0.25 return car_controls We then define the reward function in compute_reward as a convex combination of how fast the vehicle is travelling and how much it deviates from the center line. The agent gets a high reward when its moving fast and staying in the center of the lane. def compute_reward(car_state): MAX_SPEED = 300 MIN_SPEED = 10 thresh_dist = 3.5 beta = 3 z = 0 pts = [np.array([0, -1, z]), np.array([130, -1, z]), np.array([130, 125, z]), np.array([0, 125, z]), np.array([0, -1, z]), np.array([130, -1, z]), np.array([130, -128, z]), np.array([0, -128, z]), np.array([0, -1, z])] pd = car_state.position car_pt = np.array(list(pd.values())) dist = 10000000 for i in range(0, len(pts)-1): dist = min(dist, np.linalg.norm(np.cross((car_pt - pts[i]), (car_pt - pts[i+1])))/np.linalg.norm(pts[i]-pts[i+1])) #print(dist) if dist > thresh_dist: reward = -3 else: reward_dist = (math.exp(-beta*dist) - 0.5) reward_speed = (((car_state.speed - MIN_SPEED)/(MAX_SPEED - MIN_SPEED)) - 0.5) reward = reward_dist + reward_speed return reward The function isDone determines if the episode has terminated (e.g. due to collision). We look at the speed of the vehicle and if it is less than a threshold than the episode is considered to be terminated. def isDone(car_state, car_controls, reward): done = 0 if reward < -1: done = 1 if car_controls.brake == 0: if car_state.speed <= 5: done = 1 return done The main loop then sequences through obtaining the image, computing the action to take according to the current policy, getting a reward and so forth. If the episode terminates then we reset the vehicle to the original state via: client.reset() client.enableApiControl(True) client.armDisarm(True) car_control = interpret_action(1) // Reset position and drive straight for one second client.setCarControls(car_control) time.sleep(1) Note that the simulation needs to be up and running before you execute DQNcar.py. The video below shows first few episodes of DQN training. RL with Quadrotor Source code This example works with AirSimMountainLandscape environment available in releases . We can similarly apply RL for various autonomous flight scenarios with quadrotors. Below is an example on how RL could be used to train quadrotors to follow high tension power lines (e.g. application for energy infrastructure inspection). There are seven actions here that correspond to different directions in which the quadrotor can move in (six directions + one hovering action). def interpret_action(action): if action == 0: quad_offset = (0, 0, 0) elif action == 1: quad_offset = (1, 0, 0) elif action == 2: quad_offset = (0, 1, 0) elif action == 3: quad_offset = (0, 0, 1) elif action == 4: quad_offset = (-1, 0, 0) elif action == 5: quad_offset = (0, -1, 0) elif action == 6: quad_offset = (0, 0, -1) return quad_offset The reward again is a function how how fast the quad travels in conjunction with how far it gets from the known powerlines. def compute_reward(quad_state, quad_vel, collision_info): thresh_dist = 10 beta = 1 z = -10 pts = [np.array([0, 0, z]), np.array([130, 0, z]), np.array([130, 125, z]), np.array([0, 125, z]), np.array([0, 0, z]), np.array([130, 0, z]), np.array([130, -128, z]), np.array([0, -128, z]), np.array([0, 0, z])] quad_pt = np.array(list((quad_state.x_val, quad_state.y_val, quad_state.z_val))) if collision_info.has_collided: reward = -100 else: dist = 10000000 for i in range(0, len(pts)-1): dist = min(dist, np.linalg.norm(np.cross((quad_pt - pts[i]), (quad_pt - pts[i+1])))/np.linalg.norm(pts[i]-pts[i+1])) if dist > thresh_dist: reward = -10 else: reward = 2*(0.5 - math.exp(-beta*dist)) + np.linalg.norm([quad_vel.x_val, quad_vel.y_val, quad_vel.z_val]) return reward We consider an episode to terminate if it drifts too much away from the known power line coordinates. The reset function here flies the quadrotor to the initial starting point: if done: client.moveToZAsync(clearZ, 2).join() client.moveToPositionAsync(initX, initY, clearZ, 2).join() client.moveToPositionAsync(initZ, initY, initZ, 2).join() current_step +=1 Here is the video of first few episodes during the training. Related Please also see The Autonomous Driving Cookbook by Microsoft Deep Learning and Robotics Garage Chapter.","title":"Reinforcement Learning"},{"location":"docs/reinforcement_learning/#reinforcement-learning-in-airsim","text":"We below describe how we can implement DQN in AirSim using CNTK. The easiest way is to first install python only CNTK ( instructions ). CNTK provides several demo examples of deep RL . We will modify the DeepQNeuralNetwork.py to work with AirSim. We can utilize most of the classes and methods corresponding to the DQN algorithm. However, there are certain additions we need to make for AirSim.","title":"Reinforcement Learning in AirSim"},{"location":"docs/reinforcement_learning/#disclaimer","text":"This is still in active development. What we share below is a framework that can be extended and tweaked to obtain better performance.","title":"Disclaimer"},{"location":"docs/reinforcement_learning/#rl-with-car","text":"Source code This example works with AirSimNeighborhood environment available in releases . First, we need to get the images from simulation and transform them appropriately. Below, we show how a depth image can be obtained from the ego camera and transformed to an 84X84 input to the network. (you can use other sensor modalities, and sensor inputs as well \u2013 of course you\u2019ll have to modify the code accordingly). responses = client.simGetImages([ImageRequest(0, AirSimImageType.DepthPerspective, True, False)]) current_state = transform_input(responses) We further define the six actions (breaking, straight with throttle, full-left with throttle, full-right with throttle, half-left with throttle, half-right with throttle) that an agent can execute. This is done via the function interpret_action : def interpret_action(action): car_controls.brake = 0 car_controls.throttle = 1 if action == 0: car_controls.throttle = 0 car_controls.brake = 1 elif action == 1: car_controls.steering = 0 elif action == 2: car_controls.steering = 0.5 elif action == 3: car_controls.steering = -0.5 elif action == 4: car_controls.steering = 0.25 else: car_controls.steering = -0.25 return car_controls We then define the reward function in compute_reward as a convex combination of how fast the vehicle is travelling and how much it deviates from the center line. The agent gets a high reward when its moving fast and staying in the center of the lane. def compute_reward(car_state): MAX_SPEED = 300 MIN_SPEED = 10 thresh_dist = 3.5 beta = 3 z = 0 pts = [np.array([0, -1, z]), np.array([130, -1, z]), np.array([130, 125, z]), np.array([0, 125, z]), np.array([0, -1, z]), np.array([130, -1, z]), np.array([130, -128, z]), np.array([0, -128, z]), np.array([0, -1, z])] pd = car_state.position car_pt = np.array(list(pd.values())) dist = 10000000 for i in range(0, len(pts)-1): dist = min(dist, np.linalg.norm(np.cross((car_pt - pts[i]), (car_pt - pts[i+1])))/np.linalg.norm(pts[i]-pts[i+1])) #print(dist) if dist > thresh_dist: reward = -3 else: reward_dist = (math.exp(-beta*dist) - 0.5) reward_speed = (((car_state.speed - MIN_SPEED)/(MAX_SPEED - MIN_SPEED)) - 0.5) reward = reward_dist + reward_speed return reward The function isDone determines if the episode has terminated (e.g. due to collision). We look at the speed of the vehicle and if it is less than a threshold than the episode is considered to be terminated. def isDone(car_state, car_controls, reward): done = 0 if reward < -1: done = 1 if car_controls.brake == 0: if car_state.speed <= 5: done = 1 return done The main loop then sequences through obtaining the image, computing the action to take according to the current policy, getting a reward and so forth. If the episode terminates then we reset the vehicle to the original state via: client.reset() client.enableApiControl(True) client.armDisarm(True) car_control = interpret_action(1) // Reset position and drive straight for one second client.setCarControls(car_control) time.sleep(1) Note that the simulation needs to be up and running before you execute DQNcar.py. The video below shows first few episodes of DQN training.","title":"RL with Car"},{"location":"docs/reinforcement_learning/#rl-with-quadrotor","text":"Source code This example works with AirSimMountainLandscape environment available in releases . We can similarly apply RL for various autonomous flight scenarios with quadrotors. Below is an example on how RL could be used to train quadrotors to follow high tension power lines (e.g. application for energy infrastructure inspection). There are seven actions here that correspond to different directions in which the quadrotor can move in (six directions + one hovering action). def interpret_action(action): if action == 0: quad_offset = (0, 0, 0) elif action == 1: quad_offset = (1, 0, 0) elif action == 2: quad_offset = (0, 1, 0) elif action == 3: quad_offset = (0, 0, 1) elif action == 4: quad_offset = (-1, 0, 0) elif action == 5: quad_offset = (0, -1, 0) elif action == 6: quad_offset = (0, 0, -1) return quad_offset The reward again is a function how how fast the quad travels in conjunction with how far it gets from the known powerlines. def compute_reward(quad_state, quad_vel, collision_info): thresh_dist = 10 beta = 1 z = -10 pts = [np.array([0, 0, z]), np.array([130, 0, z]), np.array([130, 125, z]), np.array([0, 125, z]), np.array([0, 0, z]), np.array([130, 0, z]), np.array([130, -128, z]), np.array([0, -128, z]), np.array([0, 0, z])] quad_pt = np.array(list((quad_state.x_val, quad_state.y_val, quad_state.z_val))) if collision_info.has_collided: reward = -100 else: dist = 10000000 for i in range(0, len(pts)-1): dist = min(dist, np.linalg.norm(np.cross((quad_pt - pts[i]), (quad_pt - pts[i+1])))/np.linalg.norm(pts[i]-pts[i+1])) if dist > thresh_dist: reward = -10 else: reward = 2*(0.5 - math.exp(-beta*dist)) + np.linalg.norm([quad_vel.x_val, quad_vel.y_val, quad_vel.z_val]) return reward We consider an episode to terminate if it drifts too much away from the known power line coordinates. The reset function here flies the quadrotor to the initial starting point: if done: client.moveToZAsync(clearZ, 2).join() client.moveToPositionAsync(initX, initY, clearZ, 2).join() client.moveToPositionAsync(initZ, initY, initZ, 2).join() current_step +=1 Here is the video of first few episodes during the training.","title":"RL with Quadrotor"},{"location":"docs/reinforcement_learning/#related","text":"Please also see The Autonomous Driving Cookbook by Microsoft Deep Learning and Robotics Garage Chapter.","title":"Related"},{"location":"docs/remote_control/","text":"Remote Control To fly manually, you need remote control or RC. If you don't have one then you can use APIs to fly programmatically or use so-called Computer Vision mode to move around using keyboard. RC Setup for Default Config By default AirSim uses simple_flight as its flight controller which connects to RC via USB port to your computer. You can either use XBox controller or FrSky Taranis X9D Plus . Note that XBox 360 controller is not precise enough and is not recommended if you wanted more real world experience. See FAQ below if things are not working. ### Other Devices AirSim can detect large variety of devices however devices other than above might need extra configuration. In future we will add ability to set this config through settings.json. For now, if things are not working then you might want to try workarounds such as x360ce or chnage code in SimJoystick.cpp file . ### Note on FrSky Taranis X9D Plus FrSky Taranis X9D Plus is real UAV remote control with an advantage that it has USB port so it can be directly connected to PC. You can download AirSim config file and follow this tutorial to import it in your RC. You should then see \"sim\" model in RC with all channels configured properly. Note on Linux Currently default config on Linux is for using Xbox controller. This means other devices might not work properly. In future we will add ability to configure RC in settings.json but for now you might have to change code in SimJoystick.cpp file to use other devices. RC Setup for PX4 AirSim supports PX4 flight controller however it requires different setup. There are many remote control options that you can use with quadrotors. We have successfully used FrSky Taranis X9D Plus, FlySky FS-TH9X and Futaba 14SG with AirSim. Following are the high level steps to configure your RC: If you are going to use Hardware-in-Loop mode, you need transmitter for your specific brand of RC and bind it. You can find this information in RC's user guide. For Hardware-in-Loop mode, you connect transmitter to Pixhawk. Usually you can find online doc or YouTube video tutorial on how to do that. Calibrate your RC in QGroundControl . See PX4 RC configuration and Please see this guide for more information. Using XBox 360 USB Gamepad You can also use an xbox controller in SITL mode, it just won't be as precise as a real RC controller. See xbox controller for details on how to set that up. Using Playstation 3 controller A Playstation 3 controller is confirmed to work as an AirSim controller. On Windows, an emulator to make it look like an Xbox 360 controller, is required however. Many different solutions are available online, for example x360ce Xbox 360 Controller Emulator . DJI Controller Nils Tijtgat wrote an excellent blog on how to get the DJI controller working with AirSim . FAQ I'm using default config and AirSim says my RC is not detected on USB. This typically happens if you have multiple RCs and or XBox/Playstation gamepads etc connected. In Windows, hit Windows+S key and search for \"Set up USB Game controllers\" (in older versions of Windows try \"joystick\"). This will show you all game controllers connected to your PC. If you don't see yours than Windows haven't detected it and so you need to first solve that issue. If you do see yours but not at the top of the list (i.e. index 0) than you need to tell AirSim because AirSim by default tries to use RC at index 0. To do this, navigate to your ~/Documents/AirSim folder, open up settings.json and add/modify following setting. Below tells AirSim to use RC at index = 2. { \"SettingsVersion\": 1.2, \"SimMode\": \"Multirotor\", \"Vehicles\": { \"SimpleFlight\": { \"VehicleType\": \"SimpleFlight\", \"RC\": { \"RemoteControlID\": 2 } } } } Vehicle seems unstable when using XBox/PS3 controller Regular gamepads are not very precise and have lot of random noise. Most of the times you may see significant offsets as well (i.e. output is not zero when sticks are at zero). So this behavior is expected. Where is RC calibration in AirSim? We haven't implemented it yet. This means your RC firmware will need to have a capability to do calibration for now. My RC is not working with PX4 setup. First you want to make sure your RC is working in QGroundControl . If it doesn't then it will sure not work in AirSim. The PX4 mode is suitable for folks who have at least intermediate level of experience to deal with various issues related to PX4 and we would generally refer you to get help from PX4 forums.","title":"Remote Control"},{"location":"docs/remote_control/#remote-control","text":"To fly manually, you need remote control or RC. If you don't have one then you can use APIs to fly programmatically or use so-called Computer Vision mode to move around using keyboard.","title":"Remote Control"},{"location":"docs/remote_control/#rc-setup-for-default-config","text":"By default AirSim uses simple_flight as its flight controller which connects to RC via USB port to your computer. You can either use XBox controller or FrSky Taranis X9D Plus . Note that XBox 360 controller is not precise enough and is not recommended if you wanted more real world experience. See FAQ below if things are not working. ### Other Devices AirSim can detect large variety of devices however devices other than above might need extra configuration. In future we will add ability to set this config through settings.json. For now, if things are not working then you might want to try workarounds such as x360ce or chnage code in SimJoystick.cpp file . ### Note on FrSky Taranis X9D Plus FrSky Taranis X9D Plus is real UAV remote control with an advantage that it has USB port so it can be directly connected to PC. You can download AirSim config file and follow this tutorial to import it in your RC. You should then see \"sim\" model in RC with all channels configured properly.","title":"RC Setup for Default Config"},{"location":"docs/remote_control/#note-on-linux","text":"Currently default config on Linux is for using Xbox controller. This means other devices might not work properly. In future we will add ability to configure RC in settings.json but for now you might have to change code in SimJoystick.cpp file to use other devices.","title":"Note on Linux"},{"location":"docs/remote_control/#rc-setup-for-px4","text":"AirSim supports PX4 flight controller however it requires different setup. There are many remote control options that you can use with quadrotors. We have successfully used FrSky Taranis X9D Plus, FlySky FS-TH9X and Futaba 14SG with AirSim. Following are the high level steps to configure your RC: If you are going to use Hardware-in-Loop mode, you need transmitter for your specific brand of RC and bind it. You can find this information in RC's user guide. For Hardware-in-Loop mode, you connect transmitter to Pixhawk. Usually you can find online doc or YouTube video tutorial on how to do that. Calibrate your RC in QGroundControl . See PX4 RC configuration and Please see this guide for more information.","title":"RC Setup for PX4"},{"location":"docs/remote_control/#using-xbox-360-usb-gamepad","text":"You can also use an xbox controller in SITL mode, it just won't be as precise as a real RC controller. See xbox controller for details on how to set that up.","title":"Using XBox 360 USB Gamepad"},{"location":"docs/remote_control/#using-playstation-3-controller","text":"A Playstation 3 controller is confirmed to work as an AirSim controller. On Windows, an emulator to make it look like an Xbox 360 controller, is required however. Many different solutions are available online, for example x360ce Xbox 360 Controller Emulator .","title":"Using Playstation 3 controller"},{"location":"docs/remote_control/#dji-controller","text":"Nils Tijtgat wrote an excellent blog on how to get the DJI controller working with AirSim .","title":"DJI Controller"},{"location":"docs/remote_control/#faq","text":"","title":"FAQ"},{"location":"docs/remote_control/#im-using-default-config-and-airsim-says-my-rc-is-not-detected-on-usb","text":"This typically happens if you have multiple RCs and or XBox/Playstation gamepads etc connected. In Windows, hit Windows+S key and search for \"Set up USB Game controllers\" (in older versions of Windows try \"joystick\"). This will show you all game controllers connected to your PC. If you don't see yours than Windows haven't detected it and so you need to first solve that issue. If you do see yours but not at the top of the list (i.e. index 0) than you need to tell AirSim because AirSim by default tries to use RC at index 0. To do this, navigate to your ~/Documents/AirSim folder, open up settings.json and add/modify following setting. Below tells AirSim to use RC at index = 2. { \"SettingsVersion\": 1.2, \"SimMode\": \"Multirotor\", \"Vehicles\": { \"SimpleFlight\": { \"VehicleType\": \"SimpleFlight\", \"RC\": { \"RemoteControlID\": 2 } } } }","title":"I'm using default config and AirSim says my RC is not detected on USB."},{"location":"docs/remote_control/#vehicle-seems-unstable-when-using-xboxps3-controller","text":"Regular gamepads are not very precise and have lot of random noise. Most of the times you may see significant offsets as well (i.e. output is not zero when sticks are at zero). So this behavior is expected.","title":"Vehicle seems unstable when using XBox/PS3 controller"},{"location":"docs/remote_control/#where-is-rc-calibration-in-airsim","text":"We haven't implemented it yet. This means your RC firmware will need to have a capability to do calibration for now.","title":"Where is RC calibration in AirSim?"},{"location":"docs/remote_control/#my-rc-is-not-working-with-px4-setup","text":"First you want to make sure your RC is working in QGroundControl . If it doesn't then it will sure not work in AirSim. The PX4 mode is suitable for folks who have at least intermediate level of experience to deal with various issues related to PX4 and we would generally refer you to get help from PX4 forums.","title":"My RC is not working with PX4 setup."},{"location":"docs/ros/","text":"How to use AirSim with Robot Operating System (ROS) AirSim and ROS can be integrated using C++ or Python. Some example ROS nodes are provided demonstrating how to publish data from AirSim as ROS topics. Python Prerequisites These instructions are for Ubuntu 16.04, ROS Kinetic, UE4 4.18 or higher, and latest AirSim release. You should have these components installed and working before proceeding Setup Create a new ROS package in your catkin workspace following these instructions. Create a new ROS package called airsim or whatever you like. Create ROS package If you don't already have a catkin workspace, you should first work through the ROS beginner tutorials. Add AirSim ROS node examples to ROS package In the ROS package directory you made, copy the ros examples from the AirSim/PythonClient directory to your ROS package. Change the code below to match your AirSim and catkin workspace paths. # copy package mkdir -p ../catkin_ws/src/airsim/scripts/airsim cp AirSim/PythonClient/airsim/*.py ../catkin_ws/src/airsim/scripts/airsim # copy ROS examples cp AirSim/PythonClient/ros/*.py ../catkin_ws/src/airsim/scripts Build ROS AirSim package Change directory to your top level catkin workspace folder i.e. cd ~/catkin_ws and run catkin_make This will build the airsim package. Next, run source devel/setup.bash so ROS can find the new package. You can add this command to your ~/.bashrc to load your catkin workspace automatically. How to run ROS AirSim nodes First make sure UE4 is running an airsim project, the car or drone should be selected, and the simulations is playing. Examples support car or drone. Make sure to have the correct vehicle for the ros example running. The example airsim nodes can be run using rosrun airsim example_name.py The output of the node can be viewed in another terminal by running rostopic echo /example_name You can view a list of the topics currently published via tab completion after typing rostopic echo in the terminal. Rviz is a useful visualization tool that can display the published data. C++ (coming soon)","title":"ROS"},{"location":"docs/ros/#how-to-use-airsim-with-robot-operating-system-ros","text":"AirSim and ROS can be integrated using C++ or Python. Some example ROS nodes are provided demonstrating how to publish data from AirSim as ROS topics.","title":"How to use AirSim with Robot Operating System (ROS)"},{"location":"docs/ros/#python","text":"","title":"Python"},{"location":"docs/ros/#prerequisites","text":"These instructions are for Ubuntu 16.04, ROS Kinetic, UE4 4.18 or higher, and latest AirSim release. You should have these components installed and working before proceeding","title":"Prerequisites"},{"location":"docs/ros/#setup","text":"","title":"Setup"},{"location":"docs/ros/#create-a-new-ros-package-in-your-catkin-workspace-following-these-instructions","text":"Create a new ROS package called airsim or whatever you like. Create ROS package If you don't already have a catkin workspace, you should first work through the ROS beginner tutorials.","title":"Create a new ROS package in your catkin workspace following these instructions."},{"location":"docs/ros/#add-airsim-ros-node-examples-to-ros-package","text":"In the ROS package directory you made, copy the ros examples from the AirSim/PythonClient directory to your ROS package. Change the code below to match your AirSim and catkin workspace paths. # copy package mkdir -p ../catkin_ws/src/airsim/scripts/airsim cp AirSim/PythonClient/airsim/*.py ../catkin_ws/src/airsim/scripts/airsim # copy ROS examples cp AirSim/PythonClient/ros/*.py ../catkin_ws/src/airsim/scripts","title":"Add AirSim ROS node examples to ROS package"},{"location":"docs/ros/#build-ros-airsim-package","text":"Change directory to your top level catkin workspace folder i.e. cd ~/catkin_ws and run catkin_make This will build the airsim package. Next, run source devel/setup.bash so ROS can find the new package. You can add this command to your ~/.bashrc to load your catkin workspace automatically.","title":"Build ROS AirSim package"},{"location":"docs/ros/#how-to-run-ros-airsim-nodes","text":"First make sure UE4 is running an airsim project, the car or drone should be selected, and the simulations is playing. Examples support car or drone. Make sure to have the correct vehicle for the ros example running. The example airsim nodes can be run using rosrun airsim example_name.py The output of the node can be viewed in another terminal by running rostopic echo /example_name You can view a list of the topics currently published via tab completion after typing rostopic echo in the terminal. Rviz is a useful visualization tool that can display the published data.","title":"How to run ROS AirSim nodes"},{"location":"docs/ros/#c-coming-soon","text":"","title":"C++ (coming soon)"},{"location":"docs/sensors/","text":"Sensors in AirSim AirSim currently supports the following sensors: Camera Imu Magnetometer Gps Barometer Distance * Lidar The cameras are currently configured a bit differently than other sensors. The camera configuration and apis are covered in other documents, e.g., general settings and image API . This document focuses on the configuration of other sensors. Default sensors If not sensors are specified in the settings json, the the following sensors are enabled by default based on the simmode. Multirotor Imu Magnetometer Gps Barometer Car Gps ComputerVision None Please see 'createDefaultSensorSettings' method in AirSimSettings.hpp Configuration of Default Sensor list A default sensor list can be configured in settings json. e.g., \"DefaultSensors\": { \"Barometer\": { \"SensorType\": 1, \"Enabled\" : true }, \"Gps\": { \"SensorType\": 1, \"Enabled\" : true }, \"Lidar1\": { \"SensorType\": 6, \"Enabled\" : true, \"NumberOfChannels\": 16, \"PointsPerSecond\": 10000 }, \"Lidar2\": { \"SensorType\": 6, \"Enabled\" : false, \"NumberOfChannels\": 4, \"PointsPerSecond\": 10000 } }, Configuration of vehicle specific sensor settings A vehicle specific sensor list can be specified in the vehicle settings part of the json. e.g., \"Vehicles\": { \"Drone1\": { \"VehicleType\": \"simpleflight\", \"AutoCreate\": true, ... \"Sensors\": { \"MyLidar1\": { \"SensorType\": 6, \"Enabled\" : true, \"NumberOfChannels\": 16, \"PointsPerSecond\": 10000, \"X\": 0, \"Y\": 0, \"Z\": -1, \"DrawDebugPoints\": true }, \"MyLidar2\": { \"SensorType\": 6, \"Enabled\" : true, \"NumberOfChannels\": 4, \"PointsPerSecond\": 10000, \"X\": 0, \"Y\": 0, \"Z\": -1, \"DrawDebugPoints\": true } } } } If a vehicle provides its sensor list, it must provide the whole list. Selective add/remove/update of the default sensor list is NOT supported. Configuration of sensor settings Shared settings There are two shared settings: * SensorType An integer representing the sensor-type SensorBase.hpp enum class SensorType : uint { Barometer = 1, Imu = 2, Gps = 3, Magnetometer = 4, Distance = 5, Lidar = 6 }; Enabled Boolean Sensor specific settings Each sensor-type has its own set of settings as well. Please see lidar for example of Lidar specific settings. Sensor APIs Each sensor-type has its own set of APIs currently. Please see lidar for example of Lidar specific APIs.","title":"Sensors"},{"location":"docs/sensors/#sensors-in-airsim","text":"AirSim currently supports the following sensors: Camera Imu Magnetometer Gps Barometer Distance * Lidar The cameras are currently configured a bit differently than other sensors. The camera configuration and apis are covered in other documents, e.g., general settings and image API . This document focuses on the configuration of other sensors.","title":"Sensors in AirSim"},{"location":"docs/sensors/#default-sensors","text":"If not sensors are specified in the settings json, the the following sensors are enabled by default based on the simmode.","title":"Default sensors"},{"location":"docs/sensors/#multirotor","text":"Imu Magnetometer Gps Barometer","title":"Multirotor"},{"location":"docs/sensors/#car","text":"Gps","title":"Car"},{"location":"docs/sensors/#computervision","text":"None Please see 'createDefaultSensorSettings' method in AirSimSettings.hpp","title":"ComputerVision"},{"location":"docs/sensors/#configuration-of-default-sensor-list","text":"A default sensor list can be configured in settings json. e.g., \"DefaultSensors\": { \"Barometer\": { \"SensorType\": 1, \"Enabled\" : true }, \"Gps\": { \"SensorType\": 1, \"Enabled\" : true }, \"Lidar1\": { \"SensorType\": 6, \"Enabled\" : true, \"NumberOfChannels\": 16, \"PointsPerSecond\": 10000 }, \"Lidar2\": { \"SensorType\": 6, \"Enabled\" : false, \"NumberOfChannels\": 4, \"PointsPerSecond\": 10000 } },","title":"Configuration of Default Sensor list"},{"location":"docs/sensors/#configuration-of-vehicle-specific-sensor-settings","text":"A vehicle specific sensor list can be specified in the vehicle settings part of the json. e.g., \"Vehicles\": { \"Drone1\": { \"VehicleType\": \"simpleflight\", \"AutoCreate\": true, ... \"Sensors\": { \"MyLidar1\": { \"SensorType\": 6, \"Enabled\" : true, \"NumberOfChannels\": 16, \"PointsPerSecond\": 10000, \"X\": 0, \"Y\": 0, \"Z\": -1, \"DrawDebugPoints\": true }, \"MyLidar2\": { \"SensorType\": 6, \"Enabled\" : true, \"NumberOfChannels\": 4, \"PointsPerSecond\": 10000, \"X\": 0, \"Y\": 0, \"Z\": -1, \"DrawDebugPoints\": true } } } } If a vehicle provides its sensor list, it must provide the whole list. Selective add/remove/update of the default sensor list is NOT supported.","title":"Configuration of vehicle specific sensor settings"},{"location":"docs/sensors/#configuration-of-sensor-settings","text":"","title":"Configuration of sensor settings"},{"location":"docs/sensors/#shared-settings","text":"There are two shared settings: * SensorType An integer representing the sensor-type SensorBase.hpp enum class SensorType : uint { Barometer = 1, Imu = 2, Gps = 3, Magnetometer = 4, Distance = 5, Lidar = 6 }; Enabled Boolean","title":"Shared settings"},{"location":"docs/sensors/#sensor-specific-settings","text":"Each sensor-type has its own set of settings as well. Please see lidar for example of Lidar specific settings.","title":"Sensor specific settings"},{"location":"docs/sensors/#sensor-apis","text":"Each sensor-type has its own set of APIs currently. Please see lidar for example of Lidar specific APIs.","title":"Sensor APIs"},{"location":"docs/settings/","text":"AirSim Settings Where are Settings Stored? Windows: Documents\\AirSim Linux: ~/Documents/AirSim The file is in usual json format . On first startup AirSim would create settings.json file with no settings. To avoid problems, always use ASCII format to save json file. How to Chose Between Car and Multirotor? The default is to use multirotor. To use car simple set \"SimMode\": \"Car\" like this: { \"SettingsVersion\": 1.2, \"SimMode\": \"Car\" } To choose multirotor, set \"SimMode\": \"Multirotor\" . If you want to prompt user to select vehicle type then use \"SimMode\": \"\" . Available Settings and Their Defaults Below are complete list of settings available along with their default values. If any of the settings is missing from json file, then default value is used. Some default values are simply specified as \"\" which means actual value may be chosen based on the vehicle you are using. For example, ViewMode setting has default value \"\" which translates to \"FlyWithMe\" for drones and \"SpringArmChase\" for cars. WARNING: Do not copy paste all of below in your settings.json. We strongly recommend adding only those settings that you don't want default values. Only required element is \"SettingsVersion\" . { \"SimMode\": \"\", \"ClockType\": \"\", \"ClockSpeed\": 1, \"LocalHostIp\": \"127.0.0.1\", \"RecordUIVisible\": true, \"LogMessagesVisible\": true, \"ViewMode\": \"\", \"RpcEnabled\": true, \"EngineSound\": true, \"PhysicsEngineName\": \"\", \"SpeedUnitFactor\": 1.0, \"SpeedUnitLabel\": \"m/s\", \"Recording\": { \"RecordOnMove\": false, \"RecordInterval\": 0.05, \"Cameras\": [ { \"CameraName\": \"0\", \"ImageType\": 0, \"PixelsAsFloat\": false, \"Compress\": true } ] }, \"CameraDefaults\": { \"CaptureSettings\": [ { \"ImageType\": 0, \"Width\": 256, \"Height\": 144, \"FOV_Degrees\": 90, \"AutoExposureSpeed\": 100, \"AutoExposureBias\": 0, \"AutoExposureMaxBrightness\": 0.64, \"AutoExposureMinBrightness\": 0.03, \"MotionBlurAmount\": 0, \"TargetGamma\": 1.0, \"ProjectionMode\": \"\", \"OrthoWidth\": 5.12 } ], \"NoiseSettings\": [ { \"Enabled\": false, \"ImageType\": 0, \"RandContrib\": 0.2, \"RandSpeed\": 100000.0, \"RandSize\": 500.0, \"RandDensity\": 2, \"HorzWaveContrib\":0.03, \"HorzWaveStrength\": 0.08, \"HorzWaveVertSize\": 1.0, \"HorzWaveScreenSize\": 1.0, \"HorzNoiseLinesContrib\": 1.0, \"HorzNoiseLinesDensityY\": 0.01, \"HorzNoiseLinesDensityXY\": 0.5, \"HorzDistortionContrib\": 1.0, \"HorzDistortionStrength\": 0.002 } ], \"Gimbal\": { \"Stabilization\": 0, \"Pitch\": NaN, \"Roll\": NaN, \"Yaw\": NaN } \"X\": NaN, \"Y\": NaN, \"Z\": NaN, \"Pitch\": NaN, \"Roll\": NaN, \"Yaw\": NaN }, \"OriginGeopoint\": { \"Latitude\": 47.641468, \"Longitude\": -122.140165, \"Altitude\": 122 }, \"TimeOfDay\": { \"Enabled\": false, \"StartDateTime\": \"\", \"CelestialClockSpeed\": 1, \"StartDateTimeDst\": false, \"UpdateIntervalSecs\": 60 }, \"SubWindows\": [ {\"WindowID\": 0, \"CameraName\": \"0\", \"ImageType\": 3, \"Visible\": false}, {\"WindowID\": 1, \"CameraName\": \"0\", \"ImageType\": 5, \"Visible\": false}, {\"WindowID\": 2, \"CameraName\": \"0\", \"ImageType\": 0, \"Visible\": false} ], \"SegmentationSettings\": { \"InitMethod\": \"\", \"MeshNamingMethod\": \"\", \"OverrideExisting\": false }, \"PawnPaths\": { \"BareboneCar\": {\"PawnBP\": \"Class'/AirSim/VehicleAdv/Vehicle/VehicleAdvPawn.VehicleAdvPawn_C'\"}, \"DefaultCar\": {\"PawnBP\": \"Class'/AirSim/VehicleAdv/SUV/SuvCarPawn.SuvCarPawn_C'\"}, \"DefaultQuadrotor\": {\"PawnBP\": \"Class'/AirSim/Blueprints/BP_FlyingPawn.BP_FlyingPawn_C'\"}, \"DefaultComputerVision\": {\"PawnBP\": \"Class'/AirSim/Blueprints/BP_ComputerVisionPawn.BP_ComputerVisionPawn_C'\"} }, \"Vehicles\": { \"SimpleFlight\": { \"VehicleType\": \"SimpleFlight\", \"DefaultVehicleState\": \"Armed\", \"AutoCreate\": true, \"PawnPath\": \"\", \"EnableCollisionPassthrogh\": false, \"EnableCollisions\": true, \"AllowAPIAlways\": true, \"RC\": { \"RemoteControlID\": 0, \"AllowAPIWhenDisconnected\": false }, \"Cameras\": { //same elements as CameraDefaults above, key as name }, \"X\": NaN, \"Y\": NaN, \"Z\": NaN, \"Pitch\": NaN, \"Roll\": NaN, \"Yaw\": NaN }, \"PhysXCar\": { \"VehicleType\": \"PhysXCar\", \"DefaultVehicleState\": \"\", \"AutoCreate\": true, \"PawnPath\": \"\", \"EnableCollisionPassthrogh\": false, \"EnableCollisions\": true, \"RC\": { \"RemoteControlID\": -1 }, \"Cameras\": { \"MyCamera1\": { //same elements as elements inside CameraDefaults above }, \"MyCamera2\": { //same elements as elements inside CameraDefaults above }, }, \"X\": NaN, \"Y\": NaN, \"Z\": NaN, \"Pitch\": NaN, \"Roll\": NaN, \"Yaw\": NaN } } } SimMode SimMode determines which simulation mode will be used. Below are currently supported values: - \"\" : prompt user to select vehicle type multirotor or car - \"Multirotor\" : Use multirotor simulation - \"Car\" : Use car simulation - \"ComputerVision\" : Use only camera, no vehicle or physics ViewMode The ViewMode determines which camera to use as default and how camera will follow the vehicle. For multirotors, the default ViewMode is \"FlyWithMe\" while for cars the default ViewMode is \"SpringArmChase\" . FlyWithMe : Chase the vehicle from behind with 6 degrees of freedom GroundObserver : Chase the vehicle from 6' above the ground but with full freedom in XY plane. Fpv : View the scene from front camera of vehicle Manual : Don't move camera automatically. Use arrow keys and ASWD keys for move camera manually. SpringArmChase : Chase the vehicle with camera mounted on (invisible) arm that is attached to the vehicle via spring (so it has some latency in movement). NoDisplay : This will freeze rendering for main screen however rendering for subwindows, recording and APIs remain active. This mode is useful to save resources in \"headless\" mode where you are only interested in getting images and don't care about what gets rendered on main screen. This may also improve FPS for recording images. TimeOfDay This setting controls the position of Sun in the environment. By default Enabled is false which means Sun's position is left at whatever was the default in the environment and it doesn't change over the time. If Enabled is true then Sun position is computed using longitude, latitude and altitude specified in OriginGeopoint section for the date specified in StartDateTime in the string format as %Y-%m-%d %H:%M:%S , for example, 2018-02-12 15:20:00 . If this string is empty then current date and time is used. If StartDateTimeDst is true then we adjust for day light savings time. The Sun's position is then continuously updated at the interval specified in UpdateIntervalSecs . In some cases, it might be desirable to have celestial clock run faster or slower than simulation clock. This can be specified using CelestialClockSpeed , for example, value 100 means for every 1 second of simulation clock, Sun's position is advanced by 100 seconds so Sun will move in sky much faster. OriginGeopoint This setting specifies the latitude, longitude and altitude of the Player Start component placed in the Unreal environment. The vehicle's home point is computed using this transformation. Note that all coordinates exposed via APIs are using NED system in SI units which means each vehicle starts at (0, 0, 0) in NED system. Time of Day settings are computed for geographical coordinates specified in OriginGeopoint . SubWindows This setting determines what is shown in each of 3 subwindows which are visible when you press 0 key. The WindowsID can be 0 to 2, CameraName is any available camera on the vehicle. ImageType integer value determines what kind of image gets shown according to ImageType enum . For example, for car vehicles below shows driver view, front bumper view and rear view as scene, depth and surface normals respectively. \"SubWindows\": [ {\"WindowID\": 0, \"ImageType\": 0, \"CameraName\": \"3\", \"Visible\": true}, {\"WindowID\": 1, \"ImageType\": 3, \"CameraName\": \"0\", \"Visible\": true}, {\"WindowID\": 2, \"ImageType\": 6, \"CameraName\": \"4\", \"Visible\": true} ] Recording The recording feature allows you to record data such as position, orientation, velocity along with the captured image at specified intervals. You can start recording by pressing red Record button on lower right or the R key. The data is stored in the Documents\\AirSim folder, in a time stamped subfolder for each recording session, as tab separated file. RecordInterval : specifies minimal interval in seconds between capturing two images. RecordOnMove : specifies that do not record frame if there was vehicle's position or orientation hasn't changed. Cameras : this element controls which cameras are used to capture images. By default scene image from camera 0 is recorded as compressed png format. This setting is json array so you can specify multiple cameras to capture images, each with potentially different image types . When PixelsAsFloat is true, image is saved as pfm file instead of png file. ClockSpeed This setting allows you to set the speed of simulation clock with respect to wall clock. For example, value of 5.0 would mean simulation clock has 5 seconds elapsed when wall clock has 1 second elapsed (i.e. simulation is running faster). The value of 0.1 means that simulation clock is 10X slower than wall clock. The value of 1 means simulation is running in real time. It is important to realize that quality of simulation may decrease as the simulation clock runs faster. You might see artifacts like object moving past obstacles because collision is not detected. However slowing down simulation clock (i.e. values < 1.0) generally improves the quality of simulation. Segmentation Settings The InitMethod determines how object IDs are initialized at startup to generate segmentation . The value \"\" or \"CommonObjectsRandomIDs\" (default) means assign random IDs to each object at startup. This will generate segmentation view with random colors assign to each object. The value \"None\" means don't initialize object IDs. This will cause segmentation view to have single solid colors. This mode is useful if you plan to set up object IDs using APIs and it can save lot of delay at startup for large environments like CityEnviron. If OverrideExisting is false then initialization does not alter non-zero object IDs already assigned otherwise it does. If MeshNamingMethod is \"\" or \"OwnerName\" then we use mesh's owner name to generate random hash as object IDs. If its \"StaticMeshName\" then we use static mesh's name to generate random hash as object IDs. Note that it is not possible to tell individual instances of the same static mesh apart this way, but the names are often more intuitive. Camera Settings The CameraDefaults element at root level specifies defaults used for all cameras. These defaults can be overridden for individual camera in Cameras element inside Vehicles as described later. Note on ImageType element The ImageType element in JSON array determines which image type that settings applies to. The valid values are described in ImageType section . In addition, we also support special value ImageType: -1 to apply the settings to external camera (i.e. what you are looking at on the screen). For example, CaptureSettings element is json array so you can add settings for multiple image types easily. CaptureSettings The CaptureSettings determines how different image types such as scene, depth, disparity, surface normals and segmentation views are rendered. The Width, Height and FOV settings should be self explanatory. The AutoExposureSpeed decides how fast eye adaptation works. We set to generally high value such as 100 to avoid artifacts in image capture. Similarly we set MotionBlurAmount to 0 by default to avoid artifacts in ground truth images. The ProjectionMode decides the projection used by the capture camera and can take value \"perspective\" (default) or \"orthographic\". If projection mode is \"orthographic\" then OrthoWidth determines width of projected area captured in meters. For explanation of other settings, please see this article . NoiseSettings The NoiseSettings allows to add noise to the specified image type with a goal of simulating camera sensor noise, interference and other artifacts. By default no noise is added, i.e., Enabled: false . If you set Enabled: true then following different types of noise and interference artifacts are enabled, each can be further tuned using setting. The noise effects are implemented as shader created as post processing material in Unreal Engine called CameraSensorNoise . Demo of camera noise and interference simulation: Random noise This adds random noise blobs with following parameters. RandContrib : This determines blend ratio of noise pixel with image pixel, 0 means no noise and 1 means only noise. RandSpeed : This determines how fast noise fluctuates, 1 means no fluctuation and higher values like 1E6 means full fluctuation. RandSize : This determines how coarse noise is, 1 means every pixel has its own noise while higher value means more than 1 pixels share same noise value. RandDensity : This determines how many pixels out of total will have noise, 1 means all pixels while higher value means lesser number of pixels (exponentially). Horizontal bump distortion This adds horizontal bumps / flickering / ghosting effect. HorzWaveContrib : This determines blend ratio of noise pixel with image pixel, 0 means no noise and 1 means only noise. HorzWaveStrength : This determines overall strength of the effect. HorzWaveVertSize : This determines how many vertical pixels would be effected by the effect. HorzWaveScreenSize : This determines how much of the screen is effected by the effect. Horizontal noise lines This adds regions of noise on horizontal lines. HorzNoiseLinesContrib : This determines blend ratio of noise pixel with image pixel, 0 means no noise and 1 means only noise. HorzNoiseLinesDensityY : This determines how many pixels in horizontal line gets affected. * HorzNoiseLinesDensityXY : This determines how many lines on screen gets affected. Horizontal line distortion This adds fluctuations on horizontal line. HorzDistortionContrib : This determines blend ratio of noise pixel with image pixel, 0 means no noise and 1 means only noise. HorzDistortionStrength : This determines how large is the distortion. Gimbal The Gimbal element allows to freeze camera orientation for pitch, roll and/or yaw. This setting is ignored unless ImageType is -1. The Stabilization is defaulted to 0 meaning no gimbal i.e. camera orientation changes with body orientation on all axis. The value of 1 means full stabilization. The value between 0 to 1 acts as a weight for fixed angles specified (in degrees, in world-frame) in Pitch , Roll and Yaw elements and orientation of the vehicle body. When any of the angles is omitted from json or set to NaN, that angle is not stabilized (i.e. it moves along with vehicle body). Vehicles Settings Each simulation mode will go through the list of vehicles specified in this setting and create the ones that has \"AutoCreate\": true . Each vehicle specified in this setting has key which becomes the name of the vehicle. If \"Vehicles\" element is missing then this list is populated with default car named \"PhysXCar\" and default multirotor named \"SimpleFlight\". Common Vehicle Setting VehicleType : This could be either PhysXCar , SimpleFlight , PX4Multirotor or ComputerVision . There is no default value therefore this element must be specified. PawnPath : This allows to override the pawn blueprint to use for the vehicle. For example, you may create new pawn blueprint derived from ACarPawn for a warehouse robot in your own project outside the AirSim code and then specify its path here. See also PawnPaths . DefaultVehicleState : Possible value for multirotors is Armed or Disarmed . AutoCreate : If true then this vehicle would be spawned (if supported by selected sim mode). RC : This sub-element allows to specify which remote controller to use for vehicle using RemoteControlID . The value of -1 means use keyboard (not supported yet for multirotors). The value >= 0 specifies one of many remote controllers connected to the system. The list of available RCs can be seen in Game Controllers panel in Windows, for example. X, Y, Z, Yaw, Roll, Pitch : These elements allows you to specify the initial position and orientation of the vehicle. Position is in NED coordinates in SI units with origin set to Player Start location in Unreal environment. The orientation is specified in degrees. IsFpvVehicle : This setting allows to specify which vehicle camera will follow and the view that will be shown when ViewMode is set to Fpv. By default, AirSim selects the first vehicle in settings as FPV vehicle. Cameras : This element specifies camera settings for vehicle. The key in this element is name of the available camera and the value is same as CameraDefaults as described above. For example, to change FOV for the front center camera to 120 degrees, you can use this for Vehicles setting: \"Vehicles\": { \"FishEyeDrone\": { \"VehicleType\": \"SimpleFlight\", \"Cameras\": { \"front-center\": { \"CaptureSettings\": [ { \"ImageType\": 0, \"FOV_Degrees\": 120 } ] } } } } Using PX4 By default we use simple_flight so you don't have to do separate HITL or SITL setups. We also support \"PX4\" for advanced users. To use PX4 with AirSim, you can use the following for Vehicles setting: \"Vehicles\": { \"PX4\": { \"VehicleType\": \"PX4Multirotor\", } } Additional PX4 Settings The defaults for PX4 is to enable hardware-in-loop setup. There are various other settings available for PX4 as follows with their default values: \"Vehicles\": { \"PX4\": { \"VehicleType\": \"PX4Multirotor\", \"LogViewerHostIp\": \"127.0.0.1\", \"LogViewerPort\": 14388, \"OffboardCompID\": 1, \"OffboardSysID\": 134, \"QgcHostIp\": \"127.0.0.1\", \"QgcPort\": 14550, \"SerialBaudRate\": 115200, \"SerialPort\": \"*\", \"SimCompID\": 42, \"SimSysID\": 142, \"SitlIp\": \"127.0.0.1\", \"SitlPort\": 14556, \"UdpIp\": \"127.0.0.1\", \"UdpPort\": 14560, \"UseSerial\": true, \"VehicleCompID\": 1, \"VehicleSysID\": 135, \"Model\": \"Generic\", \"LocalHostIp\": \"127.0.0.1\" } } These settings define the MavLink SystemId and ComponentId for the Simulator (SimSysID, SimCompID), and for an optional external renderer (ExtRendererSysID, ExtRendererCompID) and the node that allows remote control of the drone from another app this is called the Air Control node (AirControlSysID, AirControlCompID). If you want the simulator to also talk to your ground control app (like QGroundControl) you can also set the UDP address for that in case you want to run that on a different machine (QgcHostIp,QgcPort). You can connect the simulator to the LogViewer app, provided in this repo, by setting the UDP address for that (LogViewerHostIp,LogViewerPort). And for each flying drone added to the simulator there is a named block of additional settings. In the above you see the default name \"PX4\". You can change this name from the Unreal Editor when you add a new BP_FlyingPawn asset. You will see these properties grouped under the category \"MavLink\". The MavLink node for this pawn can be remote over UDP or it can be connected to a local serial port. If serial then set UseSerial to true, otherwise set UseSerial to false and set the appropriate bard rate. The default of 115200 works with Pixhawk version 2 over USB. Other Settings EngineSound To turn off the engine sound use setting \"EngineSound\": false . Currently this setting applies only to car. PawnPaths This allows you to specify your own vehicle pawn blueprints, for example, you can replace the default car in AirSim with your own car. Your vehicle BP can reside in Content folder of your own Unreal project (i.e. outside of AirSim plugin folder). For example, if you have a car BP located in file Content\\MyCar\\MySedanBP.uasset in your project then you can set \"DefaultCar\": {\"PawnBP\":\"Class'/Game/MyCar/MySedanBP.MySedanBP_C'\"} . The XYZ.XYZ_C is a special notation required to specify class for BP XYZ . Please note that your BP must be derived from CarPawn class. By default this is not the case but you can re-parent the BP using the \"Class Settings\" button in toolbar in UE editor after you open the BP and then choosing \"Car Pawn\" for Parent Class settings in Class Options. It's also a good idea to disable \"Auto Possess Player\" and \"Auto Possess AI\" as well as set AI Controller Class to None in BP details. Please make sure your asset is included for cooking in packaging options if you are creating binary. PhysicsEngineName For cars, we support only PhysX for now (regardless of value in this setting). For multirotors, we support \"FastPhysicsEngine\" only. LocalHostIp Setting Now when connecting to remote machines you may need to pick a specific Ethernet adapter to reach those machines, for example, it might be over Ethernet or over Wi-Fi, or some other special virtual adapter or a VPN. Your PC may have multiple networks, and those networks might not be allowed to talk to each other, in which case the UDP messages from one network will not get through to the others. So the LocalHostIp allows you to configure how you are reaching those machines. The default of 127.0.0.1 is not able to reach external machines, this default is only used when everything you are talking to is contained on a single PC. SpeedUnitFactor Unit conversion factor for speed related to m/s , default is 1. Used in conjunction with SpeedUnitLabel. This may be only used for display purposes for example on-display speed when car is being driven. For example, to get speed in miles/hr use factor 2.23694. SpeedUnitLabel Unit label for speed, default is m/s . Used in conjunction with SpeedUnitFactor.","title":"Settings"},{"location":"docs/settings/#airsim-settings","text":"","title":"AirSim Settings"},{"location":"docs/settings/#where-are-settings-stored","text":"Windows: Documents\\AirSim Linux: ~/Documents/AirSim The file is in usual json format . On first startup AirSim would create settings.json file with no settings. To avoid problems, always use ASCII format to save json file.","title":"Where are Settings Stored?"},{"location":"docs/settings/#how-to-chose-between-car-and-multirotor","text":"The default is to use multirotor. To use car simple set \"SimMode\": \"Car\" like this: { \"SettingsVersion\": 1.2, \"SimMode\": \"Car\" } To choose multirotor, set \"SimMode\": \"Multirotor\" . If you want to prompt user to select vehicle type then use \"SimMode\": \"\" .","title":"How to Chose Between Car and Multirotor?"},{"location":"docs/settings/#available-settings-and-their-defaults","text":"Below are complete list of settings available along with their default values. If any of the settings is missing from json file, then default value is used. Some default values are simply specified as \"\" which means actual value may be chosen based on the vehicle you are using. For example, ViewMode setting has default value \"\" which translates to \"FlyWithMe\" for drones and \"SpringArmChase\" for cars. WARNING: Do not copy paste all of below in your settings.json. We strongly recommend adding only those settings that you don't want default values. Only required element is \"SettingsVersion\" . { \"SimMode\": \"\", \"ClockType\": \"\", \"ClockSpeed\": 1, \"LocalHostIp\": \"127.0.0.1\", \"RecordUIVisible\": true, \"LogMessagesVisible\": true, \"ViewMode\": \"\", \"RpcEnabled\": true, \"EngineSound\": true, \"PhysicsEngineName\": \"\", \"SpeedUnitFactor\": 1.0, \"SpeedUnitLabel\": \"m/s\", \"Recording\": { \"RecordOnMove\": false, \"RecordInterval\": 0.05, \"Cameras\": [ { \"CameraName\": \"0\", \"ImageType\": 0, \"PixelsAsFloat\": false, \"Compress\": true } ] }, \"CameraDefaults\": { \"CaptureSettings\": [ { \"ImageType\": 0, \"Width\": 256, \"Height\": 144, \"FOV_Degrees\": 90, \"AutoExposureSpeed\": 100, \"AutoExposureBias\": 0, \"AutoExposureMaxBrightness\": 0.64, \"AutoExposureMinBrightness\": 0.03, \"MotionBlurAmount\": 0, \"TargetGamma\": 1.0, \"ProjectionMode\": \"\", \"OrthoWidth\": 5.12 } ], \"NoiseSettings\": [ { \"Enabled\": false, \"ImageType\": 0, \"RandContrib\": 0.2, \"RandSpeed\": 100000.0, \"RandSize\": 500.0, \"RandDensity\": 2, \"HorzWaveContrib\":0.03, \"HorzWaveStrength\": 0.08, \"HorzWaveVertSize\": 1.0, \"HorzWaveScreenSize\": 1.0, \"HorzNoiseLinesContrib\": 1.0, \"HorzNoiseLinesDensityY\": 0.01, \"HorzNoiseLinesDensityXY\": 0.5, \"HorzDistortionContrib\": 1.0, \"HorzDistortionStrength\": 0.002 } ], \"Gimbal\": { \"Stabilization\": 0, \"Pitch\": NaN, \"Roll\": NaN, \"Yaw\": NaN } \"X\": NaN, \"Y\": NaN, \"Z\": NaN, \"Pitch\": NaN, \"Roll\": NaN, \"Yaw\": NaN }, \"OriginGeopoint\": { \"Latitude\": 47.641468, \"Longitude\": -122.140165, \"Altitude\": 122 }, \"TimeOfDay\": { \"Enabled\": false, \"StartDateTime\": \"\", \"CelestialClockSpeed\": 1, \"StartDateTimeDst\": false, \"UpdateIntervalSecs\": 60 }, \"SubWindows\": [ {\"WindowID\": 0, \"CameraName\": \"0\", \"ImageType\": 3, \"Visible\": false}, {\"WindowID\": 1, \"CameraName\": \"0\", \"ImageType\": 5, \"Visible\": false}, {\"WindowID\": 2, \"CameraName\": \"0\", \"ImageType\": 0, \"Visible\": false} ], \"SegmentationSettings\": { \"InitMethod\": \"\", \"MeshNamingMethod\": \"\", \"OverrideExisting\": false }, \"PawnPaths\": { \"BareboneCar\": {\"PawnBP\": \"Class'/AirSim/VehicleAdv/Vehicle/VehicleAdvPawn.VehicleAdvPawn_C'\"}, \"DefaultCar\": {\"PawnBP\": \"Class'/AirSim/VehicleAdv/SUV/SuvCarPawn.SuvCarPawn_C'\"}, \"DefaultQuadrotor\": {\"PawnBP\": \"Class'/AirSim/Blueprints/BP_FlyingPawn.BP_FlyingPawn_C'\"}, \"DefaultComputerVision\": {\"PawnBP\": \"Class'/AirSim/Blueprints/BP_ComputerVisionPawn.BP_ComputerVisionPawn_C'\"} }, \"Vehicles\": { \"SimpleFlight\": { \"VehicleType\": \"SimpleFlight\", \"DefaultVehicleState\": \"Armed\", \"AutoCreate\": true, \"PawnPath\": \"\", \"EnableCollisionPassthrogh\": false, \"EnableCollisions\": true, \"AllowAPIAlways\": true, \"RC\": { \"RemoteControlID\": 0, \"AllowAPIWhenDisconnected\": false }, \"Cameras\": { //same elements as CameraDefaults above, key as name }, \"X\": NaN, \"Y\": NaN, \"Z\": NaN, \"Pitch\": NaN, \"Roll\": NaN, \"Yaw\": NaN }, \"PhysXCar\": { \"VehicleType\": \"PhysXCar\", \"DefaultVehicleState\": \"\", \"AutoCreate\": true, \"PawnPath\": \"\", \"EnableCollisionPassthrogh\": false, \"EnableCollisions\": true, \"RC\": { \"RemoteControlID\": -1 }, \"Cameras\": { \"MyCamera1\": { //same elements as elements inside CameraDefaults above }, \"MyCamera2\": { //same elements as elements inside CameraDefaults above }, }, \"X\": NaN, \"Y\": NaN, \"Z\": NaN, \"Pitch\": NaN, \"Roll\": NaN, \"Yaw\": NaN } } }","title":"Available Settings and Their Defaults"},{"location":"docs/settings/#simmode","text":"SimMode determines which simulation mode will be used. Below are currently supported values: - \"\" : prompt user to select vehicle type multirotor or car - \"Multirotor\" : Use multirotor simulation - \"Car\" : Use car simulation - \"ComputerVision\" : Use only camera, no vehicle or physics","title":"SimMode"},{"location":"docs/settings/#viewmode","text":"The ViewMode determines which camera to use as default and how camera will follow the vehicle. For multirotors, the default ViewMode is \"FlyWithMe\" while for cars the default ViewMode is \"SpringArmChase\" . FlyWithMe : Chase the vehicle from behind with 6 degrees of freedom GroundObserver : Chase the vehicle from 6' above the ground but with full freedom in XY plane. Fpv : View the scene from front camera of vehicle Manual : Don't move camera automatically. Use arrow keys and ASWD keys for move camera manually. SpringArmChase : Chase the vehicle with camera mounted on (invisible) arm that is attached to the vehicle via spring (so it has some latency in movement). NoDisplay : This will freeze rendering for main screen however rendering for subwindows, recording and APIs remain active. This mode is useful to save resources in \"headless\" mode where you are only interested in getting images and don't care about what gets rendered on main screen. This may also improve FPS for recording images.","title":"ViewMode"},{"location":"docs/settings/#timeofday","text":"This setting controls the position of Sun in the environment. By default Enabled is false which means Sun's position is left at whatever was the default in the environment and it doesn't change over the time. If Enabled is true then Sun position is computed using longitude, latitude and altitude specified in OriginGeopoint section for the date specified in StartDateTime in the string format as %Y-%m-%d %H:%M:%S , for example, 2018-02-12 15:20:00 . If this string is empty then current date and time is used. If StartDateTimeDst is true then we adjust for day light savings time. The Sun's position is then continuously updated at the interval specified in UpdateIntervalSecs . In some cases, it might be desirable to have celestial clock run faster or slower than simulation clock. This can be specified using CelestialClockSpeed , for example, value 100 means for every 1 second of simulation clock, Sun's position is advanced by 100 seconds so Sun will move in sky much faster.","title":"TimeOfDay"},{"location":"docs/settings/#origingeopoint","text":"This setting specifies the latitude, longitude and altitude of the Player Start component placed in the Unreal environment. The vehicle's home point is computed using this transformation. Note that all coordinates exposed via APIs are using NED system in SI units which means each vehicle starts at (0, 0, 0) in NED system. Time of Day settings are computed for geographical coordinates specified in OriginGeopoint .","title":"OriginGeopoint"},{"location":"docs/settings/#subwindows","text":"This setting determines what is shown in each of 3 subwindows which are visible when you press 0 key. The WindowsID can be 0 to 2, CameraName is any available camera on the vehicle. ImageType integer value determines what kind of image gets shown according to ImageType enum . For example, for car vehicles below shows driver view, front bumper view and rear view as scene, depth and surface normals respectively. \"SubWindows\": [ {\"WindowID\": 0, \"ImageType\": 0, \"CameraName\": \"3\", \"Visible\": true}, {\"WindowID\": 1, \"ImageType\": 3, \"CameraName\": \"0\", \"Visible\": true}, {\"WindowID\": 2, \"ImageType\": 6, \"CameraName\": \"4\", \"Visible\": true} ]","title":"SubWindows"},{"location":"docs/settings/#recording","text":"The recording feature allows you to record data such as position, orientation, velocity along with the captured image at specified intervals. You can start recording by pressing red Record button on lower right or the R key. The data is stored in the Documents\\AirSim folder, in a time stamped subfolder for each recording session, as tab separated file. RecordInterval : specifies minimal interval in seconds between capturing two images. RecordOnMove : specifies that do not record frame if there was vehicle's position or orientation hasn't changed. Cameras : this element controls which cameras are used to capture images. By default scene image from camera 0 is recorded as compressed png format. This setting is json array so you can specify multiple cameras to capture images, each with potentially different image types . When PixelsAsFloat is true, image is saved as pfm file instead of png file.","title":"Recording"},{"location":"docs/settings/#clockspeed","text":"This setting allows you to set the speed of simulation clock with respect to wall clock. For example, value of 5.0 would mean simulation clock has 5 seconds elapsed when wall clock has 1 second elapsed (i.e. simulation is running faster). The value of 0.1 means that simulation clock is 10X slower than wall clock. The value of 1 means simulation is running in real time. It is important to realize that quality of simulation may decrease as the simulation clock runs faster. You might see artifacts like object moving past obstacles because collision is not detected. However slowing down simulation clock (i.e. values < 1.0) generally improves the quality of simulation.","title":"ClockSpeed"},{"location":"docs/settings/#segmentation-settings","text":"The InitMethod determines how object IDs are initialized at startup to generate segmentation . The value \"\" or \"CommonObjectsRandomIDs\" (default) means assign random IDs to each object at startup. This will generate segmentation view with random colors assign to each object. The value \"None\" means don't initialize object IDs. This will cause segmentation view to have single solid colors. This mode is useful if you plan to set up object IDs using APIs and it can save lot of delay at startup for large environments like CityEnviron. If OverrideExisting is false then initialization does not alter non-zero object IDs already assigned otherwise it does. If MeshNamingMethod is \"\" or \"OwnerName\" then we use mesh's owner name to generate random hash as object IDs. If its \"StaticMeshName\" then we use static mesh's name to generate random hash as object IDs. Note that it is not possible to tell individual instances of the same static mesh apart this way, but the names are often more intuitive.","title":"Segmentation Settings"},{"location":"docs/settings/#camera-settings","text":"The CameraDefaults element at root level specifies defaults used for all cameras. These defaults can be overridden for individual camera in Cameras element inside Vehicles as described later.","title":"Camera Settings"},{"location":"docs/settings/#note-on-imagetype-element","text":"The ImageType element in JSON array determines which image type that settings applies to. The valid values are described in ImageType section . In addition, we also support special value ImageType: -1 to apply the settings to external camera (i.e. what you are looking at on the screen). For example, CaptureSettings element is json array so you can add settings for multiple image types easily.","title":"Note on ImageType element"},{"location":"docs/settings/#capturesettings","text":"The CaptureSettings determines how different image types such as scene, depth, disparity, surface normals and segmentation views are rendered. The Width, Height and FOV settings should be self explanatory. The AutoExposureSpeed decides how fast eye adaptation works. We set to generally high value such as 100 to avoid artifacts in image capture. Similarly we set MotionBlurAmount to 0 by default to avoid artifacts in ground truth images. The ProjectionMode decides the projection used by the capture camera and can take value \"perspective\" (default) or \"orthographic\". If projection mode is \"orthographic\" then OrthoWidth determines width of projected area captured in meters. For explanation of other settings, please see this article .","title":"CaptureSettings"},{"location":"docs/settings/#noisesettings","text":"The NoiseSettings allows to add noise to the specified image type with a goal of simulating camera sensor noise, interference and other artifacts. By default no noise is added, i.e., Enabled: false . If you set Enabled: true then following different types of noise and interference artifacts are enabled, each can be further tuned using setting. The noise effects are implemented as shader created as post processing material in Unreal Engine called CameraSensorNoise . Demo of camera noise and interference simulation:","title":"NoiseSettings"},{"location":"docs/settings/#random-noise","text":"This adds random noise blobs with following parameters. RandContrib : This determines blend ratio of noise pixel with image pixel, 0 means no noise and 1 means only noise. RandSpeed : This determines how fast noise fluctuates, 1 means no fluctuation and higher values like 1E6 means full fluctuation. RandSize : This determines how coarse noise is, 1 means every pixel has its own noise while higher value means more than 1 pixels share same noise value. RandDensity : This determines how many pixels out of total will have noise, 1 means all pixels while higher value means lesser number of pixels (exponentially).","title":"Random noise"},{"location":"docs/settings/#horizontal-bump-distortion","text":"This adds horizontal bumps / flickering / ghosting effect. HorzWaveContrib : This determines blend ratio of noise pixel with image pixel, 0 means no noise and 1 means only noise. HorzWaveStrength : This determines overall strength of the effect. HorzWaveVertSize : This determines how many vertical pixels would be effected by the effect. HorzWaveScreenSize : This determines how much of the screen is effected by the effect.","title":"Horizontal bump distortion"},{"location":"docs/settings/#horizontal-noise-lines","text":"This adds regions of noise on horizontal lines. HorzNoiseLinesContrib : This determines blend ratio of noise pixel with image pixel, 0 means no noise and 1 means only noise. HorzNoiseLinesDensityY : This determines how many pixels in horizontal line gets affected. * HorzNoiseLinesDensityXY : This determines how many lines on screen gets affected.","title":"Horizontal noise lines"},{"location":"docs/settings/#horizontal-line-distortion","text":"This adds fluctuations on horizontal line. HorzDistortionContrib : This determines blend ratio of noise pixel with image pixel, 0 means no noise and 1 means only noise. HorzDistortionStrength : This determines how large is the distortion.","title":"Horizontal line distortion"},{"location":"docs/settings/#gimbal","text":"The Gimbal element allows to freeze camera orientation for pitch, roll and/or yaw. This setting is ignored unless ImageType is -1. The Stabilization is defaulted to 0 meaning no gimbal i.e. camera orientation changes with body orientation on all axis. The value of 1 means full stabilization. The value between 0 to 1 acts as a weight for fixed angles specified (in degrees, in world-frame) in Pitch , Roll and Yaw elements and orientation of the vehicle body. When any of the angles is omitted from json or set to NaN, that angle is not stabilized (i.e. it moves along with vehicle body).","title":"Gimbal"},{"location":"docs/settings/#vehicles-settings","text":"Each simulation mode will go through the list of vehicles specified in this setting and create the ones that has \"AutoCreate\": true . Each vehicle specified in this setting has key which becomes the name of the vehicle. If \"Vehicles\" element is missing then this list is populated with default car named \"PhysXCar\" and default multirotor named \"SimpleFlight\".","title":"Vehicles Settings"},{"location":"docs/settings/#common-vehicle-setting","text":"VehicleType : This could be either PhysXCar , SimpleFlight , PX4Multirotor or ComputerVision . There is no default value therefore this element must be specified. PawnPath : This allows to override the pawn blueprint to use for the vehicle. For example, you may create new pawn blueprint derived from ACarPawn for a warehouse robot in your own project outside the AirSim code and then specify its path here. See also PawnPaths . DefaultVehicleState : Possible value for multirotors is Armed or Disarmed . AutoCreate : If true then this vehicle would be spawned (if supported by selected sim mode). RC : This sub-element allows to specify which remote controller to use for vehicle using RemoteControlID . The value of -1 means use keyboard (not supported yet for multirotors). The value >= 0 specifies one of many remote controllers connected to the system. The list of available RCs can be seen in Game Controllers panel in Windows, for example. X, Y, Z, Yaw, Roll, Pitch : These elements allows you to specify the initial position and orientation of the vehicle. Position is in NED coordinates in SI units with origin set to Player Start location in Unreal environment. The orientation is specified in degrees. IsFpvVehicle : This setting allows to specify which vehicle camera will follow and the view that will be shown when ViewMode is set to Fpv. By default, AirSim selects the first vehicle in settings as FPV vehicle. Cameras : This element specifies camera settings for vehicle. The key in this element is name of the available camera and the value is same as CameraDefaults as described above. For example, to change FOV for the front center camera to 120 degrees, you can use this for Vehicles setting: \"Vehicles\": { \"FishEyeDrone\": { \"VehicleType\": \"SimpleFlight\", \"Cameras\": { \"front-center\": { \"CaptureSettings\": [ { \"ImageType\": 0, \"FOV_Degrees\": 120 } ] } } } }","title":"Common Vehicle Setting"},{"location":"docs/settings/#using-px4","text":"By default we use simple_flight so you don't have to do separate HITL or SITL setups. We also support \"PX4\" for advanced users. To use PX4 with AirSim, you can use the following for Vehicles setting: \"Vehicles\": { \"PX4\": { \"VehicleType\": \"PX4Multirotor\", } }","title":"Using PX4"},{"location":"docs/settings/#additional-px4-settings","text":"The defaults for PX4 is to enable hardware-in-loop setup. There are various other settings available for PX4 as follows with their default values: \"Vehicles\": { \"PX4\": { \"VehicleType\": \"PX4Multirotor\", \"LogViewerHostIp\": \"127.0.0.1\", \"LogViewerPort\": 14388, \"OffboardCompID\": 1, \"OffboardSysID\": 134, \"QgcHostIp\": \"127.0.0.1\", \"QgcPort\": 14550, \"SerialBaudRate\": 115200, \"SerialPort\": \"*\", \"SimCompID\": 42, \"SimSysID\": 142, \"SitlIp\": \"127.0.0.1\", \"SitlPort\": 14556, \"UdpIp\": \"127.0.0.1\", \"UdpPort\": 14560, \"UseSerial\": true, \"VehicleCompID\": 1, \"VehicleSysID\": 135, \"Model\": \"Generic\", \"LocalHostIp\": \"127.0.0.1\" } } These settings define the MavLink SystemId and ComponentId for the Simulator (SimSysID, SimCompID), and for an optional external renderer (ExtRendererSysID, ExtRendererCompID) and the node that allows remote control of the drone from another app this is called the Air Control node (AirControlSysID, AirControlCompID). If you want the simulator to also talk to your ground control app (like QGroundControl) you can also set the UDP address for that in case you want to run that on a different machine (QgcHostIp,QgcPort). You can connect the simulator to the LogViewer app, provided in this repo, by setting the UDP address for that (LogViewerHostIp,LogViewerPort). And for each flying drone added to the simulator there is a named block of additional settings. In the above you see the default name \"PX4\". You can change this name from the Unreal Editor when you add a new BP_FlyingPawn asset. You will see these properties grouped under the category \"MavLink\". The MavLink node for this pawn can be remote over UDP or it can be connected to a local serial port. If serial then set UseSerial to true, otherwise set UseSerial to false and set the appropriate bard rate. The default of 115200 works with Pixhawk version 2 over USB.","title":"Additional PX4 Settings"},{"location":"docs/settings/#other-settings","text":"","title":"Other Settings"},{"location":"docs/settings/#enginesound","text":"To turn off the engine sound use setting \"EngineSound\": false . Currently this setting applies only to car.","title":"EngineSound"},{"location":"docs/settings/#pawnpaths","text":"This allows you to specify your own vehicle pawn blueprints, for example, you can replace the default car in AirSim with your own car. Your vehicle BP can reside in Content folder of your own Unreal project (i.e. outside of AirSim plugin folder). For example, if you have a car BP located in file Content\\MyCar\\MySedanBP.uasset in your project then you can set \"DefaultCar\": {\"PawnBP\":\"Class'/Game/MyCar/MySedanBP.MySedanBP_C'\"} . The XYZ.XYZ_C is a special notation required to specify class for BP XYZ . Please note that your BP must be derived from CarPawn class. By default this is not the case but you can re-parent the BP using the \"Class Settings\" button in toolbar in UE editor after you open the BP and then choosing \"Car Pawn\" for Parent Class settings in Class Options. It's also a good idea to disable \"Auto Possess Player\" and \"Auto Possess AI\" as well as set AI Controller Class to None in BP details. Please make sure your asset is included for cooking in packaging options if you are creating binary.","title":"PawnPaths"},{"location":"docs/settings/#physicsenginename","text":"For cars, we support only PhysX for now (regardless of value in this setting). For multirotors, we support \"FastPhysicsEngine\" only.","title":"PhysicsEngineName"},{"location":"docs/settings/#localhostip-setting","text":"Now when connecting to remote machines you may need to pick a specific Ethernet adapter to reach those machines, for example, it might be over Ethernet or over Wi-Fi, or some other special virtual adapter or a VPN. Your PC may have multiple networks, and those networks might not be allowed to talk to each other, in which case the UDP messages from one network will not get through to the others. So the LocalHostIp allows you to configure how you are reaching those machines. The default of 127.0.0.1 is not able to reach external machines, this default is only used when everything you are talking to is contained on a single PC.","title":"LocalHostIp Setting"},{"location":"docs/settings/#speedunitfactor","text":"Unit conversion factor for speed related to m/s , default is 1. Used in conjunction with SpeedUnitLabel. This may be only used for display purposes for example on-display speed when car is being driven. For example, to get speed in miles/hr use factor 2.23694.","title":"SpeedUnitFactor"},{"location":"docs/settings/#speedunitlabel","text":"Unit label for speed, default is m/s . Used in conjunction with SpeedUnitFactor.","title":"SpeedUnitLabel"},{"location":"docs/simple_flight/","text":"simple_flight If you don't know what flight controller does than see What is Flight Controller? . AirSim has built-in flight controller called simple_flight and it is used by default. You don't need to do anything to use or configure it. AirSim also supports PX4 as another flight controller for advanced users. In future, we also plan to support ROSFlight and Hackflight . Advantages The advantage of using simple_flight is zero additional setup you need to do and it \"just works\". Also, simple_flight uses steppable clock which means you can pause the simulation and things are not at mercy of high variance low precision clock that operating system provides. Further, simple_flight is simple, cross platform and 100% header-only dependency-free C++ code which means you can literally step through from simulator to inside flight controller code within same code base! Design Normally flight controllers are designed to run on actual hardware on vehicles and their support for running in simulator varies widely. They are often fairly difficult to configure for non-expert users and typically have complex build usually lacking cross platform support. All these problems have played significant part in design of simple_flight. simple_flight is designed from ground up as library with clean interface that can work onboard the vehicle as well as simulator. The core principle is that flight controller has no way to specify special simulation mode and there for it has no way to know if it is running under simulation or real vehicle. We thus view flight controller simply as collection of algorithms packaged in a library. Another key emphasis is to develop this code as dependency free header-only pure standard C++11 code. This means there is no special build required to compile simple_flight. You just copy its source code to any project you wish and it just works. Control simple_flight can control vehicle by taking in desired input as angle rate, angle level, velocity or position. Each axis of control can be specified with one of these modes. Internally simple_flight uses cascade of PID controllers to finally generate actuator signals. This means position PID drives velocity PID which drives angle level PID which finally drives angle rate PID. State Estimation In current release we are using ground truth from simulator for our state estimation. We plan to add complimentary filter based state estimation for angular velocity and orientation using 2 sensors (gyroscope, accelerometer) in near future. In more longer term, we plan to integrate another library to do velocity and position estimation using 4 sensors (gyroscope, accelerometer, magnetometer and barometer) using EKF. If you have experience this area than we encourage you to engage with us and contribute! Supported Boards Currently we have implemented simple_flight interfaces for simulated board. We plan to implement it for Pixhawk V2 board and possibly Naze32 board. We expect all our code to remain unchanged and the implementation would mainly involve adding drivers for various sensors, handling ISRs and managing other board specific details. If you have experience this area than we encourage you to engage with us and contribute! Configuration To have AirSim use simple_flight, you can specify it in settings.json as shown below. Note that this is default so you don't have to do it explicitly. \"Vehicles\": { \"SimpleFlight\": { \"VehicleType\": \"SimpleFlight\", } } By default, vehicle using simple_flight is already armed which is why you would see propellers spinning. However if you don't want that than set DefaultVehicleState to Inactive like this: \"Vehicles\": { \"SimpleFlight\": { \"VehicleType\": \"SimpleFlight\", \"DefaultVehicleState\": \"Inactive\" } } In this case, you will need to either manually arm using RC sticks in down inward position or using APIs. For safety reasons, flight controllers would disallow API control unless human operator has consented using a switch on RC. Also, when RC control is lost, vehicle should disable API control and enter hover mode for safety reasons. To simplify things a bit, simple_flight enables API control without human consent using RC and even when RC is not detected by default however you can change this using following setting: \"Vehicles\": { \"SimpleFlight\": { \"VehicleType\": \"SimpleFlight\", \"AllowAPIAlways\": true, \"RC\": { \"RemoteControlID\": 0, \"AllowAPIWhenDisconnected\": true } } } Finally, simple_flight uses steppable clock by default which means clock advances when simulator tells it to advance (unlike wall clock which advances strictly according to passage of time). This means clock can be paused, for example, if code hits the break point and there is zero variance in clock (clock APIs provides by operating system might have significant variance unless its \"real time\" OS). If you want simple_flight to use wall clock instead than use following settings: \"ClockType\": \"ScalableClock\"","title":"Simple Flight"},{"location":"docs/simple_flight/#simple_flight","text":"If you don't know what flight controller does than see What is Flight Controller? . AirSim has built-in flight controller called simple_flight and it is used by default. You don't need to do anything to use or configure it. AirSim also supports PX4 as another flight controller for advanced users. In future, we also plan to support ROSFlight and Hackflight .","title":"simple_flight"},{"location":"docs/simple_flight/#advantages","text":"The advantage of using simple_flight is zero additional setup you need to do and it \"just works\". Also, simple_flight uses steppable clock which means you can pause the simulation and things are not at mercy of high variance low precision clock that operating system provides. Further, simple_flight is simple, cross platform and 100% header-only dependency-free C++ code which means you can literally step through from simulator to inside flight controller code within same code base!","title":"Advantages"},{"location":"docs/simple_flight/#design","text":"Normally flight controllers are designed to run on actual hardware on vehicles and their support for running in simulator varies widely. They are often fairly difficult to configure for non-expert users and typically have complex build usually lacking cross platform support. All these problems have played significant part in design of simple_flight. simple_flight is designed from ground up as library with clean interface that can work onboard the vehicle as well as simulator. The core principle is that flight controller has no way to specify special simulation mode and there for it has no way to know if it is running under simulation or real vehicle. We thus view flight controller simply as collection of algorithms packaged in a library. Another key emphasis is to develop this code as dependency free header-only pure standard C++11 code. This means there is no special build required to compile simple_flight. You just copy its source code to any project you wish and it just works.","title":"Design"},{"location":"docs/simple_flight/#control","text":"simple_flight can control vehicle by taking in desired input as angle rate, angle level, velocity or position. Each axis of control can be specified with one of these modes. Internally simple_flight uses cascade of PID controllers to finally generate actuator signals. This means position PID drives velocity PID which drives angle level PID which finally drives angle rate PID.","title":"Control"},{"location":"docs/simple_flight/#state-estimation","text":"In current release we are using ground truth from simulator for our state estimation. We plan to add complimentary filter based state estimation for angular velocity and orientation using 2 sensors (gyroscope, accelerometer) in near future. In more longer term, we plan to integrate another library to do velocity and position estimation using 4 sensors (gyroscope, accelerometer, magnetometer and barometer) using EKF. If you have experience this area than we encourage you to engage with us and contribute!","title":"State Estimation"},{"location":"docs/simple_flight/#supported-boards","text":"Currently we have implemented simple_flight interfaces for simulated board. We plan to implement it for Pixhawk V2 board and possibly Naze32 board. We expect all our code to remain unchanged and the implementation would mainly involve adding drivers for various sensors, handling ISRs and managing other board specific details. If you have experience this area than we encourage you to engage with us and contribute!","title":"Supported Boards"},{"location":"docs/simple_flight/#configuration","text":"To have AirSim use simple_flight, you can specify it in settings.json as shown below. Note that this is default so you don't have to do it explicitly. \"Vehicles\": { \"SimpleFlight\": { \"VehicleType\": \"SimpleFlight\", } } By default, vehicle using simple_flight is already armed which is why you would see propellers spinning. However if you don't want that than set DefaultVehicleState to Inactive like this: \"Vehicles\": { \"SimpleFlight\": { \"VehicleType\": \"SimpleFlight\", \"DefaultVehicleState\": \"Inactive\" } } In this case, you will need to either manually arm using RC sticks in down inward position or using APIs. For safety reasons, flight controllers would disallow API control unless human operator has consented using a switch on RC. Also, when RC control is lost, vehicle should disable API control and enter hover mode for safety reasons. To simplify things a bit, simple_flight enables API control without human consent using RC and even when RC is not detected by default however you can change this using following setting: \"Vehicles\": { \"SimpleFlight\": { \"VehicleType\": \"SimpleFlight\", \"AllowAPIAlways\": true, \"RC\": { \"RemoteControlID\": 0, \"AllowAPIWhenDisconnected\": true } } } Finally, simple_flight uses steppable clock by default which means clock advances when simulator tells it to advance (unlike wall clock which advances strictly according to passage of time). This means clock can be paused, for example, if code hits the break point and there is zero variance in clock (clock APIs provides by operating system might have significant variance unless its \"real time\" OS). If you want simple_flight to use wall clock instead than use following settings: \"ClockType\": \"ScalableClock\"","title":"Configuration"},{"location":"docs/steering_wheel_installation/","text":"Logitech G920 Steering Wheel Installation To use Logitech G920 steering wheel with AirSim follow these steps: Connect the steering wheel to the computer and wait until drivers installation complete. Install Logitech Gaming Software from here Before debug, you\u2019ll have to normalize the values in AirSim code. Perform this changes in CarPawn.cpp (according to the current update in the git): In line 382, change \u201cVal\u201d to \u201c1 \u2013 Val\u201d. (the complementary value in the range [0.0,1.0]). In line 388, change \u201cVal\u201d to \u201c5Val - 2.5\u201d (Change the range of the given input from [0.0,1.0] to [-1.0,1.0]). In line 404, change \u201cVal\u201d to \u201c4(1 \u2013 Val)\u201d. (the complementary value in the range [0.0,1.0]). Debug AirSim project (while the steering wheel is connected \u2013 it\u2019s important). On Unreal Editor, go to Edit->plugins->input devices and enable \u201cWindows RawInput\u201d. Go to Edit->Project Settings->Raw Input, and add new device configuration: Vendor ID: 0x046d (In case of Logitech G920, otherwise you might need to check it). Product ID: 0xc261 (In case of Logitech G920, otherwise you might need to check it). Under \u201cAxis Properties\u201d, make sure that \u201cGenericUSBController Axis 2\u201d, \u201cGenericUSBController Axis 4\u201d and \u201cGenericUSBController Axis 5\u201d are all enabled with an offset of 1.0. Explanation: axis 2 is responsible for steering movement, axis 4 is for brake and axis 5 is for gas. If you need to configure the clutch, it\u2019s on axis 3. Go to Edit->Project Settings->Input, Under Bindings in \u201cAxis Mappings\u201d: Remove existing mappings from the groups \u201cMoveRight\u201d and \u201cMoveForward\u201d. Add new axis mapping to the group \u201cMoveRight\u201d, use GenericUSBController axis 2 with a scale of 1.0. Add new axis mapping to the group \u201cMoveForward\u201d, use GenericUSBController axis 5 with a scale of 1.0. Add a new group of axis mappings, name it \u201cFootBrake\u201d and add new axis mapping to this group, use GenericUSBController axis 4 with a scale of 1.0. Play and drive ! Pay Attention Notice that in the first time we \"play\" after debug, we need to touch the wheel to \u201creset\u201d the values. Tip In the gaming software, you can configure buttons as keyboard shortcuts, we used it to configure a shortcut to record dataset or to play in full screen.","title":"Steering Wheel"},{"location":"docs/steering_wheel_installation/#logitech-g920-steering-wheel-installation","text":"To use Logitech G920 steering wheel with AirSim follow these steps: Connect the steering wheel to the computer and wait until drivers installation complete. Install Logitech Gaming Software from here Before debug, you\u2019ll have to normalize the values in AirSim code. Perform this changes in CarPawn.cpp (according to the current update in the git): In line 382, change \u201cVal\u201d to \u201c1 \u2013 Val\u201d. (the complementary value in the range [0.0,1.0]). In line 388, change \u201cVal\u201d to \u201c5Val - 2.5\u201d (Change the range of the given input from [0.0,1.0] to [-1.0,1.0]). In line 404, change \u201cVal\u201d to \u201c4(1 \u2013 Val)\u201d. (the complementary value in the range [0.0,1.0]). Debug AirSim project (while the steering wheel is connected \u2013 it\u2019s important). On Unreal Editor, go to Edit->plugins->input devices and enable \u201cWindows RawInput\u201d. Go to Edit->Project Settings->Raw Input, and add new device configuration: Vendor ID: 0x046d (In case of Logitech G920, otherwise you might need to check it). Product ID: 0xc261 (In case of Logitech G920, otherwise you might need to check it). Under \u201cAxis Properties\u201d, make sure that \u201cGenericUSBController Axis 2\u201d, \u201cGenericUSBController Axis 4\u201d and \u201cGenericUSBController Axis 5\u201d are all enabled with an offset of 1.0. Explanation: axis 2 is responsible for steering movement, axis 4 is for brake and axis 5 is for gas. If you need to configure the clutch, it\u2019s on axis 3. Go to Edit->Project Settings->Input, Under Bindings in \u201cAxis Mappings\u201d: Remove existing mappings from the groups \u201cMoveRight\u201d and \u201cMoveForward\u201d. Add new axis mapping to the group \u201cMoveRight\u201d, use GenericUSBController axis 2 with a scale of 1.0. Add new axis mapping to the group \u201cMoveForward\u201d, use GenericUSBController axis 5 with a scale of 1.0. Add a new group of axis mappings, name it \u201cFootBrake\u201d and add new axis mapping to this group, use GenericUSBController axis 4 with a scale of 1.0. Play and drive !","title":"Logitech G920 Steering Wheel Installation"},{"location":"docs/steering_wheel_installation/#pay-attention","text":"Notice that in the first time we \"play\" after debug, we need to touch the wheel to \u201creset\u201d the values.","title":"Pay Attention"},{"location":"docs/steering_wheel_installation/#tip","text":"In the gaming software, you can configure buttons as keyboard shortcuts, we used it to configure a shortcut to record dataset or to play in full screen.","title":"Tip"},{"location":"docs/unreal_blocks/","text":"Setup Blocks Environment for AirSim Blocks environment is available in repo in folder Unreal/Environments/Blocks and is designed to be lightweight in size. That means its very basic but fast. Here are quick steps to get Blocks environment up and running: Windows Make sure you have installed Unreal and built AirSim . Navigate to folder AirSim\\Unreal\\Environments\\Blocks and run update_from_git.bat . Double click on generated .sln file to open in Visual Studio 2017 or newer. Make sure Blocks project is the startup project, build configuration is set to DebugGame_Editor and Win64 . Hit F5 to run. Press the Play button in Unreal Editor and you will see something like in below video. Also see how to use AirSim . Changing Code and Rebuilding For Windows, you can just change the code in Visual Studio, press F5 and re-run. There are few batch files available in folder AirSim\\Unreal\\Environments\\Blocks that lets you sync code, clean etc. Linux Make sure you have built the Unreal Engine and AirSim . Navigate to your UnrealEngine repo folder and run Engine/Binaries/Linux/UE4Editor which will start Unreal Editor. On first start you might not see any projects in UE4 editor. Click on Projects tab, Browse button and then navigate to AirSim/Unreal/Environments/Blocks/Blocks.uproject . If you get prompted for incompatible version and conversion, select In-place conversion which is usually under \"More\" options. If you get prompted for missing modules, make sure to select No so you don't exit. Finally, when prompted with building AirSim, select Yes. Now it might take a while so go get some coffee :). Press the Play button in Unreal Editor and you will see something like in below video. Also see how to use AirSim . Changing Code and Rebuilding For Linux, make code changes in AirLib or Unreal/Plugins folder and then run ./build.sh to rebuild. This step also copies the build output to Blocks sample project. You can then follow above steps again to re-run. Chosing Your Vehicle: Car or Multirotor By default AirSim spawns multirotor. You can easily change this to car and use all of AirSim goodies. Please see using car guide. FAQ I see warnings about like \"_BuitData\" file is missing. These are intermediate files and you can safely ignore it.","title":"Blocks Environment"},{"location":"docs/unreal_blocks/#setup-blocks-environment-for-airsim","text":"Blocks environment is available in repo in folder Unreal/Environments/Blocks and is designed to be lightweight in size. That means its very basic but fast. Here are quick steps to get Blocks environment up and running:","title":"Setup Blocks Environment for AirSim"},{"location":"docs/unreal_blocks/#windows","text":"Make sure you have installed Unreal and built AirSim . Navigate to folder AirSim\\Unreal\\Environments\\Blocks and run update_from_git.bat . Double click on generated .sln file to open in Visual Studio 2017 or newer. Make sure Blocks project is the startup project, build configuration is set to DebugGame_Editor and Win64 . Hit F5 to run. Press the Play button in Unreal Editor and you will see something like in below video. Also see how to use AirSim .","title":"Windows"},{"location":"docs/unreal_blocks/#changing-code-and-rebuilding","text":"For Windows, you can just change the code in Visual Studio, press F5 and re-run. There are few batch files available in folder AirSim\\Unreal\\Environments\\Blocks that lets you sync code, clean etc.","title":"Changing Code and Rebuilding"},{"location":"docs/unreal_blocks/#linux","text":"Make sure you have built the Unreal Engine and AirSim . Navigate to your UnrealEngine repo folder and run Engine/Binaries/Linux/UE4Editor which will start Unreal Editor. On first start you might not see any projects in UE4 editor. Click on Projects tab, Browse button and then navigate to AirSim/Unreal/Environments/Blocks/Blocks.uproject . If you get prompted for incompatible version and conversion, select In-place conversion which is usually under \"More\" options. If you get prompted for missing modules, make sure to select No so you don't exit. Finally, when prompted with building AirSim, select Yes. Now it might take a while so go get some coffee :). Press the Play button in Unreal Editor and you will see something like in below video. Also see how to use AirSim .","title":"Linux"},{"location":"docs/unreal_blocks/#changing-code-and-rebuilding_1","text":"For Linux, make code changes in AirLib or Unreal/Plugins folder and then run ./build.sh to rebuild. This step also copies the build output to Blocks sample project. You can then follow above steps again to re-run.","title":"Changing Code and Rebuilding"},{"location":"docs/unreal_blocks/#chosing-your-vehicle-car-or-multirotor","text":"By default AirSim spawns multirotor. You can easily change this to car and use all of AirSim goodies. Please see using car guide.","title":"Chosing Your Vehicle: Car or Multirotor"},{"location":"docs/unreal_blocks/#faq","text":"","title":"FAQ"},{"location":"docs/unreal_blocks/#i-see-warnings-about-like-_buitdata-file-is-missing","text":"These are intermediate files and you can safely ignore it.","title":"I see warnings about like \"_BuitData\" file is missing."},{"location":"docs/unreal_custenv/","text":"Creating and Setting Up Unreal Environment This page contains the complete instructions start to finish for setting up Unreal environment with AirSim. The Unreal Marketplace has several environment available that you can start using in just few minutes. It is also possible to use environments available on websites such as turbosquid.com or cgitrader.com with bit more effort (here's tutorial video ). In addition there also several free environments available. Below we will use a freely downloadable environment from Unreal Marketplace called Landscape Mountain but the steps are same for any other environments. You can also view these steps performed in Unreal AirSim Setup Video . Note for Linux Users There is no Epic Games Launcher for Linux which means that if you need to create custom environment, you will need Windows machine to do that. Once you have Unreal project folder, just copy it over to your Linux machine. Step by Step Instructions Make sure AirSim is built and Unreal 4.18 is installed as described in build instructions . In Epic Games Launcher click the Learn tab then scroll down and find Landscape Mountains . Click the Create Project and download this content (~2GB download). Open LandscapeMountains.uproject , it should launch the Unreal Editor. From the File menu select New C++ class , leave default None on the type of class, click Next , leave default name MyClass , and click Create Class . We need to do this because Unreal requires at least one source file in project. It should trigger compile and open up Visual Studio solution LandscapeMountains.sln . Go to your folder for AirSim repo and copy Unreal\\Plugins folder in to your LandscapeMountains folder. This way now your own Unreal project has AirSim plugin. Edit the LandscapeMountains.uproject so that it looks like this { \"FileVersion\": 3, \"EngineAssociation\": \"4.18\", \"Category\": \"Samples\", \"Description\": \"\", \"Modules\": [ { \"Name\": \"LandscapeMountains\", \"Type\": \"Runtime\", \"LoadingPhase\": \"Default\", \"AdditionalDependencies\": [ \"AirSim\" ] } ], \"TargetPlatforms\": [ \"MacNoEditor\", \"WindowsNoEditor\" ], \"Plugins\": [ { \"Name\": \"AirSim\", \"Enabled\": true } ] } Close Visual Studio and the Unreal Editor and right click the LandscapeMountains.uproject in Windows Explorer and select Generate Visual Studio Project Files . This step detects all plugins and source files in your Unreal project and generates .sln file for Visual Studio. Tip: If the Generate Visual Studio Project Files option is missing you may need to reboot your machine for the Unreal Shell extensions to take effect. If it is still missing then open the LandscapeMountains.uproject in the Unreal Editor and select Refresh Visual Studio Project from the File menu. Reopen LandscapeMountains.sln in Visual Studio, and make sure \"DebugGame Editor\" and \"Win64\" build configuration is the active build configuration. Press F5 to run . This will start the Unreal Editor. The Unreal Editor allows you to edit the environment, assets and other game related settings. First thing you want to do in your environment is set up PlayerStart object. In Landscape Mountains environment, PlayerStart object already exist and you can find it in the World Outliner . Make sure its location is setup as shown. This is where AirSim plugin will create and place the vehicle. If its too high up then vehicle will fall down as soon as you press play giving potentially random behavior In Window/World Settings as shown below, set the GameMode Override to AirSimGameMode : Go to 'Edit->Editor Preferences' in Unreal Editor, in the 'Search' box type 'CPU' and ensure that the 'Use Less CPU when in Background' is unchecked. If you don't do this then UE will be slowed down dramatically when UE window loses focus. Be sure to Save these edits. Hit the Play button in the Unreal Editor. See how to use AirSim . Congratulations! You are now running AirSim in your own Unreal environment. Choosing Your Vehicle: Car or Multirotor By default AirSim prompts user for which vehicle to use. You can easily change this by setting SimMode . Please see using car guide. Updating Your Environment to Latest Version of AirSim Once you have your environment using above instructions, you should frequently update your local AirSim code to latest version from GitHub. Below are the instructions to do this: First put clean.bat (or clean.sh for Linux users) in the root folder of your environment. Run this file to clean up all intermediate files in your Unreal project. Do git pull in your AirSim repo followed by build.cmd (or ./build.sh for Linux users). Replace [your project]/Plugins folder with AirSim/Unreal/Plugins folder. Right click on your .uproject file and chose \"Generate Visual Studio project files\" option. This is not required for Linux. FAQ What are other cool environments? Unreal Marketplace has dozens of prebuilt extra-ordinarily detailed environments ranging from Moon to Mars and everything in between. The one we have used for testing is called Modular Neighborhood Pack but you can use any environment. Another free environment is Infinity Blade series . Alternatively, if you look under the Learn tab in Epic Game Launcher, you will find many free samples that you can use. One of our favorites is \"A Boy and His Kite\" which is a 100 square miles of highly detailed environment (caution: you will need very beefy PC to run it!). When I press Play button some kind of video starts instead of my vehicle. If the environment comes with MatineeActor, delete it to avoid any startup demo sequences. There might be other ways to remove it as well, for example, click on Blueprints button, then Level Blueprint and then look at Begin Play event in Event Graph. You might want to disconnect any connections that may be starting \"matinee\". Is there easy way to sync code in my Unreal project with code in AirSim repo? Sure, there is! You can find bunch of .bat files (for linux, .sh ) in AirSim\\Unreal\\Environments\\Blocks . Just copy them over to your own Unreal project. Most of these are quite simple and self explanatory. I get some error about map. You might have to set default map for your project. For example, if you are using Modular Neighborhood Pack, set the Editor Starter Map as well as Game Default Map to Demo_Map in Project Settings > Maps & Modes. I see \"Add to project\" option for environment but not \"Create project\" option. In this case, create a new blank C++ project with no Starter Content and add your environment in to it. I already have my own Unreal project. How do I use AirSim with it? Copy the Unreal\\Plugins folder from the build you did in the above section into the root of your Unreal project's folder. In your Unreal project's .uproject file, add the key AdditionalDependencies to the \"Modules\" object as we showed in the LandscapeMountains.uproject above. \"AdditionalDependencies\": [ \"AirSim\" ] and the Plugins section to the top level object: \"Plugins\": [ { \"Name\": \"AirSim\", \"Enabled\": true } ]","title":"Creating Custom Environment"},{"location":"docs/unreal_custenv/#creating-and-setting-up-unreal-environment","text":"This page contains the complete instructions start to finish for setting up Unreal environment with AirSim. The Unreal Marketplace has several environment available that you can start using in just few minutes. It is also possible to use environments available on websites such as turbosquid.com or cgitrader.com with bit more effort (here's tutorial video ). In addition there also several free environments available. Below we will use a freely downloadable environment from Unreal Marketplace called Landscape Mountain but the steps are same for any other environments. You can also view these steps performed in Unreal AirSim Setup Video .","title":"Creating and Setting Up Unreal Environment"},{"location":"docs/unreal_custenv/#note-for-linux-users","text":"There is no Epic Games Launcher for Linux which means that if you need to create custom environment, you will need Windows machine to do that. Once you have Unreal project folder, just copy it over to your Linux machine.","title":"Note for Linux Users"},{"location":"docs/unreal_custenv/#step-by-step-instructions","text":"Make sure AirSim is built and Unreal 4.18 is installed as described in build instructions . In Epic Games Launcher click the Learn tab then scroll down and find Landscape Mountains . Click the Create Project and download this content (~2GB download). Open LandscapeMountains.uproject , it should launch the Unreal Editor. From the File menu select New C++ class , leave default None on the type of class, click Next , leave default name MyClass , and click Create Class . We need to do this because Unreal requires at least one source file in project. It should trigger compile and open up Visual Studio solution LandscapeMountains.sln . Go to your folder for AirSim repo and copy Unreal\\Plugins folder in to your LandscapeMountains folder. This way now your own Unreal project has AirSim plugin. Edit the LandscapeMountains.uproject so that it looks like this { \"FileVersion\": 3, \"EngineAssociation\": \"4.18\", \"Category\": \"Samples\", \"Description\": \"\", \"Modules\": [ { \"Name\": \"LandscapeMountains\", \"Type\": \"Runtime\", \"LoadingPhase\": \"Default\", \"AdditionalDependencies\": [ \"AirSim\" ] } ], \"TargetPlatforms\": [ \"MacNoEditor\", \"WindowsNoEditor\" ], \"Plugins\": [ { \"Name\": \"AirSim\", \"Enabled\": true } ] } Close Visual Studio and the Unreal Editor and right click the LandscapeMountains.uproject in Windows Explorer and select Generate Visual Studio Project Files . This step detects all plugins and source files in your Unreal project and generates .sln file for Visual Studio. Tip: If the Generate Visual Studio Project Files option is missing you may need to reboot your machine for the Unreal Shell extensions to take effect. If it is still missing then open the LandscapeMountains.uproject in the Unreal Editor and select Refresh Visual Studio Project from the File menu. Reopen LandscapeMountains.sln in Visual Studio, and make sure \"DebugGame Editor\" and \"Win64\" build configuration is the active build configuration. Press F5 to run . This will start the Unreal Editor. The Unreal Editor allows you to edit the environment, assets and other game related settings. First thing you want to do in your environment is set up PlayerStart object. In Landscape Mountains environment, PlayerStart object already exist and you can find it in the World Outliner . Make sure its location is setup as shown. This is where AirSim plugin will create and place the vehicle. If its too high up then vehicle will fall down as soon as you press play giving potentially random behavior In Window/World Settings as shown below, set the GameMode Override to AirSimGameMode : Go to 'Edit->Editor Preferences' in Unreal Editor, in the 'Search' box type 'CPU' and ensure that the 'Use Less CPU when in Background' is unchecked. If you don't do this then UE will be slowed down dramatically when UE window loses focus. Be sure to Save these edits. Hit the Play button in the Unreal Editor. See how to use AirSim . Congratulations! You are now running AirSim in your own Unreal environment.","title":"Step by Step Instructions"},{"location":"docs/unreal_custenv/#choosing-your-vehicle-car-or-multirotor","text":"By default AirSim prompts user for which vehicle to use. You can easily change this by setting SimMode . Please see using car guide.","title":"Choosing Your Vehicle: Car or Multirotor"},{"location":"docs/unreal_custenv/#updating-your-environment-to-latest-version-of-airsim","text":"Once you have your environment using above instructions, you should frequently update your local AirSim code to latest version from GitHub. Below are the instructions to do this: First put clean.bat (or clean.sh for Linux users) in the root folder of your environment. Run this file to clean up all intermediate files in your Unreal project. Do git pull in your AirSim repo followed by build.cmd (or ./build.sh for Linux users). Replace [your project]/Plugins folder with AirSim/Unreal/Plugins folder. Right click on your .uproject file and chose \"Generate Visual Studio project files\" option. This is not required for Linux.","title":"Updating Your Environment to Latest Version of AirSim"},{"location":"docs/unreal_custenv/#faq","text":"","title":"FAQ"},{"location":"docs/unreal_custenv/#what-are-other-cool-environments","text":"Unreal Marketplace has dozens of prebuilt extra-ordinarily detailed environments ranging from Moon to Mars and everything in between. The one we have used for testing is called Modular Neighborhood Pack but you can use any environment. Another free environment is Infinity Blade series . Alternatively, if you look under the Learn tab in Epic Game Launcher, you will find many free samples that you can use. One of our favorites is \"A Boy and His Kite\" which is a 100 square miles of highly detailed environment (caution: you will need very beefy PC to run it!).","title":"What are other cool environments?"},{"location":"docs/unreal_custenv/#when-i-press-play-button-some-kind-of-video-starts-instead-of-my-vehicle","text":"If the environment comes with MatineeActor, delete it to avoid any startup demo sequences. There might be other ways to remove it as well, for example, click on Blueprints button, then Level Blueprint and then look at Begin Play event in Event Graph. You might want to disconnect any connections that may be starting \"matinee\".","title":"When I press Play button some kind of video starts instead of my vehicle."},{"location":"docs/unreal_custenv/#is-there-easy-way-to-sync-code-in-my-unreal-project-with-code-in-airsim-repo","text":"Sure, there is! You can find bunch of .bat files (for linux, .sh ) in AirSim\\Unreal\\Environments\\Blocks . Just copy them over to your own Unreal project. Most of these are quite simple and self explanatory.","title":"Is there easy way to sync code in my Unreal project with code in AirSim repo?"},{"location":"docs/unreal_custenv/#i-get-some-error-about-map","text":"You might have to set default map for your project. For example, if you are using Modular Neighborhood Pack, set the Editor Starter Map as well as Game Default Map to Demo_Map in Project Settings > Maps & Modes.","title":"I get some error about map."},{"location":"docs/unreal_custenv/#i-see-add-to-project-option-for-environment-but-not-create-project-option","text":"In this case, create a new blank C++ project with no Starter Content and add your environment in to it.","title":"I see \"Add to project\" option for environment but not \"Create project\" option."},{"location":"docs/unreal_custenv/#i-already-have-my-own-unreal-project-how-do-i-use-airsim-with-it","text":"Copy the Unreal\\Plugins folder from the build you did in the above section into the root of your Unreal project's folder. In your Unreal project's .uproject file, add the key AdditionalDependencies to the \"Modules\" object as we showed in the LandscapeMountains.uproject above. \"AdditionalDependencies\": [ \"AirSim\" ] and the Plugins section to the top level object: \"Plugins\": [ { \"Name\": \"AirSim\", \"Enabled\": true } ]","title":"I already have my own Unreal project. How do I use AirSim with it?"},{"location":"docs/unreal_proj/","text":"Unreal Environment Setting Up the Unreal Project Option 1: Built-in Blocks Environment To get up and running fast, you can use the Blocks project that already comes with AirSim. This is not very highly detailed environment to keep the repo size reasonable but we use it for various testing all the times and it is the easiest way to get your feet wet in this strange land. Follow these quick steps . Option 2: Create Your Own Unreal Environment If you want to setup photo-realistic high quality environments, then you will need to create your own Unreal project. This is little bit more involved but worthwhile! Follow this step-by-step guide . Changing Code and Development Workflow To see how you can change and test AirSim code, please read our recommended development workflow .","title":"Setting up Unreal Environment"},{"location":"docs/unreal_proj/#unreal-environment","text":"","title":"Unreal Environment"},{"location":"docs/unreal_proj/#setting-up-the-unreal-project","text":"","title":"Setting Up the Unreal Project"},{"location":"docs/unreal_proj/#option-1-built-in-blocks-environment","text":"To get up and running fast, you can use the Blocks project that already comes with AirSim. This is not very highly detailed environment to keep the repo size reasonable but we use it for various testing all the times and it is the easiest way to get your feet wet in this strange land. Follow these quick steps .","title":"Option 1: Built-in Blocks Environment"},{"location":"docs/unreal_proj/#option-2-create-your-own-unreal-environment","text":"If you want to setup photo-realistic high quality environments, then you will need to create your own Unreal project. This is little bit more involved but worthwhile! Follow this step-by-step guide .","title":"Option 2: Create Your Own Unreal Environment"},{"location":"docs/unreal_proj/#changing-code-and-development-workflow","text":"To see how you can change and test AirSim code, please read our recommended development workflow .","title":"Changing Code and Development Workflow"},{"location":"docs/unreal_upgrade/","text":"Upgrading to Unreal Engine 4.18 These instructions apply if you are already using AirSim on Unreal Engine 4.16. If you have never installed AirSim, please see How to get it . Caution: The below steps will delete any of your unsaved work in AirSim or Unreal folder. Do this first For Windows Users Install Visual Studio 2017 with VC++, Python and C#. Install UE 4.18 through Epic Games Launcher. Start x64 Native Tools Command Prompt for VS 2017 and navigate to AirSim repo. Run clean_rebuild.bat to remove all unchecked/extra stuff and rebuild everything. For Linux Users From your AirSim repo folder, run 'clean_rebuild.sh`. Rename or delete your existing folder for Unreal Engine. Follow step 1 and 2 to install Unreal Engine 4.18 . Upgrading Your Custom Unreal Project If you have your own Unreal project created in an older version of Unreal Engine then you need to upgrade your project to Unreal 4.18. To do this, Open .uproject file and look for the line \"EngineAssociation\" and make sure it reads like \"EngineAssociation\": \"4.18\" . Delete Plugins/AirSim folder in your Unreal project's folder. Go to your AirSim repo folder and copy Unreal\\Plugins folder to your Unreal project's folder. Copy .bat (or .sh for Linux) from Unreal\\Environments\\Blocks to your project's folder. Run clean.bat (or clean.sh for Linux) followed by GenerateProjectFiles.bat (only for Windows). FAQ I have an Unreal project that is older than 4.16. How do I upgrade it? Option 1: Just Recreate Project If your project doesn't have any code or assets other than environment you downloaded then you can also simply recreate the project in Unreal 4.18 Editor and then copy Plugins folder from AirSim/Unreal/Plugins . Option 2: Modify Few Files Unreal versions newer than Unreal 4.15 has breaking changes. So you need to modify your .Build.cs and .Target.cs which you can find in the Source folder of your Unreal project. So what are those changes? Below is the gist of it but you should really refer to Unreal's official 4.16 transition post . In your project's *.Target.cs Change the contructor from, public MyProjectTarget(TargetInfo Target) to public MyProjectTarget(TargetInfo Target) : base(Target) Remove SetupBinaries method if you have one and instead add following line in contructor above: ExtraModuleNames.AddRange(new string[] { \"MyProject\" }); In your project's *.Build.cs Change the constructor from public MyProject(TargetInfo Target) to public MyProject(ReadOnlyTargetRules Target) : base(Target) . And finally... Follow above steps to continue the upgrade. The warning box might show only \"Open Copy\" button. Don't click that. Instead, click on More Options which will reveal more buttons. Choose Convert-In-Place option . Caution: Always keep backup of your project first! If you don't have anything nasty, in place conversion should go through and you are now on the new version of Unreal.","title":"Upgrading Unreal"},{"location":"docs/unreal_upgrade/#upgrading-to-unreal-engine-418","text":"These instructions apply if you are already using AirSim on Unreal Engine 4.16. If you have never installed AirSim, please see How to get it . Caution: The below steps will delete any of your unsaved work in AirSim or Unreal folder.","title":"Upgrading to Unreal Engine 4.18"},{"location":"docs/unreal_upgrade/#do-this-first","text":"","title":"Do this first"},{"location":"docs/unreal_upgrade/#for-windows-users","text":"Install Visual Studio 2017 with VC++, Python and C#. Install UE 4.18 through Epic Games Launcher. Start x64 Native Tools Command Prompt for VS 2017 and navigate to AirSim repo. Run clean_rebuild.bat to remove all unchecked/extra stuff and rebuild everything.","title":"For Windows Users"},{"location":"docs/unreal_upgrade/#for-linux-users","text":"From your AirSim repo folder, run 'clean_rebuild.sh`. Rename or delete your existing folder for Unreal Engine. Follow step 1 and 2 to install Unreal Engine 4.18 .","title":"For Linux Users"},{"location":"docs/unreal_upgrade/#upgrading-your-custom-unreal-project","text":"If you have your own Unreal project created in an older version of Unreal Engine then you need to upgrade your project to Unreal 4.18. To do this, Open .uproject file and look for the line \"EngineAssociation\" and make sure it reads like \"EngineAssociation\": \"4.18\" . Delete Plugins/AirSim folder in your Unreal project's folder. Go to your AirSim repo folder and copy Unreal\\Plugins folder to your Unreal project's folder. Copy .bat (or .sh for Linux) from Unreal\\Environments\\Blocks to your project's folder. Run clean.bat (or clean.sh for Linux) followed by GenerateProjectFiles.bat (only for Windows).","title":"Upgrading Your Custom Unreal Project"},{"location":"docs/unreal_upgrade/#faq","text":"","title":"FAQ"},{"location":"docs/unreal_upgrade/#i-have-an-unreal-project-that-is-older-than-416-how-do-i-upgrade-it","text":"","title":"I have an Unreal project that is older than 4.16. How do I upgrade it?"},{"location":"docs/unreal_upgrade/#option-1-just-recreate-project","text":"If your project doesn't have any code or assets other than environment you downloaded then you can also simply recreate the project in Unreal 4.18 Editor and then copy Plugins folder from AirSim/Unreal/Plugins .","title":"Option 1: Just Recreate Project"},{"location":"docs/unreal_upgrade/#option-2-modify-few-files","text":"Unreal versions newer than Unreal 4.15 has breaking changes. So you need to modify your .Build.cs and .Target.cs which you can find in the Source folder of your Unreal project. So what are those changes? Below is the gist of it but you should really refer to Unreal's official 4.16 transition post .","title":"Option 2: Modify Few Files"},{"location":"docs/unreal_upgrade/#in-your-projects-targetcs","text":"Change the contructor from, public MyProjectTarget(TargetInfo Target) to public MyProjectTarget(TargetInfo Target) : base(Target) Remove SetupBinaries method if you have one and instead add following line in contructor above: ExtraModuleNames.AddRange(new string[] { \"MyProject\" });","title":"In your project's *.Target.cs"},{"location":"docs/unreal_upgrade/#in-your-projects-buildcs","text":"Change the constructor from public MyProject(TargetInfo Target) to public MyProject(ReadOnlyTargetRules Target) : base(Target) .","title":"In your project's *.Build.cs"},{"location":"docs/unreal_upgrade/#and-finally","text":"Follow above steps to continue the upgrade. The warning box might show only \"Open Copy\" button. Don't click that. Instead, click on More Options which will reveal more buttons. Choose Convert-In-Place option . Caution: Always keep backup of your project first! If you don't have anything nasty, in place conversion should go through and you are now on the new version of Unreal.","title":"And finally..."},{"location":"docs/upgrade_apis/","text":"Upgrading API Client Code There have been several API changes in AirSim v1.2 that we hope removes inconsistency, adds future extensibility and presents cleaner interface. Many of these changes are however breaking changes which means you will need to modify your client code that talks to AirSim. Quicker Way While most changes you need to do in your client code are fairly easy, a quicker way is simply to take a look at the example code such as Hello Drone or Hello Car to get gist of changes. Importing AirSim Instead of, from AirSimClient import * use this: import airsim Above assumes you have installed AirSim module using, pip install --user airsim If you are running you code from PythonClient folder in repo then you can also do this: import setup_path import airsim Here setup_path.py should exist in your folder and it will set the path of airsim package in PythonClient repo folder. All examples in PythonClient folder uses this method. Using AirSim Classes As we have everything now in package, you will need to use explicit namespace for AirSim classes like shown below. Instead of, client1 = CarClient() use this: client1 = airsim.CarClient() AirSim Types We have moved all types in airsim namespace. Instead of, image_type = AirSimImageType.DepthVis d = DrivetrainType.MaxDegreeOfFreedom use this: image_type = airsim.ImageType.DepthVis d = airsim.DrivetrainType.MaxDegreeOfFreedom Getting Images Nothing new below, it's just combination of above. Note that all APIs that previously took camera_id , now takes camera_name instead. You can take a look at available cameras here. Instead of, responses = client.simGetImages([ImageRequest(0, AirSimImageType.DepthVis)]) use this: responses = client.simGetImages([airsim.ImageRequest(\"0\", airsim.ImageType.DepthVis)]) Utility Methods In earlier version, we provided several utility methods as part of AirSimClientBase . These methods are now moved to airsim namespace for more pythonic interface. Instead of, AirSimClientBase.write_png(my_path, img_rgba) AirSimClientBase.wait_key('Press any key') use this: airsim.write_png(my_path, img_rgba) airsim.wait_key('Press any key') Camera Names AirSim now uses names to reference cameras instead of index numbers. However to retain backward compatibility, these names are aliased with old index numbers as string. Instead of, client.simGetCameraInfo(0) use this: client.simGetCameraInfo(\"0\") # or client.simGetCameraInfo(\"front-center\") Async Methods For multirotors, AirSim had various methods such as takeoff or moveByVelocityZ that would take long time to complete. All of such methods are now renamed by adding the suffix Async as shown below. Instead of, client.takeoff() client.moveToPosition(-10, 10, -10, 5) use this: client.takeoffAsync().join() client.moveToPositionAsync(-10, 10, -10, 5).join() Here .join() is a call on Python's Future class to wait for the async call to complete. You can also choose to do some other computation instead while the call is in progress. Simulation-Only Methods Now we have clear distinction between methods that are only available in simulation from the ones that may be available on actual vehicle. The simulation only methods are prefixed with sim as shown below. getCollisionInfo() is renamed to simGetCollisionInfo() getCameraInfo() is renamed to simGetCameraInfo() setCameraOrientation() is renamed to simSetCameraOrientation() State Information Previously CarState mixed simulation-only information like kinematics_true . Moving forward, CarState will only contain information that can be obtained in real world. k = car_state.kinematics_true use this: k = car_state.kinematics_estimated # or k = client.simGetGroundTruthKinematics()","title":"Upgrading APIs"},{"location":"docs/upgrade_apis/#upgrading-api-client-code","text":"There have been several API changes in AirSim v1.2 that we hope removes inconsistency, adds future extensibility and presents cleaner interface. Many of these changes are however breaking changes which means you will need to modify your client code that talks to AirSim.","title":"Upgrading API Client Code"},{"location":"docs/upgrade_apis/#quicker-way","text":"While most changes you need to do in your client code are fairly easy, a quicker way is simply to take a look at the example code such as Hello Drone or Hello Car to get gist of changes.","title":"Quicker Way"},{"location":"docs/upgrade_apis/#importing-airsim","text":"Instead of, from AirSimClient import * use this: import airsim Above assumes you have installed AirSim module using, pip install --user airsim If you are running you code from PythonClient folder in repo then you can also do this: import setup_path import airsim Here setup_path.py should exist in your folder and it will set the path of airsim package in PythonClient repo folder. All examples in PythonClient folder uses this method.","title":"Importing AirSim"},{"location":"docs/upgrade_apis/#using-airsim-classes","text":"As we have everything now in package, you will need to use explicit namespace for AirSim classes like shown below. Instead of, client1 = CarClient() use this: client1 = airsim.CarClient()","title":"Using AirSim Classes"},{"location":"docs/upgrade_apis/#airsim-types","text":"We have moved all types in airsim namespace. Instead of, image_type = AirSimImageType.DepthVis d = DrivetrainType.MaxDegreeOfFreedom use this: image_type = airsim.ImageType.DepthVis d = airsim.DrivetrainType.MaxDegreeOfFreedom","title":"AirSim Types"},{"location":"docs/upgrade_apis/#getting-images","text":"Nothing new below, it's just combination of above. Note that all APIs that previously took camera_id , now takes camera_name instead. You can take a look at available cameras here. Instead of, responses = client.simGetImages([ImageRequest(0, AirSimImageType.DepthVis)]) use this: responses = client.simGetImages([airsim.ImageRequest(\"0\", airsim.ImageType.DepthVis)])","title":"Getting Images"},{"location":"docs/upgrade_apis/#utility-methods","text":"In earlier version, we provided several utility methods as part of AirSimClientBase . These methods are now moved to airsim namespace for more pythonic interface. Instead of, AirSimClientBase.write_png(my_path, img_rgba) AirSimClientBase.wait_key('Press any key') use this: airsim.write_png(my_path, img_rgba) airsim.wait_key('Press any key')","title":"Utility Methods"},{"location":"docs/upgrade_apis/#camera-names","text":"AirSim now uses names to reference cameras instead of index numbers. However to retain backward compatibility, these names are aliased with old index numbers as string. Instead of, client.simGetCameraInfo(0) use this: client.simGetCameraInfo(\"0\") # or client.simGetCameraInfo(\"front-center\")","title":"Camera Names"},{"location":"docs/upgrade_apis/#async-methods","text":"For multirotors, AirSim had various methods such as takeoff or moveByVelocityZ that would take long time to complete. All of such methods are now renamed by adding the suffix Async as shown below. Instead of, client.takeoff() client.moveToPosition(-10, 10, -10, 5) use this: client.takeoffAsync().join() client.moveToPositionAsync(-10, 10, -10, 5).join() Here .join() is a call on Python's Future class to wait for the async call to complete. You can also choose to do some other computation instead while the call is in progress.","title":"Async Methods"},{"location":"docs/upgrade_apis/#simulation-only-methods","text":"Now we have clear distinction between methods that are only available in simulation from the ones that may be available on actual vehicle. The simulation only methods are prefixed with sim as shown below. getCollisionInfo() is renamed to simGetCollisionInfo() getCameraInfo() is renamed to simGetCameraInfo() setCameraOrientation() is renamed to simSetCameraOrientation()","title":"Simulation-Only Methods"},{"location":"docs/upgrade_apis/#state-information","text":"Previously CarState mixed simulation-only information like kinematics_true . Moving forward, CarState will only contain information that can be obtained in real world. k = car_state.kinematics_true use this: k = car_state.kinematics_estimated # or k = client.simGetGroundTruthKinematics()","title":"State Information"},{"location":"docs/upgrade_settings/","text":"Upgrading Settings The settings schema in AirSim 1.2 is changed for more flexibility and cleaner interface. If you have older settings.json file then you can either delete it and restart AirSim or use this guide to make manual upgrade. Quicker Way We recommend simply deleting the settings.json and add back the settings you need. Please see the doc for complete information on available settings. Changes UsageScenario Previously we used UsageScenario to specify the ComputerVision mode. Now we use \"SimMode\": \"ComputerVision\" instead. CameraDefaults and Changing Camera Settings Previously we had CaptureSettings and NoiseSettings in root. Now these are combined in new CameraDefaults element. The schema for this element is later used to configure cameras on vehicle. Gimbal The Gimbal element (instead of old Gimble element) is now moved out of CaptureSettings . CameraID to CameraName All settings now reference cameras by name instead of ID. Using PX4 The new Vehicles element allows to specify which vehicles to create. To use PX4, please see this section . AdditionalCameras The old AdditionalCameras setting is now replaced by Cameras element within vehicle setting.","title":"Upgrading Settings"},{"location":"docs/upgrade_settings/#upgrading-settings","text":"The settings schema in AirSim 1.2 is changed for more flexibility and cleaner interface. If you have older settings.json file then you can either delete it and restart AirSim or use this guide to make manual upgrade.","title":"Upgrading Settings"},{"location":"docs/upgrade_settings/#quicker-way","text":"We recommend simply deleting the settings.json and add back the settings you need. Please see the doc for complete information on available settings.","title":"Quicker Way"},{"location":"docs/upgrade_settings/#changes","text":"","title":"Changes"},{"location":"docs/upgrade_settings/#usagescenario","text":"Previously we used UsageScenario to specify the ComputerVision mode. Now we use \"SimMode\": \"ComputerVision\" instead.","title":"UsageScenario"},{"location":"docs/upgrade_settings/#cameradefaults-and-changing-camera-settings","text":"Previously we had CaptureSettings and NoiseSettings in root. Now these are combined in new CameraDefaults element. The schema for this element is later used to configure cameras on vehicle.","title":"CameraDefaults and Changing Camera Settings"},{"location":"docs/upgrade_settings/#gimbal","text":"The Gimbal element (instead of old Gimble element) is now moved out of CaptureSettings .","title":"Gimbal"},{"location":"docs/upgrade_settings/#cameraid-to-cameraname","text":"All settings now reference cameras by name instead of ID.","title":"CameraID to CameraName"},{"location":"docs/upgrade_settings/#using-px4","text":"The new Vehicles element allows to specify which vehicles to create. To use PX4, please see this section .","title":"Using PX4"},{"location":"docs/upgrade_settings/#additionalcameras","text":"The old AdditionalCameras setting is now replaced by Cameras element within vehicle setting.","title":"AdditionalCameras"},{"location":"docs/use_precompiled/","text":"Download Binaries You can simply download precompiled binaries and run to get started immediately. If you want to set up your own Unreal environment then please see these instructions . Windows : Download the binaries for the environment of your choice from the latest release . Linux : Binaries for Ubuntu 16.04 LTS is coming soon. For now you will need to build it on Linux yourself. Controlling Vehicles Most of our users typically use APIs to control the vehicles. However if you can also control vehicles manually. You can drive the car using keyboard, gamepad or steering wheel . To fly drone manually, you will need either XBox controller or a remote control (feel free to contribute keyboard support). Please see remote control setup for more details. Alternatively you can use APIs for programmatic control or use so-called Computer Vision mode to move around in environment using the keyboard. Don't Have Good GPU? The AirSim binaries, like CityEnviron, requires a beefy GPU to run smoothly. You can run them in low resolution mode by editing the run.bat file on Windows like this: start CityEnviron -ResX=640 -ResY=480 -windowed","title":"Download Binaries"},{"location":"docs/use_precompiled/#download-binaries","text":"You can simply download precompiled binaries and run to get started immediately. If you want to set up your own Unreal environment then please see these instructions . Windows : Download the binaries for the environment of your choice from the latest release . Linux : Binaries for Ubuntu 16.04 LTS is coming soon. For now you will need to build it on Linux yourself.","title":"Download Binaries"},{"location":"docs/use_precompiled/#controlling-vehicles","text":"Most of our users typically use APIs to control the vehicles. However if you can also control vehicles manually. You can drive the car using keyboard, gamepad or steering wheel . To fly drone manually, you will need either XBox controller or a remote control (feel free to contribute keyboard support). Please see remote control setup for more details. Alternatively you can use APIs for programmatic control or use so-called Computer Vision mode to move around in environment using the keyboard.","title":"Controlling Vehicles"},{"location":"docs/use_precompiled/#dont-have-good-gpu","text":"The AirSim binaries, like CityEnviron, requires a beefy GPU to run smoothly. You can run them in low resolution mode by editing the run.bat file on Windows like this: start CityEnviron -ResX=640 -ResY=480 -windowed","title":"Don't Have Good GPU?"},{"location":"docs/using_car/","text":"How to Use Car in AirSim By default AirSim prompts user for which vehicle to use. You can easily change this by setting SimMode . For example, if you want to use car instead then just set the SimMode in your settings.json which you can find in your ~/Documents/AirSim folder, like this: { \"SettingsVersion\": 1.2, \"SimMode\": \"Car\" } Now when you restart AirSim, you should see the car spawned automatically. Manual Driving Please use the keyboard arrow keys to drive manually. Spacebar for the handbrake. In manual drive mode, gears are set in \"auto\". Using APIs You can control the car, get state and images by calling APIs in variety of client languages including C++ and Python. Please see APIs doc for more details. Changing Views By default camera will chase the car from the back. You can get the FPV view by pressing F key and switch back to chasing from back view by pressing / key. More keyboard shortcuts can be seen by pressing F1. Cameras By default car is installed with 5 cameras: center, left and right, driver and reverse. You can chose the images from these camera by specifying the name .","title":"Using Car"},{"location":"docs/using_car/#how-to-use-car-in-airsim","text":"By default AirSim prompts user for which vehicle to use. You can easily change this by setting SimMode . For example, if you want to use car instead then just set the SimMode in your settings.json which you can find in your ~/Documents/AirSim folder, like this: { \"SettingsVersion\": 1.2, \"SimMode\": \"Car\" } Now when you restart AirSim, you should see the car spawned automatically.","title":"How to Use Car in AirSim"},{"location":"docs/using_car/#manual-driving","text":"Please use the keyboard arrow keys to drive manually. Spacebar for the handbrake. In manual drive mode, gears are set in \"auto\".","title":"Manual Driving"},{"location":"docs/using_car/#using-apis","text":"You can control the car, get state and images by calling APIs in variety of client languages including C++ and Python. Please see APIs doc for more details.","title":"Using APIs"},{"location":"docs/using_car/#changing-views","text":"By default camera will chase the car from the back. You can get the FPV view by pressing F key and switch back to chasing from back view by pressing / key. More keyboard shortcuts can be seen by pressing F1.","title":"Changing Views"},{"location":"docs/using_car/#cameras","text":"By default car is installed with 5 cameras: center, left and right, driver and reverse. You can chose the images from these camera by specifying the name .","title":"Cameras"},{"location":"docs/who_is_using/","text":"Who is Using AirSim? Would you like to see your own group or project here? Just add a GitHub issue with quick details and link to your website or paper or send us email at msrair at microsoft.com. NASA Ames Research Center \u2013 Systems Analysis Office Astrobotic GRASP Lab, Univ of Pennsylvania Department of Aeronautics and Astronautics, Stanford University Formula Technion Ghent University ICARUS UC, Santa Barbara WISE Lab, Univ of Waterloo HAMS project, MSR India Washington and Lee University University of Oklahoma Robotics Institute, Carnegie Mellon University Texas A&M Robotics and Perception Group, University of Zurich National University of Ireland, Galway (NUIG)","title":"Who is Using AirSim"},{"location":"docs/who_is_using/#who-is-using-airsim","text":"","title":"Who is Using AirSim?"},{"location":"docs/who_is_using/#would-you-like-to-see-your-own-group-or-project-here","text":"Just add a GitHub issue with quick details and link to your website or paper or send us email at msrair at microsoft.com. NASA Ames Research Center \u2013 Systems Analysis Office Astrobotic GRASP Lab, Univ of Pennsylvania Department of Aeronautics and Astronautics, Stanford University Formula Technion Ghent University ICARUS UC, Santa Barbara WISE Lab, Univ of Waterloo HAMS project, MSR India Washington and Lee University University of Oklahoma Robotics Institute, Carnegie Mellon University Texas A&M Robotics and Perception Group, University of Zurich National University of Ireland, Galway (NUIG)","title":"Would you like to see your own group or project here?"},{"location":"docs/working_with_plugin_contents/","text":"How to use plugin contents Plugin contents are not shown in Unreal projects by default. To view plugin content, you need to click on few semi-hidden buttons: Causion Changes you make in content folder are changes to binary files so be careful.","title":"Working with UE Plugin Contents"},{"location":"docs/working_with_plugin_contents/#how-to-use-plugin-contents","text":"Plugin contents are not shown in Unreal projects by default. To view plugin content, you need to click on few semi-hidden buttons: Causion Changes you make in content folder are changes to binary files so be careful.","title":"How to use plugin contents"},{"location":"docs/xbox_controller/","text":"XBox Controller To use an XBox controller with AirSim follow these steps: Connect XBox controller so it shows up in your PC Game Controllers: Launch QGroundControl and you should see a new Joystick tab under stettings: Now calibrate the radio, and setup some handy button actions. For example, I set mine so that the 'A' button arms the drone, 'B' put it in manual flight mode, 'X' puts it in altitude hold mode and 'Y' puts it in position hold mode. I also prefer the feel of the controller when I check the box labelled \"Use exponential curve on roll,pitch, yaw\" because this gives me more sensitivity for small movements.] QGroundControl will find your Pixhawk via the UDP proxy port 14550 setup by MavLinkTest above. AirSim will find your Pixhawk via the other UDP server port 14570 also setup by MavLinkTest above. You can also use all the QGroundControl controls for autonomous flying at this point too. Connect to Pixhawk serial port using MavLinkTest.exe like this: MavLinkTest.exe -serial:*,115200 -proxy:127.0.0.1:14550 -server:127.0.0.1:14570 Run AirSim Unreal simulator with these ~/Documents/AirSim/settings.json settings: \"Vehicles\": { \"PX4\": { \"VehicleType\": \"PX4Multirotor\", \"SitlIp\": \"\", \"SitlPort\": 14560, \"UdpIp\": \"127.0.0.1\", \"UdpPort\": 14570, \"UseSerial\": false } } Advanced If the Joystick tab doesn't show up in QGroundControl then Click on the purple \"Q\" icon on left in tool bar to reveal the Preferences panel. Go to General tab and check the Virtual Joystick checkbox. Go back to settings screen (gears icon), click on Parameters tab, type COM_RC_IN_MODE in search box and change its value to either Joystick/No RC Checks or Virtual RC by Joystick . Other Options See remote controller options","title":"XBox Controller"},{"location":"docs/xbox_controller/#xbox-controller","text":"To use an XBox controller with AirSim follow these steps: Connect XBox controller so it shows up in your PC Game Controllers: Launch QGroundControl and you should see a new Joystick tab under stettings: Now calibrate the radio, and setup some handy button actions. For example, I set mine so that the 'A' button arms the drone, 'B' put it in manual flight mode, 'X' puts it in altitude hold mode and 'Y' puts it in position hold mode. I also prefer the feel of the controller when I check the box labelled \"Use exponential curve on roll,pitch, yaw\" because this gives me more sensitivity for small movements.] QGroundControl will find your Pixhawk via the UDP proxy port 14550 setup by MavLinkTest above. AirSim will find your Pixhawk via the other UDP server port 14570 also setup by MavLinkTest above. You can also use all the QGroundControl controls for autonomous flying at this point too. Connect to Pixhawk serial port using MavLinkTest.exe like this: MavLinkTest.exe -serial:*,115200 -proxy:127.0.0.1:14550 -server:127.0.0.1:14570 Run AirSim Unreal simulator with these ~/Documents/AirSim/settings.json settings: \"Vehicles\": { \"PX4\": { \"VehicleType\": \"PX4Multirotor\", \"SitlIp\": \"\", \"SitlPort\": 14560, \"UdpIp\": \"127.0.0.1\", \"UdpPort\": 14570, \"UseSerial\": false } }","title":"XBox Controller"},{"location":"docs/xbox_controller/#advanced","text":"If the Joystick tab doesn't show up in QGroundControl then Click on the purple \"Q\" icon on left in tool bar to reveal the Preferences panel. Go to General tab and check the Virtual Joystick checkbox. Go back to settings screen (gears icon), click on Parameters tab, type COM_RC_IN_MODE in search box and change its value to either Joystick/No RC Checks or Virtual RC by Joystick .","title":"Advanced"},{"location":"docs/xbox_controller/#other-options","text":"See remote controller options","title":"Other Options"}]}