{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Test The Model\n",
    "\n",
    "In this notebook, we will use the model that we trained in Step 1 to drive the car around in AirSim. We will make some observations about the performance of the model, and suggest some potential experiments to improve the model.\n",
    "\n",
    "First, let us import some libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "if ('../../PythonClient/' not in sys.path):\n",
    "    sys.path.insert(0, '../../PythonClient/')\n",
    "from AirSimClient import *\n",
    "\n",
    "# << Set this to the path of the model >>\n",
    "MODEL_PATH = 'model/models/sample_model.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll load the model and connect to AirSim Simulator in the Landscape environment. Please ensure that the simulator is running in a different process *before* kicking this step off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for connection: \n"
     ]
    }
   ],
   "source": [
    "model = load_model(MODEL_PATH)\n",
    "\n",
    "client = CarClient()\n",
    "client.confirmConnection()\n",
    "client.enableApiControl(True)\n",
    "car_controls = CarControls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll set the initial state of the car, as well as some buffers used to store the output from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "car_controls.steering = 0\n",
    "car_controls.throttle = 0\n",
    "car_controls.brake = 0\n",
    "\n",
    "image_buf = np.zeros((1, 59, 255, 3))\n",
    "state_buf = np.zeros((1,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a helper function to read a RGB image from AirSim and prepare it for consumption by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_image():\n",
    "    image_response = client.simGetImages([ImageRequest(0, AirSimImageType.Scene, False, False)])[0]\n",
    "    image1d = np.fromstring(image_response.image_data_uint8, dtype=np.uint8)\n",
    "    image_rgba = image1d.reshape(image_response.height, image_response.width, 4)\n",
    "    \n",
    "    return image_rgba[76:135,0:255,0:3].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, a control block to run the car. Because our model doesn't predict speed, we will attempt to keep the car running at a constant 5 m/s. Running the block below will cause the model to drive the car!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "while (True):\n",
    "    car_state = client.getCarState()\n",
    "    \n",
    "    if (car_state.speed < 5):\n",
    "        car_controls.throttle = 1.0\n",
    "    else:\n",
    "        car_controls.throttle = 0.0\n",
    "    \n",
    "    image_buf[0] = get_image()\n",
    "    state_buf[0] = np.array([car_controls.steering, car_controls.throttle, car_controls.brake, car_state.speed])\n",
    "    model_output = model.predict([image_buf, state_buf])\n",
    "    car_controls.steering = round(0.5 * float(model_output[0][0]), 2)\n",
    "    \n",
    "    print('Sending steering = {0}, throttle = {1}'.format(car_controls.steering, car_controls.throttle))\n",
    "    \n",
    "    client.setCarControls(car_controls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations and Future Experiments\n",
    "\n",
    "We did it! The car is driving around nicely on the road, keeping to the right side for the most part, carefully navigating all the sharp turns and instances where it could potentially go off the road. However, you would immediately notice a few other things. Firstly, the motion of the car is not smooth, especially on those bridges. Also, if you let the model running for a while (a little more than 5 minutes), you will notice that the car eventually veers off the road randomly and crashes. But that is nothing to be disheartened by. Keep in mind that we have barely scratched the surface of the possibilities here. The fact that were able to have the car learn to drive around almost perfectly using a very small dataset is something to be proud of!\n",
    "\n",
    "> **Thought Exercise 2.1**:\n",
    "As you might have noticed, the motion of the car is not very smooth on those bridges. Can you think of a reason why it is so? Can you use one of the techniques we described in Step 0 to fix this?\n",
    "\n",
    "> ** Thought Exercise 2.2**:\n",
    "The car seems to crash when it tries to climb one of those hills. Can you think of a reason why? How can you fix this? (Hint: You might want to take a look at what the car is seeing when it is making that ascent)\n",
    "\n",
    "AirSim opens up a world of possibilties. There is no limit to the new things you can try as you train even more complex models and use other learning techniques (Check out our reinforcement learning tutorial). Here are a few immediate things you could try that might require modifying some of the code provided in this tutorials (including the helper files) but won't require modifying any Unreal assets.\n",
    "\n",
    "> ** Exploratory Idea 2.1**:\n",
    "If you have a background in Machine Learning, you might have asked the question: why did we train and test in the same environment? Isn't that overfitting? Well, you can make arguments on both sides. While using the same environment for both training and testing might seem like you are overfitting to that environment, it can also be seen as drawing examples from the same probability distribution. The data used for training and testing is not the same, even though it is coming from the same distribution. So that brings us to the question: how will this model fare in a different environment, one it hasn't seen before? \n",
    "This current model will probably not do very well, given that the other available environments are very different and contain elements that this model has never seen before (intersections, traffic, buildings etc.). But it would be unfair to ask this model to work well on those environments. Think of it like a human who has only ever driven in the mountains, never seen other cars or intersections in their entire life, is suddenly asked to drive in a city. How well do you think they will fare?\n",
    "The opposite case should be interesting though. Does training on data collected from one of the city environments generalize easily to driving in the mountains? Try it yourself to find out.\n",
    "\n",
    "> ** Exploratory Idea 2.2**:\n",
    "We formulated this problem as a regression problem - we are predicting a continuous valued variable. Instead, we could formulate the problem as a classification problem. More specifically, we could define buckets for the steering angles (..., -0.1, -0.05, 0, 0.05, 0.1, ...), bucketize the labels, and predict the correct bucket for each image. What happens if we make this change?\n",
    "\n",
    "> ** Exploratory Idea 2.3**:\n",
    "The model currently views a single image and a single state for each prediction. However, we have access to historical data. Can we extend the model to make predictions using the previous N images and states (e.g. given the past 3 images and past 3 states, predict the next steering angle)? (Hint: This will possibly require you to use recurrent neural network techniques)\n",
    "\n",
    "> ** Exploratory Idea 2.4**:\n",
    "AirSim is much more than the dataset we provided you. For starters, we only used one camera and used it only in RGB mode. AirSim lets you collect data in depth view, segmentation view, surface normal view etc for each of the cameras available. So you can potentially have 20 different images (for 5 cameras operating in all 4 modes) for each instance (we only used 1 image here). How can combining all this information help us improve the model we just trained?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
